{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be0t3Zk4eo4p",
        "outputId": "94029340-c1bf-42b4-f8f3-7e892313ad34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxkXcyGBeyZU",
        "outputId": "63d9692a-31c3-4af0-e596-90189a561aac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ir_spectroscopy_dataset.pt', 'ir_model_checkpoint_(4L)_(L2)_v1.pth', 'IR_NN(4L)(24)_with_L2.ipynb']\n",
            "------------\n"
          ]
        }
      ],
      "source": [
        "# Finding the Data Directory\n",
        "data_dir = '/content/drive/My Drive/Ml_IR/24_Labels/'\n",
        "os.chdir(data_dir)\n",
        "\n",
        "# List the contents of the directory\n",
        "print(os.listdir())\n",
        "\n",
        "print(\"------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33wN5z4MfMKz",
        "outputId": "24deb189-088b-46c2-9d25-28532002c35f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-f91958e94e04>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load('ir_spectroscopy_dataset.pt')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X shape: torch.Size([1000]), Processed X shape: torch.Size([980])\n",
            "Original Y shape: torch.Size([141, 1000]), Processed Y shape: torch.Size([139, 980])\n",
            "Original labels: torch.Size([141, 24]), Processed labels: torch.Size([139, 24])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "data = torch.load('ir_spectroscopy_dataset.pt')\n",
        "X_values = data['X_values']\n",
        "Y_values = data['Y_values']\n",
        "Labels = data['Labels']\n",
        "\n",
        "#print(X_values)\n",
        "\n",
        "\n",
        "def preprocess_data(X_values, Y_values, Labels, cut_front=10, cut_end=10):\n",
        "    \"\"\"\n",
        "    Preprocess the X_values and Y_values tensors by trimming a few points from the beginning and end,\n",
        "    and removing data points with all NaN values or only NaN intensities.\n",
        "\n",
        "    Parameters:\n",
        "    - X_values: torch.Tensor\n",
        "        The tensor containing the X values (wavenumbers) of the IR spectra\n",
        "    - Y_values: torch.Tensor\n",
        "        The tensor containing the Y values of the IR spectra\n",
        "    - Labels: torch.Tensor\n",
        "        The tensor containing the labels corresponding to Y_values\n",
        "    - cut_front: int, default=10\n",
        "        The number of data points to cut from the front of each spectrum\n",
        "    - cut_end: int, default=10\n",
        "        The number of data points to cut from the end of each spectrum\n",
        "\n",
        "    Returns:\n",
        "    - processed_X: torch.Tensor\n",
        "        The processed X values tensor\n",
        "    - processed_Y: torch.Tensor\n",
        "        The processed Y values tensor\n",
        "    - processed_Labels: torch.Tensor\n",
        "        The processed labels tensor\n",
        "    \"\"\"\n",
        "    # Trim the front and end of each spectrum\n",
        "    processed_X = X_values[cut_front:-cut_end]\n",
        "    processed_Y = Y_values[:, cut_front:-cut_end]\n",
        "\n",
        "    # Create a mask for non-NaN rows and rows that are not all NaN\n",
        "    mask = ~torch.isnan(processed_Y).all(dim=1) & ~torch.isnan(processed_Y).any(dim=1)\n",
        "\n",
        "    # Apply the mask to Y_values and Labels\n",
        "    processed_Y = processed_Y[mask]\n",
        "    processed_Labels = Labels[mask]\n",
        "\n",
        "    return processed_X, processed_Y, processed_Labels\n",
        "\n",
        "# Example usage:\n",
        "processed_X_values, processed_Y_values, processed_Labels = preprocess_data(X_values, Y_values, Labels)\n",
        "print(f\"Original X shape: {X_values.shape}, Processed X shape: {processed_X_values.shape}\")\n",
        "print(f\"Original Y shape: {Y_values.shape}, Processed Y shape: {processed_Y_values.shape}\")\n",
        "print(f\"Original labels: {Labels.shape}, Processed labels: {processed_Labels.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLMqiAbRVjNB",
        "outputId": "33e3d729-afe6-49de-f639-692d2f1cffd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: torch.Size([129, 980])\n",
            "Training labels shape: torch.Size([129, 24])\n",
            "Test set shape: torch.Size([10, 980])\n",
            "Test labels shape: torch.Size([10, 24])\n",
            "\n",
            "Unique label combinations in test set:\n",
            "Example 1: [13, 23]\n",
            "Example 2: 0\n",
            "Example 3: [1, 15, 23]\n",
            "Example 4: [7, 8, 23]\n",
            "Example 5: [7, 16, 23]\n",
            "Example 6: [1, 6, 23]\n",
            "Example 7: [6, 7, 13, 23]\n",
            "Example 8: 0\n",
            "Example 9: [5, 6, 23]\n",
            "Example 10: [0, 6]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def select_diverse_examples(processed_Y_values, processed_Labels, num_examples=10):\n",
        "    num_samples = processed_Y_values.shape[0]\n",
        "    num_labels = processed_Labels.shape[1]\n",
        "\n",
        "    # Convert Labels to numpy for easier manipulation\n",
        "    labels_np = processed_Labels.cpu().numpy()\n",
        "\n",
        "    selected_indices = []\n",
        "    remaining_indices = list(range(num_samples))\n",
        "\n",
        "    while len(selected_indices) < num_examples and remaining_indices:\n",
        "        if not selected_indices:\n",
        "            # Select the first example randomly\n",
        "            idx = np.random.choice(remaining_indices)\n",
        "        else:\n",
        "            # Calculate the Hamming distance to already selected examples\n",
        "            distances = []\n",
        "            for idx in remaining_indices:\n",
        "                dist = [np.sum(labels_np[idx] != labels_np[sel_idx]) for sel_idx in selected_indices]\n",
        "                distances.append(np.mean(dist))\n",
        "\n",
        "            # Select the example with distance closest to the average\n",
        "            avg_dist = np.mean(distances)\n",
        "            idx = min(remaining_indices, key=lambda i: abs(distances[remaining_indices.index(i)] - avg_dist))\n",
        "\n",
        "        selected_indices.append(idx)\n",
        "        remaining_indices.remove(idx)\n",
        "\n",
        "    # Create test set\n",
        "    Y_test = processed_Y_values[selected_indices]\n",
        "    Labels_test = processed_Labels[selected_indices]\n",
        "\n",
        "    # Create train set (all indices not in selected_indices)\n",
        "    train_indices = list(set(range(num_samples)) - set(selected_indices))\n",
        "    Y_train = processed_Y_values[train_indices]\n",
        "    Labels_train = processed_Labels[train_indices]\n",
        "\n",
        "    return Y_train, Labels_train, Y_test, Labels_test\n",
        "\n",
        "# Use the function to split the dataset\n",
        "Y_train, Labels_train, Y_test, Labels_test = select_diverse_examples(processed_Y_values, processed_Labels)\n",
        "\n",
        "print(f\"Training set shape: {Y_train.shape}\")\n",
        "print(f\"Training labels shape: {Labels_train.shape}\")\n",
        "print(f\"Test set shape: {Y_test.shape}\")\n",
        "print(f\"Test labels shape: {Labels_test.shape}\")\n",
        "\n",
        "# Verify that we have diverse examples in the test set\n",
        "print(\"\\nUnique label combinations in test set:\")\n",
        "for i in range(len(Labels_test)):\n",
        "    print(f\"Example {i+1}: {Labels_test[i].nonzero().squeeze().tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S79omws5VX3Y",
        "outputId": "b88cabec-4336-4f2c-a799-2cd911a3d991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The NN has: 12938524 parameters\n",
            "Using device: cuda\n",
            "Model and data moved to GPU successfully.\n"
          ]
        }
      ],
      "source": [
        "#----// NN //---------------------------\n",
        "\n",
        "\n",
        "class NN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.g = torch.Generator()\n",
        "\n",
        "        self.W1 = torch.nn.Parameter(torch.randn((980, 4000), generator=self.g))\n",
        "        self.b1 = torch.nn.Parameter(torch.randn(4000, generator=self.g))\n",
        "        self.W2 = torch.nn.Parameter(torch.randn((4000, 2000), generator=self.g))\n",
        "        self.b2 = torch.nn.Parameter(torch.randn(2000, generator=self.g))\n",
        "        self.W3 = torch.nn.Parameter(torch.randn((2000, 500), generator=self.g))\n",
        "        self.b3 = torch.nn.Parameter(torch.randn(500, generator=self.g))\n",
        "        self.W4 = torch.nn.Parameter(torch.randn((500, 24), generator=self.g))\n",
        "        self.b4 = torch.nn.Parameter(torch.randn(24, generator=self.g))\n",
        "\n",
        "        # Add dropout layers\n",
        "        self.dropout1 = torch.nn.Dropout(0.2)\n",
        "        self.dropout2 = torch.nn.Dropout(0.2)\n",
        "        self.dropout3 = torch.nn.Dropout(0.2)\n",
        "\n",
        "        print(f\"The NN has: {sum(p.numel() for p in self.parameters())} parameters\")\n",
        "\n",
        "    def forward(self, Y_values, Labels):\n",
        "        h = torch.sigmoid(Y_values @ self.W1 + self.b1)\n",
        "        h = self.dropout1(h)\n",
        "        h2 = torch.sigmoid(h @ self.W2 + self.b2)\n",
        "        h2 = self.dropout2(h2)\n",
        "        h3 = torch.sigmoid(h2 @ self.W3 + self.b3)\n",
        "        h3 = self.dropout3(h3)\n",
        "        logits = h3 @ self.W4 + self.b4\n",
        "        out = torch.sigmoid(logits)\n",
        "\n",
        "        # Create a target tensor from Labels\n",
        "        target = Labels.to(logits.device)\n",
        "\n",
        "        # Compute binary cross-entropy loss\n",
        "        loss = torch.nn.functional.binary_cross_entropy(out, target)\n",
        "\n",
        "        return loss, out\n",
        "\n",
        "    def __call__(self, data_tensor):\n",
        "        # Ensure data_tensor is on the same device as the model\n",
        "        data_tensor = data_tensor.to(self.W1.device)\n",
        "\n",
        "        h = torch.sigmoid(data_tensor @ self.W1 + self.b1)\n",
        "        h2 = torch.sigmoid(h @ self.W2 + self.b2)\n",
        "        h3 = torch.sigmoid(h2 @ self.W3 + self.b3)\n",
        "        logits = h3 @ self.W4 + self.b4\n",
        "        out = torch.sigmoid(logits)\n",
        "\n",
        "        return out\n",
        "\n",
        "nn_model = NN()\n",
        "optimizer = torch.optim.Adam(nn_model.parameters(), lr=0.001, weight_decay=1e-1)  # Changed to Adam optimizer with lower learning rate and added weight decay\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Move the model to the GPU\n",
        "nn_model = nn_model.to(device)\n",
        "\n",
        "# Move data tensors to GPU\n",
        "Labels_train = Labels_train.to(device)\n",
        "Y_train = Y_train.to(device)\n",
        "Y_test = Y_test.to(device)\n",
        "Labels_test = Labels_test.to(device)\n",
        "\n",
        "print(\"Model and data moved to GPU successfully.\")\n",
        "\n",
        "# L2 regularization is now handled by the optimizer's weight_decay parameter\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ImprovedNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(980, 4000),\n",
        "            nn.BatchNorm1d(4000),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(4000, 2000),\n",
        "            nn.BatchNorm1d(2000),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(2000, 500),\n",
        "            nn.BatchNorm1d(500),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "        self.layer4 = nn.Linear(500, 24)\n",
        "\n",
        "        # Initialize weights using He initialization\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "        print(f\"The NN has: {sum(p.numel() for p in self.parameters())} parameters\")\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            nn.init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
        "            if module.bias is not None:\n",
        "                nn.init.constant_(module.bias, 0)\n",
        "\n",
        "    def forward(self, Y_values, Labels):\n",
        "        \"\"\"\n",
        "        Forward pass for training.\n",
        "\n",
        "        Args:\n",
        "            Y_values (torch.Tensor): Input features.\n",
        "            Labels (torch.Tensor): Ground truth labels.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (loss, output)\n",
        "        \"\"\"\n",
        "        h = self.layer1(Y_values)\n",
        "        h2 = self.layer2(h)\n",
        "        h3 = self.layer3(h2)\n",
        "        logits = self.layer4(h3)\n",
        "        out = torch.sigmoid(logits)\n",
        "\n",
        "        # Create a target tensor from Labels\n",
        "        target = Labels.to(logits.device)\n",
        "\n",
        "        # Compute binary cross-entropy loss\n",
        "        loss = nn.functional.binary_cross_entropy(out, target)\n",
        "\n",
        "        return loss, out\n",
        "\n",
        "    def __call__(self, data_tensor):\n",
        "        \"\"\"\n",
        "        Inference pass.\n",
        "\n",
        "        Args:\n",
        "            data_tensor (torch.Tensor): Input features.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Model predictions.\n",
        "        \"\"\"\n",
        "        self.eval()  # Set the model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            # Ensure data_tensor is on the same device as the model\n",
        "            data_tensor = data_tensor.to(next(self.parameters()).device)\n",
        "\n",
        "            # Add a batch dimension if it's not present\n",
        "            if data_tensor.dim() == 1:\n",
        "                data_tensor = data_tensor.unsqueeze(0)\n",
        "\n",
        "            h = self.layer1(data_tensor)\n",
        "            h2 = self.layer2(h)\n",
        "            h3 = self.layer3(h2)\n",
        "            logits = self.layer4(h3)\n",
        "            out = torch.sigmoid(logits)\n",
        "\n",
        "            # Remove the batch dimension if we added it\n",
        "            if out.shape[0] == 1:\n",
        "                out = out.squeeze(0)\n",
        "\n",
        "            return out\n",
        "\n",
        "# Initialize the model\n",
        "nn_model = ImprovedNN()\n",
        "optimizer = torch.optim.AdamW(nn_model.parameters(), lr=0.001, weight_decay=1e-2)\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Move the model to the GPU\n",
        "nn_model = nn_model.to(device)\n",
        "\n",
        "# Move data tensors to GPU (assuming these variables exist)\n",
        "Labels_train = Labels_train.to(device)\n",
        "Y_train = Y_train.to(device)\n",
        "Y_test = Y_test.to(device)\n",
        "Labels_test = Labels_test.to(device)\n",
        "\n",
        "print(\"Model and data moved to GPU successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiE3bpnVsbKM",
        "outputId": "b26dcc25-b2d1-40bd-dea9-418c749d4a9b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The NN has: 12951524 parameters\n",
            "Using device: cuda\n",
            "Model and data moved to GPU successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqhofe3I8vz9",
        "outputId": "c328893e-cb2a-42ba-8588-93e38f803c8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 1, Loss: 2.8543521693791263e-05\n",
            "Epoch 1, Loss: 3.182068758178502e-05\n",
            "Epoch 1, Loss: 3.178249971824698e-05\n",
            "Epoch 1, Loss: 3.275971903349273e-05\n",
            "Epoch 1, Loss: 3.248096618335694e-05\n",
            "Epoch 1, Loss: 2.9358878236962482e-05\n",
            "Epoch 1, Loss: 3.065842611249536e-05\n",
            "Epoch 1, Loss: 3.197568003088236e-05\n",
            "Epoch 1, Loss: 2.8528629627544433e-05\n",
            "Epoch 1, Loss: 3.097386070294306e-05\n",
            "Epoch 1, Loss: 2.5518686015857384e-05\n",
            "Epoch 1, Loss: 2.5897610612446442e-05\n",
            "Epoch 1, Loss: 3.2170562917599455e-05\n",
            "Epoch 1, Loss: 3.399079287191853e-05\n",
            "Epoch 1, Loss: 3.728653973666951e-05\n",
            "Epoch 1, Loss: 2.716643393796403e-05\n",
            "Epoch 1, Loss: 2.6730087483883835e-05\n",
            "Epoch 1, Loss: 3.858928903355263e-05\n",
            "Epoch 1, Loss: 2.7238249458605424e-05\n",
            "Epoch 1, Loss: 2.8853963158326223e-05\n",
            "Epoch 1, Loss: 2.6807456379174255e-05\n",
            "Epoch 1, Loss: 2.620903978822753e-05\n",
            "Epoch 1, Loss: 2.781973307719454e-05\n",
            "Epoch 1, Loss: 2.4506114641553722e-05\n",
            "Epoch 1, Loss: 2.6816840545507148e-05\n",
            "Epoch 1, Loss: 3.1270625186152756e-05\n",
            "Epoch 1, Loss: 2.9179311241023242e-05\n",
            "Epoch 1, Loss: 3.362990537425503e-05\n",
            "Epoch 1, Loss: 2.5523735530441627e-05\n",
            "Epoch 1, Loss: 3.630101855378598e-05\n",
            "Epoch 1, Loss: 2.9369241019594483e-05\n",
            "Epoch 1, Loss: 3.0771017918596044e-05\n",
            "Epoch 1, Loss: 2.8716760425595567e-05\n",
            "Epoch 1, Loss: 2.899399260058999e-05\n",
            "Epoch 1, Loss: 2.8572327209985815e-05\n",
            "Epoch 1, Loss: 2.698761090869084e-05\n",
            "Epoch 1, Loss: 2.6809384507942013e-05\n",
            "Epoch 1, Loss: 2.39735672948882e-05\n",
            "Epoch 1, Loss: 3.189426570315845e-05\n",
            "Epoch 1, Loss: 2.5952389478334226e-05\n",
            "Epoch 1, Loss: 2.8196765924803913e-05\n",
            "Epoch 1, Loss: 2.7545198463485576e-05\n",
            "Epoch 1, Loss: 3.0835486541036516e-05\n",
            "Epoch 1, Loss: 3.56972923327703e-05\n",
            "Epoch 1, Loss: 3.0592724215239286e-05\n",
            "Epoch 1, Loss: 2.872239019779954e-05\n",
            "Epoch 1, Loss: 3.4572480217320845e-05\n",
            "Epoch 1, Loss: 2.910636794695165e-05\n",
            "Epoch 1, Loss: 2.717369352467358e-05\n",
            "Epoch 1, Loss: 3.0444241929217242e-05\n",
            "Epoch 1, Loss: 2.4540689992136322e-05\n",
            "Epoch 1, Loss: 2.8507183742476627e-05\n",
            "Epoch 1, Loss: 2.860557651729323e-05\n",
            "Epoch 1, Loss: 4.0416049159830436e-05\n",
            "Epoch 1, Loss: 3.8576687074964866e-05\n",
            "Epoch 1, Loss: 3.0555100238416344e-05\n",
            "Epoch 1, Loss: 3.4322660212637857e-05\n",
            "Epoch 1, Loss: 2.7080286599812098e-05\n",
            "Epoch 1, Loss: 2.8247508453205228e-05\n",
            "Epoch 1, Loss: 2.963552287837956e-05\n",
            "Epoch 1, Loss: 2.712337300181389e-05\n",
            "Epoch 1, Loss: 2.8022259357385337e-05\n",
            "Epoch 1, Loss: 3.0468057957477868e-05\n",
            "Epoch 1, Loss: 2.9800814445479773e-05\n",
            "Epoch 1, Loss: 3.3668802643660456e-05\n",
            "Epoch 1, Loss: 2.540026616770774e-05\n",
            "Epoch 1, Loss: 2.88869359792443e-05\n",
            "Epoch 1, Loss: 2.8809688956243917e-05\n",
            "Epoch 1, Loss: 2.50449484155979e-05\n",
            "Epoch 1, Loss: 3.3580414310563356e-05\n",
            "Epoch 1, Loss: 3.385881791473366e-05\n",
            "Epoch 1, Loss: 2.6870302463066764e-05\n",
            "Epoch 1, Loss: 2.7376383513910696e-05\n",
            "Epoch 1, Loss: 2.678355303942226e-05\n",
            "Epoch 1, Loss: 2.580881664471235e-05\n",
            "Epoch 1, Loss: 3.170933268847875e-05\n",
            "Epoch 1, Loss: 3.216210097889416e-05\n",
            "Epoch 1, Loss: 2.820669033098966e-05\n",
            "Epoch 1, Loss: 2.781279727059882e-05\n",
            "Epoch 1, Loss: 2.718956420721952e-05\n",
            "Epoch 1, Loss: 2.5726949388626963e-05\n",
            "Epoch 1, Loss: 2.65277976723155e-05\n",
            "Epoch 1, Loss: 2.935595330200158e-05\n",
            "Epoch 1, Loss: 3.0164152121869847e-05\n",
            "Epoch 1, Loss: 2.3760248950566165e-05\n",
            "Epoch 1, Loss: 2.9410717615974136e-05\n",
            "Epoch 1, Loss: 2.971484173031058e-05\n",
            "Epoch 1, Loss: 3.428573108976707e-05\n",
            "Epoch 1, Loss: 2.8005222702631727e-05\n",
            "Epoch 1, Loss: 3.1517978641204536e-05\n",
            "Epoch 1, Loss: 2.234525527455844e-05\n",
            "Epoch 1, Loss: 2.2809934307588264e-05\n",
            "Epoch 1, Loss: 2.9722701583523303e-05\n",
            "Epoch 1, Loss: 2.933654650405515e-05\n",
            "Epoch 1, Loss: 3.550285691744648e-05\n",
            "Epoch 1, Loss: 2.9273211112013087e-05\n",
            "Epoch 1, Loss: 2.440238677081652e-05\n",
            "Epoch 1, Loss: 3.0469571356661618e-05\n",
            "Epoch 1, Loss: 3.538651071721688e-05\n",
            "Epoch 1, Loss: 2.8422589821275324e-05\n",
            "Epoch 1, Loss: 2.7888263502973132e-05\n",
            "Epoch 1, Loss: 2.455102548992727e-05\n",
            "Epoch 1, Loss: 2.7063540983363055e-05\n",
            "Epoch 1, Loss: 2.8747675969498232e-05\n",
            "Epoch 1, Loss: 2.6294548661098816e-05\n",
            "Epoch 1, Loss: 2.6793102733790874e-05\n",
            "Epoch 1, Loss: 2.8602389647858217e-05\n",
            "Epoch 1, Loss: 2.4557195501984097e-05\n",
            "Epoch 1, Loss: 2.6577568860375322e-05\n",
            "Epoch 1, Loss: 2.8138523703091778e-05\n",
            "Epoch 1, Loss: 2.5829634978435934e-05\n",
            "Epoch 1, Loss: 2.733922519837506e-05\n",
            "Epoch 1, Loss: 2.489051257725805e-05\n",
            "Epoch 1, Loss: 2.2979251298238523e-05\n",
            "Epoch 1, Loss: 2.3437120034941472e-05\n",
            "Epoch 1, Loss: 2.960473830171395e-05\n",
            "Epoch 1, Loss: 2.633443000377156e-05\n",
            "Epoch 1, Loss: 3.199501952622086e-05\n",
            "Epoch 1, Loss: 3.216373443137854e-05\n",
            "Epoch 1, Loss: 2.9618766347994097e-05\n",
            "Epoch 1, Loss: 2.8214015401317738e-05\n",
            "Epoch 1, Loss: 2.3807218894944526e-05\n",
            "Epoch 1, Loss: 2.6283867555321194e-05\n",
            "Epoch 1, Loss: 3.4209457226097584e-05\n",
            "Epoch 1, Loss: 3.164616282447241e-05\n",
            "Epoch 1, Loss: 2.835512532328721e-05\n",
            "Epoch 1, Loss: 3.293547342764214e-05\n",
            "Epoch 1, Loss: 3.0746159609407187e-05\n",
            "Epoch 1, Loss: 2.4971608581836335e-05\n",
            "Epoch 1, Loss: 3.2260741136269644e-05\n",
            "Epoch 1, Loss: 2.6623543817549944e-05\n",
            "Epoch 1, Loss: 3.4858436265494674e-05\n",
            "Epoch 1, Loss: 2.6891222660196945e-05\n",
            "Epoch 1, Loss: 3.0373024856089614e-05\n",
            "Epoch 1, Loss: 3.3636217267485335e-05\n",
            "Epoch 1, Loss: 2.664208113856148e-05\n",
            "Epoch 1, Loss: 2.574730388005264e-05\n",
            "Epoch 1, Loss: 2.444667370582465e-05\n",
            "Epoch 1, Loss: 2.3395088646793738e-05\n",
            "Epoch 1, Loss: 2.686871448531747e-05\n",
            "Epoch 1, Loss: 2.959826451842673e-05\n",
            "Epoch 1, Loss: 2.6726193027570844e-05\n",
            "Epoch 1, Loss: 2.5882343834382482e-05\n",
            "Epoch 1, Loss: 2.7170237444806844e-05\n",
            "Epoch 1, Loss: 2.535137173254043e-05\n",
            "Epoch 1, Loss: 2.9477298085112125e-05\n",
            "Epoch 1, Loss: 2.41076122620143e-05\n",
            "Epoch 1, Loss: 2.609705916256644e-05\n",
            "Epoch 1, Loss: 2.6998346584150568e-05\n",
            "Epoch 1, Loss: 2.8274438591324724e-05\n",
            "Epoch 1, Loss: 3.141340130241588e-05\n",
            "Epoch 1, Loss: 2.506973578420002e-05\n",
            "Epoch 1, Loss: 2.4104654585244134e-05\n",
            "Epoch 1, Loss: 3.460797233856283e-05\n",
            "Epoch 1, Loss: 2.6516001526033506e-05\n",
            "Epoch 1, Loss: 3.643986565293744e-05\n",
            "Epoch 1, Loss: 2.688008316908963e-05\n",
            "Epoch 1, Loss: 2.6601870558806695e-05\n",
            "Epoch 1, Loss: 2.5096140234381892e-05\n",
            "Epoch 1, Loss: 2.877160659409128e-05\n",
            "Epoch 1, Loss: 2.5545901735313237e-05\n",
            "Epoch 1, Loss: 2.4060465875663795e-05\n",
            "Epoch 1, Loss: 2.833621510944795e-05\n",
            "Epoch 1, Loss: 2.7224830773775466e-05\n",
            "Epoch 1, Loss: 2.5331999495392665e-05\n",
            "Epoch 1, Loss: 2.9522096156142652e-05\n",
            "Epoch 1, Loss: 3.294050111435354e-05\n",
            "Epoch 1, Loss: 2.641687933646608e-05\n",
            "Epoch 1, Loss: 2.3760756448609754e-05\n",
            "Epoch 1, Loss: 2.8465199648053385e-05\n",
            "Epoch 1, Loss: 2.8375503461575136e-05\n",
            "Epoch 1, Loss: 2.4082361051114276e-05\n",
            "Epoch 1, Loss: 3.3161024475703016e-05\n",
            "Epoch 1, Loss: 2.3828382836654782e-05\n",
            "Epoch 1, Loss: 2.8437529181246646e-05\n",
            "Epoch 1, Loss: 2.513683466531802e-05\n",
            "Epoch 1, Loss: 2.9722785257035866e-05\n",
            "Epoch 1, Loss: 2.402633981546387e-05\n",
            "Epoch 1, Loss: 2.674147253856063e-05\n",
            "Epoch 1, Loss: 2.463018972775899e-05\n",
            "Epoch 1, Loss: 2.5610923330532387e-05\n",
            "Epoch 1, Loss: 3.1928324460750446e-05\n",
            "Epoch 1, Loss: 2.6733458071248606e-05\n",
            "Epoch 1, Loss: 2.595431033114437e-05\n",
            "Epoch 1, Loss: 2.245510222564917e-05\n",
            "Epoch 1, Loss: 2.231540929642506e-05\n",
            "Epoch 1, Loss: 2.418753138044849e-05\n",
            "Epoch 1, Loss: 3.0946404876885936e-05\n",
            "Epoch 1, Loss: 2.6678297217586078e-05\n",
            "Epoch 1, Loss: 3.0516785045620054e-05\n",
            "Epoch 1, Loss: 2.8471935365814716e-05\n",
            "Epoch 1, Loss: 3.4110020351363346e-05\n",
            "Epoch 1, Loss: 2.6700517992139794e-05\n",
            "Epoch 1, Loss: 2.7438311008154415e-05\n",
            "Epoch 1, Loss: 2.9329541575862095e-05\n",
            "Epoch 1, Loss: 4.013919533463195e-05\n",
            "Epoch 1, Loss: 3.428439231356606e-05\n",
            "Epoch 1, Loss: 2.5121909857261926e-05\n",
            "Epoch 1, Loss: 3.329216633574106e-05\n",
            "Epoch 1, Loss: 2.577161467343103e-05\n",
            "Epoch 1, Loss: 2.301844142493792e-05\n",
            "Epoch 1, Loss: 2.228335324616637e-05\n",
            "Epoch 1, Loss: 2.8664331694017164e-05\n",
            "Epoch 1, Loss: 2.377326018176973e-05\n",
            "Epoch 1, Loss: 2.382728416705504e-05\n",
            "Epoch 1, Loss: 2.7369145755073987e-05\n",
            "Epoch 1, Loss: 2.8648648367379792e-05\n",
            "Epoch 1, Loss: 2.616468736960087e-05\n",
            "Epoch 1, Loss: 2.968516491819173e-05\n",
            "Epoch 1, Loss: 3.026318154297769e-05\n",
            "Epoch 1, Loss: 2.3763892386341467e-05\n",
            "Epoch 1, Loss: 2.4349716113647446e-05\n",
            "Epoch 1, Loss: 3.167891554767266e-05\n",
            "Epoch 1, Loss: 2.831710116879549e-05\n",
            "Epoch 1, Loss: 2.8476100851548836e-05\n",
            "Epoch 1, Loss: 3.2733754778746516e-05\n",
            "Epoch 1, Loss: 2.7318614229443483e-05\n",
            "Epoch 1, Loss: 2.76519640465267e-05\n",
            "Epoch 1, Loss: 2.1859421394765377e-05\n",
            "Epoch 1, Loss: 3.182409636792727e-05\n",
            "Epoch 1, Loss: 2.8408030630089343e-05\n",
            "Epoch 1, Loss: 2.3799888367648236e-05\n",
            "Epoch 1, Loss: 2.5069712137337774e-05\n",
            "Epoch 1, Loss: 2.537806904001627e-05\n",
            "Epoch 1, Loss: 2.7939764549955726e-05\n",
            "Epoch 1, Loss: 2.2424308554036543e-05\n",
            "Epoch 1, Loss: 2.7825075449072756e-05\n",
            "Epoch 1, Loss: 2.6879042707150802e-05\n",
            "Epoch 1, Loss: 2.4080954972305335e-05\n",
            "Epoch 1, Loss: 2.479557770129759e-05\n",
            "Epoch 1, Loss: 2.4630791813251562e-05\n",
            "Epoch 1, Loss: 2.5897998057189398e-05\n",
            "Epoch 1, Loss: 3.1781670259078965e-05\n",
            "Epoch 1, Loss: 2.243167909909971e-05\n",
            "Epoch 1, Loss: 2.101646168739535e-05\n",
            "Epoch 1, Loss: 2.7000531190424226e-05\n",
            "Epoch 1, Loss: 2.4930744984885678e-05\n",
            "Epoch 1, Loss: 2.9503713449230418e-05\n",
            "Epoch 1, Loss: 2.2065456505515613e-05\n",
            "Epoch 1, Loss: 3.231468144804239e-05\n",
            "Epoch 1, Loss: 3.032468885066919e-05\n",
            "Epoch 1, Loss: 2.6238631107844412e-05\n",
            "Epoch 1, Loss: 2.653848241607193e-05\n",
            "Epoch 1, Loss: 2.7293637685943395e-05\n",
            "Epoch 1, Loss: 3.208225825801492e-05\n",
            "Epoch 1, Loss: 2.7546926503418945e-05\n",
            "Epoch 1, Loss: 2.8647853469010442e-05\n",
            "Epoch 1, Loss: 3.0059638447710313e-05\n",
            "Epoch 1, Loss: 2.2819060177425854e-05\n",
            "Epoch 1, Loss: 2.8008616936858743e-05\n",
            "Epoch 1, Loss: 2.1297528292052448e-05\n",
            "Epoch 1, Loss: 2.5658331651357003e-05\n",
            "Epoch 1, Loss: 2.7342233806848526e-05\n",
            "Epoch 1, Loss: 2.8154860046925023e-05\n",
            "Epoch 1, Loss: 2.648821464390494e-05\n",
            "Epoch 1, Loss: 2.6589978006086312e-05\n",
            "Epoch 1, Loss: 3.1775238312548026e-05\n",
            "Epoch 1, Loss: 2.7809381208498962e-05\n",
            "Epoch 1, Loss: 2.9221937438705936e-05\n",
            "Epoch 1, Loss: 2.6754640202852897e-05\n",
            "Epoch 1, Loss: 2.8674325221800245e-05\n",
            "Epoch 1, Loss: 3.359629772603512e-05\n",
            "Epoch 1, Loss: 2.873703488148749e-05\n",
            "Epoch 1, Loss: 2.427069739496801e-05\n",
            "Epoch 1, Loss: 2.8447671866160817e-05\n",
            "Epoch 1, Loss: 2.9659337087650783e-05\n",
            "Epoch 1, Loss: 2.9786822778987698e-05\n",
            "Epoch 1, Loss: 2.9497432478819974e-05\n",
            "Epoch 1, Loss: 2.6455258193891495e-05\n",
            "Epoch 1, Loss: 2.982221485581249e-05\n",
            "Epoch 1, Loss: 2.404843326075934e-05\n",
            "Epoch 1, Loss: 2.5486757294856943e-05\n",
            "Epoch 1, Loss: 2.9521344913518988e-05\n",
            "Epoch 1, Loss: 2.5725430532475002e-05\n",
            "Epoch 1, Loss: 3.1142521038418636e-05\n",
            "Epoch 1, Loss: 2.822127498802729e-05\n",
            "Epoch 1, Loss: 2.5749122869456187e-05\n",
            "Epoch 1, Loss: 2.5650319003034383e-05\n",
            "Epoch 1, Loss: 2.0996381863369606e-05\n",
            "Epoch 1, Loss: 2.568014315329492e-05\n",
            "Epoch 1, Loss: 3.029905928997323e-05\n",
            "Epoch 1, Loss: 2.3203669115900993e-05\n",
            "Epoch 1, Loss: 2.5591607482056133e-05\n",
            "Epoch 1, Loss: 2.4514672986697406e-05\n",
            "Epoch 1, Loss: 2.442790355416946e-05\n",
            "Epoch 1, Loss: 2.2038575480110012e-05\n",
            "Epoch 1, Loss: 2.388665780017618e-05\n",
            "Epoch 1, Loss: 3.521570761222392e-05\n",
            "Epoch 1, Loss: 2.7873295039171353e-05\n",
            "Epoch 1, Loss: 3.1011375540401787e-05\n",
            "Epoch 1, Loss: 2.290368684043642e-05\n",
            "Epoch 1, Loss: 2.4102335373754613e-05\n",
            "Epoch 1, Loss: 2.7143350962433033e-05\n",
            "Epoch 1, Loss: 2.332400981686078e-05\n",
            "Epoch 1, Loss: 2.479735303495545e-05\n",
            "Epoch 1, Loss: 2.4684424715815112e-05\n",
            "Epoch 1, Loss: 2.5658982849563472e-05\n",
            "Epoch 1, Loss: 2.6596489988151006e-05\n",
            "Epoch 1, Loss: 3.479111546766944e-05\n",
            "Epoch 1, Loss: 2.300028791069053e-05\n",
            "Epoch 1, Loss: 2.131216933776159e-05\n",
            "Epoch 1, Loss: 2.4066597688943148e-05\n",
            "Epoch 1, Loss: 2.801423215714749e-05\n",
            "Epoch 1, Loss: 3.1773652153788134e-05\n",
            "Epoch 1, Loss: 2.3811082428437658e-05\n",
            "Epoch 1, Loss: 2.4642597054480575e-05\n",
            "Epoch 1, Loss: 2.491833765816409e-05\n",
            "Epoch 1, Loss: 2.3764927391312085e-05\n",
            "Epoch 1, Loss: 2.7313817554386333e-05\n",
            "Epoch 1, Loss: 2.787680205074139e-05\n",
            "Epoch 1, Loss: 2.078509896819014e-05\n",
            "Epoch 1, Loss: 2.6819219783646986e-05\n",
            "Epoch 1, Loss: 2.50017546932213e-05\n",
            "Epoch 1, Loss: 2.542591028031893e-05\n",
            "Epoch 1, Loss: 2.492497515049763e-05\n",
            "Epoch 1, Loss: 2.2988675482338294e-05\n",
            "Epoch 1, Loss: 2.009444870054722e-05\n",
            "Epoch 1, Loss: 2.4470595235470682e-05\n",
            "Epoch 1, Loss: 2.6130412152269855e-05\n",
            "Epoch 1, Loss: 2.8962065698578954e-05\n",
            "Epoch 1, Loss: 2.444599158479832e-05\n",
            "Epoch 1, Loss: 2.260658766317647e-05\n",
            "Epoch 1, Loss: 2.7124669941258617e-05\n",
            "Epoch 1, Loss: 2.5520554117974825e-05\n",
            "Epoch 1, Loss: 2.2520503989653662e-05\n",
            "Epoch 1, Loss: 2.3814811356714927e-05\n",
            "Epoch 1, Loss: 2.288507494085934e-05\n",
            "Epoch 1, Loss: 2.1393287170212716e-05\n",
            "Epoch 1, Loss: 2.7362306354916655e-05\n",
            "Epoch 1, Loss: 2.635255441418849e-05\n",
            "Epoch 1, Loss: 2.359816789976321e-05\n",
            "Epoch 1, Loss: 2.4811602997942828e-05\n",
            "Epoch 1, Loss: 2.5046570954145864e-05\n",
            "Epoch 1, Loss: 2.7009904442820698e-05\n",
            "Epoch 1, Loss: 2.8043461497873068e-05\n",
            "Epoch 1, Loss: 2.4990256861201487e-05\n",
            "Epoch 1, Loss: 2.4435646992060356e-05\n",
            "Epoch 1, Loss: 2.426929677312728e-05\n",
            "Epoch 1, Loss: 2.5620955057092942e-05\n",
            "Epoch 1, Loss: 2.2944539523450658e-05\n",
            "Epoch 1, Loss: 2.7079377105110325e-05\n",
            "Epoch 1, Loss: 2.6464511392987333e-05\n",
            "Epoch 1, Loss: 2.3895267077023163e-05\n",
            "Epoch 1, Loss: 2.726636375882663e-05\n",
            "Epoch 1, Loss: 2.9804026780766435e-05\n",
            "Epoch 1, Loss: 2.6894327675108798e-05\n",
            "Epoch 1, Loss: 2.6066862119478174e-05\n",
            "Epoch 1, Loss: 2.52296249527717e-05\n",
            "Epoch 1, Loss: 2.5924686269718222e-05\n",
            "Epoch 1, Loss: 2.3822072762413882e-05\n",
            "Epoch 1, Loss: 2.5462622943450697e-05\n",
            "Epoch 1, Loss: 2.260907604068052e-05\n",
            "Epoch 1, Loss: 2.2278391043073498e-05\n",
            "Epoch 1, Loss: 2.4708571800147183e-05\n",
            "Epoch 1, Loss: 2.68900203082012e-05\n",
            "Epoch 1, Loss: 2.016132748394739e-05\n",
            "Epoch 1, Loss: 2.5159721189993434e-05\n",
            "Epoch 1, Loss: 2.5322873625555076e-05\n",
            "Epoch 1, Loss: 2.263908572786022e-05\n",
            "Epoch 1, Loss: 2.657478216860909e-05\n",
            "Epoch 1, Loss: 2.4301272787852213e-05\n",
            "Epoch 1, Loss: 2.3872285964898765e-05\n",
            "Epoch 1, Loss: 2.3576481908094138e-05\n",
            "Epoch 1, Loss: 2.5727636966621503e-05\n",
            "Epoch 1, Loss: 2.0237586795701645e-05\n",
            "Epoch 1, Loss: 1.9923327272408642e-05\n",
            "Epoch 1, Loss: 2.52614299824927e-05\n",
            "Epoch 1, Loss: 2.7221645723329857e-05\n",
            "Epoch 1, Loss: 2.666338514245581e-05\n",
            "Epoch 1, Loss: 2.530071469664108e-05\n",
            "Epoch 1, Loss: 2.2962194634601474e-05\n",
            "Epoch 1, Loss: 2.4871236746548675e-05\n",
            "Epoch 1, Loss: 2.5171320885419846e-05\n",
            "Epoch 1, Loss: 2.621369822009001e-05\n",
            "Epoch 1, Loss: 1.9577850252971984e-05\n",
            "Epoch 1, Loss: 2.462792326696217e-05\n",
            "Epoch 1, Loss: 2.2094620362622663e-05\n",
            "Epoch 1, Loss: 2.371618029428646e-05\n",
            "Epoch 1, Loss: 2.585885340522509e-05\n",
            "Epoch 1, Loss: 2.8260876206331886e-05\n",
            "Epoch 1, Loss: 2.6780440748552792e-05\n",
            "Epoch 1, Loss: 2.4696035325177945e-05\n",
            "Epoch 1, Loss: 2.7758534997701645e-05\n",
            "Epoch 1, Loss: 2.4587046937085688e-05\n",
            "Epoch 1, Loss: 2.847881114576012e-05\n",
            "Epoch 1, Loss: 2.7556074201129377e-05\n",
            "Epoch 1, Loss: 2.4932958694989793e-05\n",
            "Epoch 1, Loss: 2.6556968805380166e-05\n",
            "Epoch 1, Loss: 2.521903115848545e-05\n",
            "Epoch 1, Loss: 2.3791213607182726e-05\n",
            "Epoch 1, Loss: 2.4380304239457473e-05\n",
            "Epoch 1, Loss: 2.44965613092063e-05\n",
            "Epoch 1, Loss: 2.2823152903583832e-05\n",
            "Epoch 1, Loss: 2.1823212591698393e-05\n",
            "Epoch 1, Loss: 2.7478232368594036e-05\n",
            "Epoch 1, Loss: 2.268762000312563e-05\n",
            "Epoch 1, Loss: 2.316189966222737e-05\n",
            "Epoch 1, Loss: 2.4432372811133973e-05\n",
            "Epoch 1, Loss: 2.352637420699466e-05\n",
            "Epoch 1, Loss: 2.6325877115596086e-05\n",
            "Epoch 1, Loss: 2.1613081116811372e-05\n",
            "Epoch 1, Loss: 2.6171128411078826e-05\n",
            "Epoch 1, Loss: 2.141616278095171e-05\n",
            "Epoch 1, Loss: 2.7350441087037325e-05\n",
            "Epoch 1, Loss: 2.3518610760220326e-05\n",
            "Epoch 1, Loss: 2.4597606170573272e-05\n",
            "Epoch 1, Loss: 2.5248560632462613e-05\n",
            "Epoch 1, Loss: 2.1731702872784808e-05\n",
            "Epoch 1, Loss: 2.3614293240825646e-05\n",
            "Epoch 1, Loss: 2.541439789638389e-05\n",
            "Epoch 1, Loss: 3.3391192118870094e-05\n",
            "Epoch 1, Loss: 2.232792212453205e-05\n",
            "Epoch 1, Loss: 2.459805727994535e-05\n",
            "Epoch 1, Loss: 2.48735068453243e-05\n",
            "Epoch 1, Loss: 2.646515167725738e-05\n",
            "Epoch 1, Loss: 2.193543332396075e-05\n",
            "Epoch 1, Loss: 2.6710602469393052e-05\n",
            "Epoch 1, Loss: 2.210356979048811e-05\n",
            "Epoch 1, Loss: 2.075460179185029e-05\n",
            "Epoch 1, Loss: 2.435120586596895e-05\n",
            "Epoch 1, Loss: 2.521565511415247e-05\n",
            "Epoch 1, Loss: 2.0148885596427135e-05\n",
            "Epoch 1, Loss: 2.59917233051965e-05\n",
            "Epoch 1, Loss: 2.3501250325352885e-05\n",
            "Epoch 1, Loss: 2.5776213078643195e-05\n",
            "Epoch 1, Loss: 1.9107868865830824e-05\n",
            "Epoch 1, Loss: 2.2569214706891216e-05\n",
            "Epoch 1, Loss: 2.2193416953086853e-05\n",
            "Epoch 1, Loss: 2.4531995222787373e-05\n",
            "Epoch 1, Loss: 2.4612252673250623e-05\n",
            "Epoch 1, Loss: 1.8604327124194242e-05\n",
            "Epoch 1, Loss: 2.7047213734476827e-05\n",
            "Epoch 1, Loss: 2.1839618057128973e-05\n",
            "Epoch 1, Loss: 2.2451882614404894e-05\n",
            "Epoch 1, Loss: 2.7086369300377555e-05\n",
            "Epoch 1, Loss: 2.2758780687581748e-05\n",
            "Epoch 1, Loss: 2.3235916160047054e-05\n",
            "Epoch 1, Loss: 2.2725615053786896e-05\n",
            "Epoch 1, Loss: 2.458587914588861e-05\n",
            "Epoch 1, Loss: 2.185371886298526e-05\n",
            "Epoch 1, Loss: 2.7951618903898634e-05\n",
            "Epoch 1, Loss: 2.566495277278591e-05\n",
            "Epoch 1, Loss: 2.688982021936681e-05\n",
            "Epoch 1, Loss: 2.1998066586093046e-05\n",
            "Epoch 1, Loss: 2.742216565820854e-05\n",
            "Epoch 1, Loss: 2.3816017346689478e-05\n",
            "Epoch 1, Loss: 1.845053702709265e-05\n",
            "Epoch 1, Loss: 2.4713914172025397e-05\n",
            "Epoch 1, Loss: 2.479906652297359e-05\n",
            "Epoch 1, Loss: 3.1912888516671956e-05\n",
            "Epoch 1, Loss: 2.103701808664482e-05\n",
            "Epoch 1, Loss: 3.009986539836973e-05\n",
            "Epoch 1, Loss: 2.0672987375291996e-05\n",
            "Epoch 1, Loss: 2.2748246919945814e-05\n",
            "Epoch 1, Loss: 2.051837509498e-05\n",
            "Epoch 1, Loss: 2.4714096070965752e-05\n",
            "Epoch 1, Loss: 2.6384066586615518e-05\n",
            "Epoch 1, Loss: 2.3756912924000062e-05\n",
            "Epoch 1, Loss: 2.3925302230054513e-05\n",
            "Epoch 1, Loss: 2.648038207553327e-05\n",
            "Epoch 1, Loss: 2.645170570758637e-05\n",
            "Epoch 1, Loss: 2.2616095520788804e-05\n",
            "Epoch 1, Loss: 2.4055567337200046e-05\n",
            "Epoch 1, Loss: 2.265278817503713e-05\n",
            "Epoch 1, Loss: 2.2767499103792943e-05\n",
            "Epoch 1, Loss: 2.2333342712954618e-05\n",
            "Epoch 1, Loss: 2.3861277441028506e-05\n",
            "Epoch 1, Loss: 2.2033524146536365e-05\n",
            "Epoch 1, Loss: 2.1279956854414195e-05\n",
            "Epoch 1, Loss: 2.1598872990580276e-05\n",
            "Epoch 1, Loss: 2.864210728148464e-05\n",
            "Epoch 1, Loss: 2.1620233383146115e-05\n",
            "Epoch 1, Loss: 3.298610681667924e-05\n",
            "Epoch 1, Loss: 2.2530164642375894e-05\n",
            "Epoch 1, Loss: 2.1425968952826224e-05\n",
            "Epoch 1, Loss: 2.1265712348395027e-05\n",
            "Epoch 1, Loss: 2.539710476412438e-05\n",
            "Epoch 1, Loss: 2.0264447812223807e-05\n",
            "Epoch 1, Loss: 2.244035931653343e-05\n",
            "Epoch 1, Loss: 2.3455064365407452e-05\n",
            "Epoch 1, Loss: 2.4228855181718245e-05\n",
            "Epoch 1, Loss: 2.6269724912708625e-05\n",
            "Epoch 1, Loss: 2.3951548428158276e-05\n",
            "Epoch 1, Loss: 2.5877132429741323e-05\n",
            "Epoch 1, Loss: 2.044719258265104e-05\n",
            "Epoch 1, Loss: 2.178116665163543e-05\n",
            "Epoch 1, Loss: 2.5096829631365836e-05\n",
            "Epoch 1, Loss: 2.3741868062643334e-05\n",
            "Epoch 1, Loss: 2.322934233234264e-05\n",
            "Epoch 1, Loss: 2.4741839297348633e-05\n",
            "Epoch 1, Loss: 2.6457626518094912e-05\n",
            "Epoch 1, Loss: 2.2362195522873662e-05\n",
            "Epoch 1, Loss: 2.558069354563486e-05\n",
            "Epoch 1, Loss: 2.262559428345412e-05\n",
            "Epoch 1, Loss: 2.2093056031735614e-05\n",
            "Epoch 1, Loss: 2.7942232918576337e-05\n",
            "Epoch 1, Loss: 2.3826692995498888e-05\n",
            "Epoch 1, Loss: 2.5083980290219188e-05\n",
            "Epoch 1, Loss: 2.188942198699806e-05\n",
            "Epoch 1, Loss: 2.879101703001652e-05\n",
            "Epoch 1, Loss: 2.052640229521785e-05\n",
            "Epoch 1, Loss: 2.2458263629232533e-05\n",
            "Epoch 1, Loss: 2.5606761482777074e-05\n",
            "Epoch 1, Loss: 2.3078111553331837e-05\n",
            "Epoch 1, Loss: 2.1025894966442138e-05\n",
            "Epoch 1, Loss: 2.881582076952327e-05\n",
            "Epoch 1, Loss: 1.9097962649539113e-05\n",
            "Epoch 1, Loss: 2.1403362552518956e-05\n",
            "Epoch 1, Loss: 2.844208756869193e-05\n",
            "Epoch 1, Loss: 2.4424694856861606e-05\n",
            "Epoch 1, Loss: 2.1571628167293966e-05\n",
            "Epoch 1, Loss: 2.5185172489727847e-05\n",
            "Epoch 1, Loss: 2.6596431780490093e-05\n",
            "Epoch 1, Loss: 2.1774341803393327e-05\n",
            "Epoch 1, Loss: 2.4263470550067723e-05\n",
            "Epoch 1, Loss: 2.3172644432634115e-05\n",
            "Epoch 1, Loss: 2.2450190954259597e-05\n",
            "Epoch 1, Loss: 2.2032170818420127e-05\n",
            "Epoch 1, Loss: 2.091499300149735e-05\n",
            "Epoch 1, Loss: 1.9457738744677044e-05\n",
            "Epoch 1, Loss: 2.797943125187885e-05\n",
            "Epoch 1, Loss: 2.143534948118031e-05\n",
            "Epoch 1, Loss: 1.951615558937192e-05\n",
            "Epoch 1, Loss: 2.6561114282230847e-05\n",
            "Epoch 1, Loss: 2.445067002554424e-05\n",
            "Epoch 1, Loss: 2.5729565095389262e-05\n",
            "Epoch 1, Loss: 2.4869543267413974e-05\n",
            "Epoch 1, Loss: 2.4215167286456563e-05\n",
            "Epoch 1, Loss: 3.0424884243984707e-05\n",
            "Epoch 1, Loss: 2.7747661079047248e-05\n",
            "Epoch 1, Loss: 2.0740790205309168e-05\n",
            "Epoch 1, Loss: 2.0362263967399485e-05\n",
            "Epoch 1, Loss: 2.2665486540063284e-05\n",
            "Epoch 1, Loss: 2.016947473748587e-05\n",
            "Epoch 1, Loss: 2.4432465579593554e-05\n",
            "Epoch 1, Loss: 2.1994870621711016e-05\n",
            "Epoch 1, Loss: 2.619772385514807e-05\n",
            "Epoch 1, Loss: 2.5110915885306895e-05\n",
            "Epoch 1, Loss: 2.405902705504559e-05\n",
            "Epoch 1, Loss: 2.4518187274225056e-05\n",
            "Epoch 1, Loss: 1.970037010323722e-05\n",
            "Epoch 1, Loss: 1.851349043135997e-05\n",
            "Epoch 1, Loss: 2.2249210815061815e-05\n",
            "Epoch 1, Loss: 2.510856393200811e-05\n",
            "Epoch 1, Loss: 2.33615191973513e-05\n",
            "Epoch 1, Loss: 2.6647481718100607e-05\n",
            "Epoch 1, Loss: 2.3954040443641134e-05\n",
            "Epoch 1, Loss: 1.941576374520082e-05\n",
            "Epoch 1, Loss: 2.4843851861078292e-05\n",
            "Epoch 1, Loss: 2.106079045915976e-05\n",
            "Epoch 1, Loss: 2.347588088014163e-05\n",
            "Epoch 1, Loss: 2.1965121050016023e-05\n",
            "Epoch 1, Loss: 2.370044239796698e-05\n",
            "Epoch 1, Loss: 2.4897670300561003e-05\n",
            "Epoch 1, Loss: 1.9899878680007532e-05\n",
            "Epoch 1, Loss: 2.491672057658434e-05\n",
            "Epoch 1, Loss: 2.163114186259918e-05\n",
            "Epoch 1, Loss: 2.3778906324878335e-05\n",
            "Epoch 1, Loss: 2.1185242076171562e-05\n",
            "Epoch 1, Loss: 1.985426206374541e-05\n",
            "Epoch 1, Loss: 1.9183969925506972e-05\n",
            "Epoch 1, Loss: 2.1275935068842955e-05\n",
            "Epoch 1, Loss: 2.1982974431011826e-05\n",
            "Epoch 1, Loss: 2.1671616195817478e-05\n",
            "Epoch 1, Loss: 1.9858209270751104e-05\n",
            "Epoch 1, Loss: 3.069447848247364e-05\n",
            "Epoch 1, Loss: 1.7766789824236184e-05\n",
            "Epoch 1, Loss: 2.6264899133821018e-05\n",
            "Epoch 1, Loss: 2.6477515348233283e-05\n",
            "Epoch 1, Loss: 2.1737489078077488e-05\n",
            "Epoch 1, Loss: 2.2905771402292885e-05\n",
            "Epoch 1, Loss: 2.2914840883458965e-05\n",
            "Epoch 1, Loss: 2.176949055865407e-05\n",
            "Epoch 1, Loss: 2.3925025743665174e-05\n",
            "Epoch 1, Loss: 2.3536462322226726e-05\n",
            "Epoch 1, Loss: 2.4847249733284116e-05\n",
            "Epoch 1, Loss: 2.1797148292534985e-05\n",
            "Epoch 1, Loss: 2.6760882974485867e-05\n",
            "Epoch 1, Loss: 2.4239468984887935e-05\n",
            "Epoch 1, Loss: 2.746968311839737e-05\n",
            "Epoch 1, Loss: 1.9583781977416947e-05\n",
            "Epoch 1, Loss: 2.2985208488535136e-05\n",
            "Epoch 1, Loss: 2.2048145183362067e-05\n",
            "Epoch 1, Loss: 2.1544023184105754e-05\n",
            "Epoch 1, Loss: 2.1858102627447806e-05\n",
            "Epoch 1, Loss: 1.9813744074781425e-05\n",
            "Epoch 1, Loss: 2.2799633370595984e-05\n",
            "Epoch 1, Loss: 2.403518919891212e-05\n",
            "Epoch 1, Loss: 1.9839597371174023e-05\n",
            "Epoch 1, Loss: 1.9610994058893993e-05\n",
            "Epoch 1, Loss: 2.265302464365959e-05\n",
            "Epoch 1, Loss: 2.0452220269362442e-05\n",
            "Epoch 1, Loss: 2.344929271203e-05\n",
            "Epoch 1, Loss: 2.4802915504551493e-05\n",
            "Epoch 1, Loss: 2.5048475436051376e-05\n",
            "Epoch 1, Loss: 2.273907193739433e-05\n",
            "Epoch 1, Loss: 1.9655793948913924e-05\n",
            "Epoch 1, Loss: 2.0591340216924436e-05\n",
            "Epoch 1, Loss: 1.861902273958549e-05\n",
            "Epoch 1, Loss: 2.9858900234103203e-05\n",
            "Epoch 1, Loss: 2.238986962765921e-05\n",
            "Epoch 1, Loss: 2.4248358386103064e-05\n",
            "Epoch 1, Loss: 2.2690262994728982e-05\n",
            "Epoch 1, Loss: 2.205181408498902e-05\n",
            "Epoch 1, Loss: 2.3901875465526246e-05\n",
            "Epoch 1, Loss: 2.7141963073518127e-05\n",
            "Epoch 1, Loss: 2.0489003873080947e-05\n",
            "Epoch 1, Loss: 2.4988825316540897e-05\n",
            "Epoch 1, Loss: 2.4727149138925597e-05\n",
            "Epoch 1, Loss: 1.91021117643686e-05\n",
            "Epoch 1, Loss: 1.7386586478096433e-05\n",
            "Epoch 1, Loss: 2.3689091904088855e-05\n",
            "Epoch 1, Loss: 2.5570330763002858e-05\n",
            "Epoch 1, Loss: 1.9641944163595326e-05\n",
            "Epoch 1, Loss: 2.2067115423851646e-05\n",
            "Epoch 1, Loss: 2.1350986571633257e-05\n",
            "Epoch 1, Loss: 2.1281264707795344e-05\n",
            "Epoch 1, Loss: 2.520283669582568e-05\n",
            "Epoch 1, Loss: 2.4345528800040483e-05\n",
            "Epoch 1, Loss: 2.1353633201215416e-05\n",
            "Epoch 1, Loss: 1.9222081391490065e-05\n",
            "Epoch 1, Loss: 2.070764276140835e-05\n",
            "Epoch 1, Loss: 2.238876186311245e-05\n",
            "Epoch 1, Loss: 2.2936716050026007e-05\n",
            "Epoch 1, Loss: 2.1884878151468e-05\n",
            "Epoch 1, Loss: 2.3842711016186513e-05\n",
            "Epoch 1, Loss: 2.2103553419583477e-05\n",
            "Epoch 1, Loss: 2.1924590328126214e-05\n",
            "Epoch 1, Loss: 1.9966808395111002e-05\n",
            "Epoch 1, Loss: 2.3079377569956705e-05\n",
            "Epoch 1, Loss: 2.0297837181715295e-05\n",
            "Epoch 1, Loss: 2.1261725123622455e-05\n",
            "Epoch 1, Loss: 2.130850225512404e-05\n",
            "Epoch 1, Loss: 2.1915486286161467e-05\n",
            "Epoch 1, Loss: 2.2256746888160706e-05\n",
            "Epoch 1, Loss: 2.774093263724353e-05\n",
            "Epoch 1, Loss: 2.4412756829406135e-05\n",
            "Epoch 1, Loss: 2.0624693206627853e-05\n",
            "Epoch 1, Loss: 2.5332841687486507e-05\n",
            "Epoch 1, Loss: 1.9995799448224716e-05\n",
            "Epoch 1, Loss: 2.371883238083683e-05\n",
            "Epoch 1, Loss: 2.4126677089952864e-05\n",
            "Epoch 1, Loss: 2.150273030565586e-05\n",
            "Epoch 1, Loss: 1.9129447537125088e-05\n",
            "Epoch 1, Loss: 2.189814767916687e-05\n",
            "Epoch 1, Loss: 2.315795427421108e-05\n",
            "Epoch 1, Loss: 1.918941779877059e-05\n",
            "Epoch 1, Loss: 2.0306881197029725e-05\n",
            "Epoch 1, Loss: 2.6103578420588747e-05\n",
            "Epoch 1, Loss: 1.9977962438133545e-05\n",
            "Epoch 1, Loss: 2.598570972622838e-05\n",
            "Epoch 1, Loss: 2.0139776097494178e-05\n",
            "Epoch 1, Loss: 2.03873569262214e-05\n",
            "Epoch 1, Loss: 1.9146271370118484e-05\n",
            "Epoch 1, Loss: 2.7695166863850318e-05\n",
            "Epoch 1, Loss: 2.2895341317052953e-05\n",
            "Epoch 1, Loss: 2.2833228285890073e-05\n",
            "Epoch 1, Loss: 2.495003900548909e-05\n",
            "Epoch 1, Loss: 1.9604151020757854e-05\n",
            "Epoch 1, Loss: 2.130364919139538e-05\n",
            "Epoch 1, Loss: 1.916263863677159e-05\n",
            "Epoch 1, Loss: 2.3773185603204183e-05\n",
            "Epoch 1, Loss: 2.8035759896738455e-05\n",
            "Epoch 1, Loss: 3.012300658156164e-05\n",
            "Epoch 1, Loss: 2.408899672445841e-05\n",
            "Epoch 1, Loss: 2.315942219865974e-05\n",
            "Epoch 1, Loss: 2.266589945065789e-05\n",
            "Epoch 1, Loss: 2.021643376792781e-05\n",
            "Epoch 1, Loss: 2.438071351207327e-05\n",
            "Epoch 1, Loss: 2.1759889932582155e-05\n",
            "Epoch 1, Loss: 2.0057312212884426e-05\n",
            "Epoch 1, Loss: 2.0214964024489745e-05\n",
            "Epoch 1, Loss: 2.0852108718827367e-05\n",
            "Epoch 1, Loss: 2.648300323926378e-05\n",
            "Epoch 1, Loss: 2.4313207177328877e-05\n",
            "Epoch 1, Loss: 2.3612408767803572e-05\n",
            "Epoch 1, Loss: 2.4208906324929558e-05\n",
            "Epoch 1, Loss: 2.4744394977460615e-05\n",
            "Epoch 1, Loss: 1.956737287400756e-05\n",
            "Epoch 1, Loss: 2.06420045287814e-05\n",
            "Epoch 1, Loss: 2.424514059384819e-05\n",
            "Epoch 1, Loss: 2.1966357962810434e-05\n",
            "Epoch 1, Loss: 2.0728683011839166e-05\n",
            "Epoch 1, Loss: 2.0104203940718435e-05\n",
            "Epoch 1, Loss: 1.8731867385213263e-05\n",
            "Epoch 1, Loss: 2.2574000468011945e-05\n",
            "Epoch 1, Loss: 2.065338230750058e-05\n",
            "Epoch 1, Loss: 2.0937501176376827e-05\n",
            "Epoch 1, Loss: 1.741778578434605e-05\n",
            "Epoch 1, Loss: 1.7622687664697878e-05\n",
            "Epoch 1, Loss: 2.2884030840941705e-05\n",
            "Epoch 1, Loss: 1.67145517480094e-05\n",
            "Epoch 1, Loss: 2.2735332095180638e-05\n",
            "Epoch 1, Loss: 1.9055103621212766e-05\n",
            "Epoch 1, Loss: 2.0518726159934886e-05\n",
            "Epoch 1, Loss: 2.0926772776874714e-05\n",
            "Epoch 1, Loss: 2.4417649910901673e-05\n",
            "Epoch 1, Loss: 2.0189370843581855e-05\n",
            "Epoch 1, Loss: 2.9539014576585032e-05\n",
            "Epoch 1, Loss: 2.8567812478286214e-05\n",
            "Epoch 1, Loss: 2.036298428720329e-05\n",
            "Epoch 1, Loss: 2.2009207896189764e-05\n",
            "Epoch 1, Loss: 2.093572766170837e-05\n",
            "Epoch 1, Loss: 1.8625121811055578e-05\n",
            "Epoch 1, Loss: 2.5363326130900532e-05\n",
            "Epoch 1, Loss: 2.2409063603845425e-05\n",
            "Epoch 1, Loss: 2.1618187020067126e-05\n",
            "Epoch 1, Loss: 1.9123961465083994e-05\n",
            "Epoch 1, Loss: 2.294819751114119e-05\n",
            "Epoch 1, Loss: 2.514322113711387e-05\n",
            "Epoch 1, Loss: 2.2220996470423415e-05\n",
            "Epoch 1, Loss: 2.0984258298994973e-05\n",
            "Epoch 1, Loss: 1.9444227291387506e-05\n",
            "Epoch 1, Loss: 2.317110192961991e-05\n",
            "Epoch 1, Loss: 2.0396802938194014e-05\n",
            "Epoch 1, Loss: 1.9578414139687084e-05\n",
            "Epoch 1, Loss: 1.9661103578982875e-05\n",
            "Epoch 1, Loss: 1.8607888705446385e-05\n",
            "Epoch 1, Loss: 2.188599501096178e-05\n",
            "Epoch 1, Loss: 2.0258445147192106e-05\n",
            "Epoch 1, Loss: 2.2523716324940324e-05\n",
            "Epoch 1, Loss: 1.7599297279957682e-05\n",
            "Epoch 1, Loss: 1.9141902157571167e-05\n",
            "Epoch 1, Loss: 1.8295164409209974e-05\n",
            "Epoch 1, Loss: 2.281131673953496e-05\n",
            "Epoch 1, Loss: 2.9761074983980507e-05\n",
            "Epoch 1, Loss: 2.0114221115363762e-05\n",
            "Epoch 1, Loss: 2.1983873011777177e-05\n",
            "Epoch 1, Loss: 1.770128437783569e-05\n",
            "Epoch 1, Loss: 2.160669828299433e-05\n",
            "Epoch 1, Loss: 2.5096464014495723e-05\n",
            "Epoch 1, Loss: 1.571923894516658e-05\n",
            "Epoch 1, Loss: 1.9611616153270006e-05\n",
            "Epoch 1, Loss: 1.5731890016468242e-05\n",
            "Epoch 1, Loss: 2.5869434466585517e-05\n",
            "Epoch 1, Loss: 2.0833178496104665e-05\n",
            "Epoch 1, Loss: 2.0352214050944895e-05\n",
            "Epoch 1, Loss: 4.49041799583938e-05\n",
            "Epoch 1, Loss: 2.0162326109129936e-05\n",
            "Epoch 1, Loss: 2.5012221158249304e-05\n",
            "Epoch 1, Loss: 2.9537861337303184e-05\n",
            "Epoch 1, Loss: 2.6841580620384775e-05\n",
            "Epoch 1, Loss: 2.3031923774397e-05\n",
            "Epoch 1, Loss: 2.5346957045258023e-05\n",
            "Epoch 1, Loss: 2.239156310679391e-05\n",
            "Epoch 1, Loss: 2.3492333639296703e-05\n",
            "Epoch 1, Loss: 2.3557155145681463e-05\n",
            "Epoch 1, Loss: 1.8838369214790873e-05\n",
            "Epoch 1, Loss: 2.3176293325377628e-05\n",
            "Epoch 1, Loss: 2.075362681352999e-05\n",
            "Epoch 1, Loss: 2.3502039766754024e-05\n",
            "Epoch 1, Loss: 2.849295560736209e-05\n",
            "Epoch 1, Loss: 2.5555107640684582e-05\n",
            "Epoch 1, Loss: 2.180837509513367e-05\n",
            "Epoch 1, Loss: 2.7422514904174022e-05\n",
            "Epoch 1, Loss: 2.924660475400742e-05\n",
            "Epoch 1, Loss: 2.015133577515371e-05\n",
            "Epoch 1, Loss: 2.36455616686726e-05\n",
            "Epoch 1, Loss: 2.40425652009435e-05\n",
            "Epoch 1, Loss: 2.57455394603312e-05\n",
            "Epoch 1, Loss: 1.746117413858883e-05\n",
            "Epoch 1, Loss: 2.4974582629511133e-05\n",
            "Epoch 1, Loss: 1.762846477504354e-05\n",
            "Epoch 1, Loss: 2.4135290004778653e-05\n",
            "Epoch 1, Loss: 1.8774850104819052e-05\n",
            "Epoch 1, Loss: 2.197746107412968e-05\n",
            "Epoch 1, Loss: 2.2667667508358136e-05\n",
            "Epoch 1, Loss: 2.0275434508221224e-05\n",
            "Epoch 1, Loss: 2.2063355572754517e-05\n",
            "Epoch 1, Loss: 3.562319034244865e-05\n",
            "Epoch 1, Loss: 1.8066151824314147e-05\n",
            "Epoch 1, Loss: 2.4214972654590383e-05\n",
            "Epoch 1, Loss: 2.880831016227603e-05\n",
            "Epoch 1, Loss: 2.487784695404116e-05\n",
            "Epoch 1, Loss: 2.4010270863072947e-05\n",
            "Epoch 1, Loss: 2.1556623323704116e-05\n",
            "Epoch 1, Loss: 2.5600715161999688e-05\n",
            "Epoch 1, Loss: 2.1289764845278114e-05\n",
            "Epoch 1, Loss: 2.0951716578565538e-05\n",
            "Epoch 1, Loss: 2.459039205859881e-05\n",
            "Epoch 1, Loss: 2.272380697831977e-05\n",
            "Epoch 1, Loss: 2.1318754079402424e-05\n",
            "Epoch 1, Loss: 2.3606804461451247e-05\n",
            "Epoch 1, Loss: 2.8393913453328423e-05\n",
            "Epoch 1, Loss: 2.3326936570811085e-05\n",
            "Epoch 1, Loss: 1.911655635922216e-05\n",
            "Epoch 1, Loss: 2.1258971173665486e-05\n",
            "Epoch 1, Loss: 2.1119714801898226e-05\n",
            "Epoch 1, Loss: 2.603740904305596e-05\n",
            "Epoch 1, Loss: 2.4442511858069338e-05\n",
            "Epoch 1, Loss: 2.383698483754415e-05\n",
            "Epoch 1, Loss: 1.658461769693531e-05\n",
            "Epoch 1, Loss: 2.050356488325633e-05\n",
            "Epoch 1, Loss: 2.4336504793609492e-05\n",
            "Epoch 1, Loss: 2.895118268497754e-05\n",
            "Epoch 1, Loss: 2.1730336811742745e-05\n",
            "Epoch 1, Loss: 2.3257656721398234e-05\n",
            "Epoch 1, Loss: 2.2285006707534194e-05\n",
            "Epoch 1, Loss: 2.3661596060264856e-05\n",
            "Epoch 1, Loss: 2.140412289008964e-05\n",
            "Epoch 1, Loss: 2.1925512555753812e-05\n",
            "Epoch 1, Loss: 2.0272655092412606e-05\n",
            "Epoch 1, Loss: 2.054308060905896e-05\n",
            "Epoch 1, Loss: 1.7282804037677124e-05\n",
            "Epoch 1, Loss: 1.9798793800873682e-05\n",
            "Epoch 1, Loss: 2.085138658003416e-05\n",
            "Epoch 1, Loss: 2.099021185131278e-05\n",
            "Epoch 1, Loss: 1.8987097064382397e-05\n",
            "Epoch 1, Loss: 2.032109296123963e-05\n",
            "Epoch 1, Loss: 2.1512783860089257e-05\n",
            "Epoch 1, Loss: 2.3548655008198693e-05\n",
            "Epoch 1, Loss: 1.769931986927986e-05\n",
            "Epoch 1, Loss: 2.047797715931665e-05\n",
            "Epoch 1, Loss: 2.5356997866765596e-05\n",
            "Epoch 1, Loss: 2.018233499256894e-05\n",
            "Epoch 1, Loss: 2.4811990442685783e-05\n",
            "Epoch 1, Loss: 1.874944064184092e-05\n",
            "Epoch 1, Loss: 2.20988458750071e-05\n",
            "Epoch 1, Loss: 2.0282401237636805e-05\n",
            "Epoch 1, Loss: 2.5665556677267887e-05\n",
            "Epoch 1, Loss: 1.9861661712639034e-05\n",
            "Epoch 1, Loss: 1.944542964338325e-05\n",
            "Epoch 1, Loss: 2.2310976419248618e-05\n",
            "Epoch 1, Loss: 1.6266652892227285e-05\n",
            "Epoch 1, Loss: 1.94982931134291e-05\n",
            "Epoch 1, Loss: 2.5119565179920755e-05\n",
            "Epoch 1, Loss: 2.436670365568716e-05\n",
            "Epoch 1, Loss: 2.077749013551511e-05\n",
            "Epoch 1, Loss: 2.088956898660399e-05\n",
            "Epoch 1, Loss: 1.846519808168523e-05\n",
            "Epoch 1, Loss: 2.2201245883479714e-05\n",
            "Epoch 1, Loss: 2.6609128326526843e-05\n",
            "Epoch 1, Loss: 2.0111867343075573e-05\n",
            "Epoch 1, Loss: 2.0846038751187734e-05\n",
            "Epoch 1, Loss: 1.9188275473425165e-05\n",
            "Epoch 1, Loss: 2.133662928827107e-05\n",
            "Epoch 1, Loss: 1.983668153116014e-05\n",
            "Epoch 1, Loss: 2.8146661861683242e-05\n",
            "Epoch 1, Loss: 2.841296372935176e-05\n",
            "Epoch 1, Loss: 1.9405697457841597e-05\n",
            "Epoch 1, Loss: 1.958567554538604e-05\n",
            "Epoch 1, Loss: 2.0218263671267778e-05\n",
            "Epoch 1, Loss: 2.3301963665289804e-05\n",
            "Epoch 1, Loss: 2.295619560754858e-05\n",
            "Epoch 1, Loss: 1.911710569402203e-05\n",
            "Epoch 1, Loss: 1.7814814782468602e-05\n",
            "Epoch 1, Loss: 1.801038160920143e-05\n",
            "Epoch 1, Loss: 2.2551757865585387e-05\n",
            "Epoch 1, Loss: 1.886329846456647e-05\n",
            "Epoch 1, Loss: 1.9569164578570053e-05\n",
            "Epoch 1, Loss: 1.8306784113519825e-05\n",
            "Epoch 1, Loss: 2.2866897779749706e-05\n",
            "Epoch 1, Loss: 2.0677984139183536e-05\n",
            "Epoch 1, Loss: 1.9756427718675695e-05\n",
            "Epoch 1, Loss: 2.1582089175353758e-05\n",
            "Epoch 1, Loss: 1.9432603949098848e-05\n",
            "Epoch 1, Loss: 1.8692640878725797e-05\n",
            "Epoch 1, Loss: 1.695641731203068e-05\n",
            "Epoch 1, Loss: 1.7980948541662656e-05\n",
            "Epoch 1, Loss: 1.9480166884022765e-05\n",
            "Epoch 1, Loss: 2.297267747053411e-05\n",
            "Epoch 1, Loss: 2.2107778931967914e-05\n",
            "Epoch 1, Loss: 2.0452425815165043e-05\n",
            "Epoch 1, Loss: 2.3506252546212636e-05\n",
            "Epoch 1, Loss: 1.9061275452258997e-05\n",
            "Epoch 1, Loss: 1.968398646567948e-05\n",
            "Epoch 1, Loss: 1.7645992556936108e-05\n",
            "Epoch 1, Loss: 1.7796903193811886e-05\n",
            "Epoch 1, Loss: 1.7576723621459678e-05\n",
            "Epoch 1, Loss: 1.947785131051205e-05\n",
            "Epoch 1, Loss: 1.839346077758819e-05\n",
            "Epoch 1, Loss: 1.7115544324042276e-05\n",
            "Epoch 1, Loss: 2.230149220849853e-05\n",
            "Epoch 1, Loss: 2.0229672372806817e-05\n",
            "Epoch 1, Loss: 1.8358945453655906e-05\n",
            "Epoch 1, Loss: 1.990481177926995e-05\n",
            "Epoch 1, Loss: 1.9139648429700173e-05\n",
            "Epoch 1, Loss: 2.2244988940656185e-05\n",
            "Epoch 1, Loss: 2.1482204829226248e-05\n",
            "Epoch 1, Loss: 1.8443604858475737e-05\n",
            "Epoch 1, Loss: 1.9774828615481965e-05\n",
            "Epoch 1, Loss: 1.960543704626616e-05\n",
            "Epoch 1, Loss: 1.726818663883023e-05\n",
            "Epoch 1, Loss: 2.4807368390611373e-05\n",
            "Epoch 1, Loss: 2.005895112233702e-05\n",
            "Epoch 1, Loss: 1.964177135960199e-05\n",
            "Epoch 1, Loss: 2.0566909370245412e-05\n",
            "Epoch 1, Loss: 2.339344246138353e-05\n",
            "Epoch 1, Loss: 1.59749743033899e-05\n",
            "Epoch 1, Loss: 2.219554880866781e-05\n",
            "Epoch 1, Loss: 2.128567939507775e-05\n",
            "Epoch 1, Loss: 1.7662203390500508e-05\n",
            "Epoch 1, Loss: 1.9636769138742238e-05\n",
            "Epoch 1, Loss: 2.2838763470645063e-05\n",
            "Epoch 1, Loss: 4.116094714845531e-05\n",
            "Epoch 1, Loss: 2.5861743779387325e-05\n",
            "Epoch 1, Loss: 1.824679748096969e-05\n",
            "Epoch 1, Loss: 1.9366323613212444e-05\n",
            "Epoch 1, Loss: 2.631720417411998e-05\n",
            "Epoch 1, Loss: 2.15082909562625e-05\n",
            "Epoch 1, Loss: 1.8055863620247692e-05\n",
            "Epoch 1, Loss: 3.34543437929824e-05\n",
            "Epoch 1, Loss: 1.7090618712245487e-05\n",
            "Epoch 1, Loss: 1.9331237126607448e-05\n",
            "Epoch 1, Loss: 3.051996463909745e-05\n",
            "Epoch 1, Loss: 1.9836075807688758e-05\n",
            "Epoch 1, Loss: 2.2284242731984705e-05\n",
            "Epoch 1, Loss: 2.3947715817485005e-05\n",
            "Epoch 1, Loss: 2.12004979402991e-05\n",
            "Epoch 1, Loss: 2.380244950472843e-05\n",
            "Epoch 1, Loss: 1.9749619241338223e-05\n",
            "Epoch 1, Loss: 2.0763174688909203e-05\n",
            "Epoch 1, Loss: 2.2144924514577724e-05\n",
            "Epoch 1, Loss: 1.8688693671720102e-05\n",
            "Epoch 1, Loss: 2.020476313191466e-05\n",
            "Epoch 1, Loss: 2.2106436517788097e-05\n",
            "Epoch 1, Loss: 2.2891346816322766e-05\n",
            "Epoch 1, Loss: 1.8635024389368482e-05\n",
            "Epoch 1, Loss: 2.027779737545643e-05\n",
            "Epoch 1, Loss: 1.5512254321947694e-05\n",
            "Epoch 1, Loss: 1.688874363026116e-05\n",
            "Epoch 1, Loss: 1.8292430468136445e-05\n",
            "Epoch 1, Loss: 2.2413290935219266e-05\n",
            "Epoch 1, Loss: 1.741505548125133e-05\n",
            "Epoch 1, Loss: 1.8083752365782857e-05\n",
            "Epoch 1, Loss: 2.1644134903908707e-05\n",
            "Epoch 1, Loss: 1.632004205021076e-05\n",
            "Epoch 1, Loss: 1.939370486070402e-05\n",
            "Epoch 1, Loss: 1.92889929166995e-05\n",
            "Epoch 1, Loss: 1.993179648707155e-05\n",
            "Epoch 1, Loss: 2.1098163415445015e-05\n",
            "Epoch 1, Loss: 1.947011514857877e-05\n",
            "Epoch 1, Loss: 2.0373256120365113e-05\n",
            "Epoch 1, Loss: 2.0223325918777846e-05\n",
            "Epoch 1, Loss: 1.82052499440033e-05\n",
            "Epoch 1, Loss: 1.7970914996112697e-05\n",
            "Epoch 1, Loss: 2.017702536249999e-05\n",
            "Epoch 1, Loss: 1.829468055802863e-05\n",
            "Epoch 1, Loss: 1.66052850545384e-05\n",
            "Epoch 1, Loss: 1.7901502360473387e-05\n",
            "Epoch 1, Loss: 2.05952201213222e-05\n",
            "Epoch 1, Loss: 2.0496872821240686e-05\n",
            "Epoch 1, Loss: 1.7427848433726467e-05\n",
            "Epoch 1, Loss: 1.8077369531965815e-05\n",
            "Epoch 1, Loss: 1.8025024473899975e-05\n",
            "Epoch 1, Loss: 1.9471683117444627e-05\n",
            "Epoch 1, Loss: 1.9141223674523644e-05\n",
            "Epoch 1, Loss: 1.9429133317316882e-05\n",
            "Epoch 1, Loss: 1.9257253370597027e-05\n",
            "Epoch 1, Loss: 1.7974434740608558e-05\n",
            "Epoch 1, Loss: 2.165545265597757e-05\n",
            "Epoch 1, Loss: 2.0937257431796752e-05\n",
            "Epoch 1, Loss: 1.7687421859591268e-05\n",
            "Epoch 1, Loss: 1.6011348634492606e-05\n",
            "Epoch 1, Loss: 1.922670708154328e-05\n",
            "Epoch 1, Loss: 1.9502647774061188e-05\n",
            "Epoch 1, Loss: 1.8539265511208214e-05\n",
            "Epoch 1, Loss: 2.241504262201488e-05\n",
            "Epoch 1, Loss: 1.9417673684074543e-05\n",
            "Epoch 1, Loss: 1.949384568433743e-05\n",
            "Epoch 1, Loss: 1.7930673493538052e-05\n",
            "Epoch 1, Loss: 2.019767816818785e-05\n",
            "Epoch 1, Loss: 2.0198091078782454e-05\n",
            "Epoch 1, Loss: 1.9503631847328506e-05\n",
            "Epoch 1, Loss: 1.9699578842846677e-05\n",
            "Epoch 1, Loss: 2.135708746209275e-05\n",
            "Epoch 1, Loss: 2.056036828435026e-05\n",
            "Epoch 1, Loss: 1.9227427401347086e-05\n",
            "Epoch 1, Loss: 2.6452687961864285e-05\n",
            "Epoch 1, Loss: 2.1358971935114823e-05\n",
            "Epoch 1, Loss: 2.739650517469272e-05\n",
            "Epoch 1, Loss: 2.599248182377778e-05\n",
            "Epoch 1, Loss: 1.9867211449309252e-05\n",
            "Epoch 1, Loss: 1.8063970856019296e-05\n",
            "Epoch 1, Loss: 2.0037370632053353e-05\n",
            "Epoch 1, Loss: 1.8999555322807282e-05\n",
            "Epoch 1, Loss: 1.5919657016638666e-05\n",
            "Epoch 1, Loss: 2.181813215429429e-05\n",
            "Epoch 1, Loss: 1.6194528143387288e-05\n",
            "Epoch 1, Loss: 1.7745007426128723e-05\n",
            "Epoch 1, Loss: 1.9051618437515572e-05\n",
            "Epoch 1, Loss: 1.6146093912539072e-05\n",
            "Epoch 1, Loss: 1.774235897755716e-05\n",
            "Epoch 1, Loss: 1.745054942148272e-05\n",
            "Epoch 1, Loss: 1.891248393803835e-05\n",
            "Epoch 1, Loss: 1.7800084606278688e-05\n",
            "Epoch 1, Loss: 2.118447082466446e-05\n",
            "Epoch 1, Loss: 1.825012259359937e-05\n",
            "Epoch 1, Loss: 2.336694706173148e-05\n",
            "Epoch 1, Loss: 2.035248326137662e-05\n",
            "Epoch 1, Loss: 1.7701320757623762e-05\n",
            "Epoch 1, Loss: 1.9939314370276406e-05\n",
            "Epoch 1, Loss: 1.894808156066574e-05\n",
            "Epoch 1, Loss: 2.1241745344013907e-05\n",
            "Epoch 1, Loss: 1.6238700482062995e-05\n",
            "Epoch 1, Loss: 1.803157829272095e-05\n",
            "Epoch 1, Loss: 1.9110486391582526e-05\n",
            "Epoch 1, Loss: 1.8115064449375495e-05\n",
            "Epoch 1, Loss: 2.5053635908989236e-05\n",
            "Epoch 1, Loss: 1.9103674276266247e-05\n",
            "Epoch 1, Loss: 1.9232766135246493e-05\n",
            "Epoch 1, Loss: 1.6583917386014946e-05\n",
            "Epoch 1, Loss: 1.882877950265538e-05\n",
            "Epoch 1, Loss: 2.437137663946487e-05\n",
            "Epoch 1, Loss: 1.684386734268628e-05\n",
            "Epoch 1, Loss: 2.1587138689938e-05\n",
            "Epoch 1, Loss: 1.7983749785344116e-05\n",
            "Epoch 1, Loss: 1.7001264495775104e-05\n",
            "Epoch 1, Loss: 1.8265363905811682e-05\n",
            "Epoch 1, Loss: 1.7482378098065965e-05\n",
            "Epoch 1, Loss: 1.7196543922182173e-05\n",
            "Epoch 1, Loss: 1.8196993551100604e-05\n",
            "Epoch 1, Loss: 1.8675327737582847e-05\n",
            "Epoch 1, Loss: 1.5531570170423947e-05\n",
            "Epoch 1, Loss: 1.6794745533843525e-05\n",
            "Epoch 1, Loss: 1.5618572433595546e-05\n",
            "Epoch 1, Loss: 1.600357427378185e-05\n",
            "Epoch 1, Loss: 1.7228172509931028e-05\n",
            "Epoch 1, Loss: 1.7641108570387587e-05\n",
            "Epoch 1, Loss: 1.4948382158763707e-05\n",
            "Epoch 1, Loss: 1.9775008695432916e-05\n",
            "Epoch 1, Loss: 1.560389318910893e-05\n",
            "Epoch 1, Loss: 1.814895949792117e-05\n",
            "Epoch 1, Loss: 2.0248560758773237e-05\n",
            "Epoch 1, Loss: 1.675719795457553e-05\n",
            "Epoch 1, Loss: 1.6014811990316957e-05\n",
            "Epoch 1, Loss: 1.7045904314727522e-05\n",
            "Epoch 1, Loss: 1.7367443433613516e-05\n",
            "Epoch 1, Loss: 1.670124038355425e-05\n",
            "Epoch 1, Loss: 1.828624226618558e-05\n",
            "Epoch 1, Loss: 2.0639366994146258e-05\n",
            "Epoch 1, Loss: 1.8351916878600605e-05\n",
            "Epoch 1, Loss: 1.570901440572925e-05\n",
            "Epoch 1, Loss: 1.7562553694006056e-05\n",
            "Epoch 1, Loss: 1.4728474525327329e-05\n",
            "Epoch 1, Loss: 1.683422306086868e-05\n",
            "Epoch 1, Loss: 1.8558574083726853e-05\n",
            "Epoch 1, Loss: 2.001242683036253e-05\n",
            "Epoch 1, Loss: 1.7061382095562294e-05\n",
            "Epoch 1, Loss: 1.8447430193191394e-05\n",
            "Epoch 1, Loss: 1.5580424587824382e-05\n",
            "Epoch 1, Loss: 1.7338663383270614e-05\n",
            "Epoch 1, Loss: 2.068256253551226e-05\n",
            "Epoch 1, Loss: 1.8788357920129783e-05\n",
            "Epoch 1, Loss: 1.9176657588104717e-05\n",
            "Epoch 1, Loss: 1.7990863852901384e-05\n",
            "Epoch 1, Loss: 2.065340959234163e-05\n",
            "Epoch 1, Loss: 1.6749640053603798e-05\n",
            "Epoch 1, Loss: 2.096153548336588e-05\n",
            "Epoch 1, Loss: 1.9088734916294925e-05\n",
            "Epoch 1, Loss: 1.9679875549627468e-05\n",
            "Epoch 1, Loss: 1.9136479750159197e-05\n",
            "Epoch 1, Loss: 2.1920985091128387e-05\n",
            "Epoch 1, Loss: 1.786626125976909e-05\n",
            "Epoch 1, Loss: 1.5492792954319157e-05\n",
            "Epoch 1, Loss: 1.5637388059985824e-05\n",
            "Epoch 1, Loss: 1.8739336155704223e-05\n",
            "Epoch 1, Loss: 1.6683836292941123e-05\n",
            "Epoch 1, Loss: 1.7034773918567225e-05\n",
            "Epoch 1, Loss: 1.588077975611668e-05\n",
            "Epoch 1, Loss: 1.7239730368601158e-05\n",
            "Epoch 1, Loss: 1.849497675721068e-05\n",
            "Epoch 1, Loss: 2.4427983589703217e-05\n",
            "Epoch 1, Loss: 1.8506896594772115e-05\n",
            "Epoch 1, Loss: 1.62147462106077e-05\n",
            "Epoch 1, Loss: 1.950135629158467e-05\n",
            "Epoch 1, Loss: 1.7238007785636e-05\n",
            "Epoch 1, Loss: 1.678024091233965e-05\n",
            "Epoch 1, Loss: 1.3120657968102023e-05\n",
            "Epoch 1, Loss: 1.6101039364002645e-05\n",
            "Epoch 1, Loss: 1.7314994693151675e-05\n",
            "Epoch 1, Loss: 1.709322714305017e-05\n",
            "Epoch 1, Loss: 1.750133560562972e-05\n",
            "Epoch 1, Loss: 1.6469817637698725e-05\n",
            "Epoch 1, Loss: 1.5972387700458057e-05\n",
            "Epoch 1, Loss: 1.7160837160190567e-05\n",
            "Epoch 1, Loss: 1.8281913071405143e-05\n",
            "Epoch 1, Loss: 1.5221937246678863e-05\n",
            "Epoch 1, Loss: 1.5667823390685953e-05\n",
            "Epoch 1, Loss: 1.453837649023626e-05\n",
            "Epoch 1, Loss: 1.95945303858025e-05\n",
            "Epoch 1, Loss: 1.8353563064010814e-05\n",
            "Epoch 1, Loss: 1.5312380128307268e-05\n",
            "Epoch 1, Loss: 1.7882495740195736e-05\n",
            "Epoch 1, Loss: 1.8300243027624674e-05\n",
            "Epoch 1, Loss: 1.7472184481448494e-05\n",
            "Epoch 1, Loss: 1.6235806469921954e-05\n",
            "Epoch 1, Loss: 2.0304969439166598e-05\n",
            "Epoch 1, Loss: 1.5951369277900085e-05\n",
            "Epoch 1, Loss: 1.7911172108142637e-05\n",
            "Epoch 1, Loss: 1.6408395822509192e-05\n",
            "Epoch 1, Loss: 1.9670609617605805e-05\n",
            "Epoch 1, Loss: 1.981212517421227e-05\n",
            "Epoch 1, Loss: 1.8106251445715316e-05\n",
            "Epoch 1, Loss: 1.4351169738802128e-05\n",
            "Epoch 1, Loss: 1.7099473552661948e-05\n",
            "Epoch 1, Loss: 1.6587924619670957e-05\n",
            "Epoch 1, Loss: 1.9597178834374063e-05\n",
            "Epoch 1, Loss: 1.757936115609482e-05\n",
            "Epoch 1, Loss: 1.8759688828140497e-05\n",
            "Epoch 1, Loss: 1.8486154658603482e-05\n",
            "Epoch 1, Loss: 2.127009975083638e-05\n",
            "Epoch 1, Loss: 1.6642527043586597e-05\n",
            "Epoch 1, Loss: 1.7009633666020818e-05\n",
            "Epoch 1, Loss: 1.653981780691538e-05\n",
            "Epoch 1, Loss: 2.261032750539016e-05\n",
            "Epoch 1, Loss: 1.6236603187280707e-05\n",
            "Epoch 1, Loss: 2.495763146725949e-05\n",
            "Epoch 1, Loss: 2.1225267119007185e-05\n",
            "Epoch 1, Loss: 2.0703300833702087e-05\n",
            "Epoch 1, Loss: 1.8018288756138645e-05\n",
            "Epoch 1, Loss: 1.773741860233713e-05\n",
            "Epoch 1, Loss: 1.897625952551607e-05\n",
            "Epoch 1, Loss: 1.6919972040341236e-05\n",
            "Epoch 1, Loss: 1.640644586586859e-05\n",
            "Epoch 1, Loss: 1.7616093828110024e-05\n",
            "Epoch 1, Loss: 1.8509785149944946e-05\n",
            "Epoch 1, Loss: 2.0221437807776965e-05\n",
            "Epoch 1, Loss: 1.6052679711719975e-05\n",
            "Epoch 1, Loss: 1.7101498087868094e-05\n",
            "Epoch 1, Loss: 1.5784022252773866e-05\n",
            "Epoch 1, Loss: 1.6712912838556804e-05\n",
            "Epoch 1, Loss: 1.8073767932946794e-05\n",
            "Epoch 1, Loss: 1.916934888868127e-05\n",
            "Epoch 1, Loss: 1.7123440557043068e-05\n",
            "Epoch 1, Loss: 1.8002923752646893e-05\n",
            "Epoch 1, Loss: 1.6169442460522987e-05\n",
            "Epoch 1, Loss: 2.1500281945918687e-05\n",
            "Epoch 1, Loss: 1.855761365732178e-05\n",
            "Epoch 1, Loss: 2.0876628695987165e-05\n",
            "Epoch 1, Loss: 1.626662015041802e-05\n",
            "Epoch 1, Loss: 1.6708723705960438e-05\n",
            "Epoch 1, Loss: 1.4623242350353394e-05\n",
            "Epoch 1, Loss: 1.7285270587308332e-05\n",
            "Epoch 1, Loss: 1.672627877269406e-05\n",
            "Epoch 1, Loss: 1.7678314179647714e-05\n",
            "Epoch 1, Loss: 1.4953669051465113e-05\n",
            "Epoch 1, Loss: 1.619924296392128e-05\n",
            "Epoch 1, Loss: 2.2638627342530526e-05\n",
            "Epoch 1, Loss: 1.71945575857535e-05\n",
            "Epoch 1, Loss: 1.7154690794995986e-05\n",
            "Epoch 1, Loss: 1.8718359569902532e-05\n",
            "Epoch 1, Loss: 1.5224241906253155e-05\n",
            "Epoch 1, Loss: 1.9523613445926458e-05\n",
            "Epoch 1, Loss: 2.1488360289367847e-05\n",
            "Epoch 1, Loss: 1.678333865129389e-05\n",
            "Epoch 1, Loss: 1.6060614143498242e-05\n",
            "Epoch 1, Loss: 1.605584293429274e-05\n",
            "Epoch 1, Loss: 1.502166469435906e-05\n",
            "Epoch 1, Loss: 1.4894503692630678e-05\n",
            "Epoch 1, Loss: 1.868857907538768e-05\n",
            "Epoch 1, Loss: 1.6459223843412474e-05\n",
            "Epoch 1, Loss: 1.895460081868805e-05\n",
            "Epoch 1, Loss: 1.845515907916706e-05\n",
            "Epoch 1, Loss: 1.5152917512750719e-05\n",
            "Epoch 1, Loss: 1.7095833754865453e-05\n",
            "Epoch 1, Loss: 1.90296250366373e-05\n",
            "Epoch 1, Loss: 1.6263958968920633e-05\n",
            "Epoch 1, Loss: 1.4911170183040667e-05\n",
            "Epoch 1, Loss: 1.8254720998811536e-05\n",
            "Epoch 1, Loss: 1.893347143777646e-05\n",
            "Epoch 1, Loss: 1.9801318558165804e-05\n",
            "Epoch 1, Loss: 1.4020072740095202e-05\n",
            "Epoch 1, Loss: 1.6543648598599248e-05\n",
            "Epoch 1, Loss: 1.835101647884585e-05\n",
            "Epoch 1, Loss: 1.7988821127801202e-05\n",
            "Epoch 1, Loss: 1.54538793140091e-05\n",
            "Epoch 1, Loss: 1.8440407075104304e-05\n",
            "Epoch 1, Loss: 2.067850437015295e-05\n",
            "Epoch 1, Loss: 1.604186400072649e-05\n",
            "Epoch 1, Loss: 1.5139607057790272e-05\n",
            "Epoch 1, Loss: 1.6023450370994397e-05\n",
            "Epoch 1, Loss: 1.743664688547142e-05\n",
            "Epoch 1, Loss: 1.675205749052111e-05\n",
            "Epoch 1, Loss: 1.7157233742182143e-05\n",
            "Epoch 1, Loss: 1.5997393347788602e-05\n",
            "Epoch 1, Loss: 1.4976087186369114e-05\n",
            "Epoch 1, Loss: 1.8051781808026135e-05\n",
            "Epoch 1, Loss: 1.5397934475913644e-05\n",
            "Epoch 1, Loss: 1.5150407307373825e-05\n",
            "Epoch 1, Loss: 1.6291973224724643e-05\n",
            "Epoch 1, Loss: 1.424806032446213e-05\n",
            "Epoch 1, Loss: 1.939101639436558e-05\n",
            "Epoch 1, Loss: 1.7774829757399857e-05\n",
            "Epoch 1, Loss: 1.8343087504035793e-05\n",
            "Epoch 1, Loss: 1.7324873624602333e-05\n",
            "Epoch 1, Loss: 2.165362639061641e-05\n",
            "Epoch 1, Loss: 1.7906639186549e-05\n",
            "Epoch 1, Loss: 1.794720083125867e-05\n",
            "Epoch 1, Loss: 1.679052184044849e-05\n",
            "Epoch 1, Loss: 1.6000158211681992e-05\n",
            "Epoch 1, Loss: 1.91961426025955e-05\n",
            "Epoch 1, Loss: 1.8258429918205366e-05\n",
            "Epoch 1, Loss: 1.933291605382692e-05\n",
            "Epoch 1, Loss: 1.9390572560951114e-05\n",
            "Epoch 1, Loss: 1.8643504517967813e-05\n",
            "Epoch 1, Loss: 1.3353968824958429e-05\n",
            "Epoch 1, Loss: 1.6190771930268966e-05\n",
            "Epoch 1, Loss: 1.584039637236856e-05\n",
            "Epoch 1, Loss: 1.8945291230920702e-05\n",
            "Epoch 1, Loss: 1.692639671091456e-05\n",
            "Epoch 1, Loss: 1.7280122847296298e-05\n",
            "Epoch 1, Loss: 2.1202860807534307e-05\n",
            "Epoch 1, Loss: 1.7585447494639084e-05\n",
            "Epoch 1, Loss: 1.5375957445940003e-05\n",
            "Epoch 1, Loss: 2.1831092453794554e-05\n",
            "Epoch 1, Loss: 1.612044798093848e-05\n",
            "Epoch 1, Loss: 1.2874729691247921e-05\n",
            "Epoch 1, Loss: 1.400618475599913e-05\n",
            "Epoch 1, Loss: 1.771885945345275e-05\n",
            "Epoch 1, Loss: 1.4265327990869991e-05\n",
            "Epoch 1, Loss: 1.634079308132641e-05\n",
            "Epoch 1, Loss: 1.5446592442458495e-05\n",
            "Epoch 1, Loss: 1.6294537999783643e-05\n",
            "Epoch 1, Loss: 1.6032412531785667e-05\n",
            "Epoch 1, Loss: 1.6390524251619354e-05\n",
            "Epoch 1, Loss: 1.58487782755401e-05\n",
            "Epoch 1, Loss: 1.2787106243195012e-05\n",
            "Epoch 1, Loss: 1.948082172020804e-05\n",
            "Epoch 1, Loss: 1.7028891306836158e-05\n",
            "Epoch 1, Loss: 1.919416718010325e-05\n",
            "Epoch 1, Loss: 1.4662543435406405e-05\n",
            "Epoch 1, Loss: 1.776491444616113e-05\n",
            "Epoch 1, Loss: 2.0171230062260292e-05\n",
            "Epoch 1, Loss: 1.779483318387065e-05\n",
            "Epoch 1, Loss: 2.542086258472409e-05\n",
            "Epoch 1, Loss: 2.0296365619287826e-05\n",
            "Epoch 1, Loss: 2.162150303774979e-05\n",
            "Epoch 1, Loss: 1.8460295905242674e-05\n",
            "Epoch 1, Loss: 1.729098403302487e-05\n",
            "Epoch 1, Loss: 1.769588197930716e-05\n",
            "Epoch 1, Loss: 1.5526706192758866e-05\n",
            "Epoch 1, Loss: 1.4448656656895764e-05\n",
            "Epoch 1, Loss: 1.8203805666416883e-05\n",
            "Epoch 1, Loss: 2.219023917859886e-05\n",
            "Epoch 1, Loss: 1.59931860252982e-05\n",
            "Epoch 1, Loss: 1.936268927238416e-05\n",
            "Epoch 1, Loss: 1.760904342518188e-05\n",
            "Epoch 1, Loss: 1.5550278476439416e-05\n",
            "Epoch 1, Loss: 1.4175558135320898e-05\n",
            "Epoch 1, Loss: 1.7899275917443447e-05\n",
            "Epoch 1, Loss: 1.9244569557486102e-05\n",
            "Epoch 1, Loss: 1.8300801457371563e-05\n",
            "Epoch 1, Loss: 1.6168178262887523e-05\n",
            "Epoch 1, Loss: 1.6467236491735093e-05\n",
            "Epoch 1, Loss: 1.6324614989571273e-05\n",
            "Epoch 1, Loss: 1.777794022927992e-05\n",
            "Epoch 1, Loss: 1.7457881767768413e-05\n",
            "Epoch 1, Loss: 1.653631989029236e-05\n",
            "Epoch 1, Loss: 2.339895763725508e-05\n",
            "Epoch 1, Loss: 1.7065574866137467e-05\n",
            "Epoch 1, Loss: 1.6410514945164323e-05\n",
            "Epoch 1, Loss: 2.430401582387276e-05\n",
            "Epoch 1, Loss: 2.2242109480430372e-05\n",
            "Epoch 1, Loss: 1.6312333173118532e-05\n",
            "Epoch 1, Loss: 1.992528086702805e-05\n",
            "Epoch 1, Loss: 1.779519152478315e-05\n",
            "Epoch 1, Loss: 1.5473560779355466e-05\n",
            "Epoch 1, Loss: 2.263297574245371e-05\n",
            "Epoch 1, Loss: 1.6698539184289984e-05\n",
            "Epoch 1, Loss: 1.9036006051464938e-05\n",
            "Epoch 1, Loss: 2.2912461645319127e-05\n",
            "Epoch 1, Loss: 1.992352190427482e-05\n",
            "Epoch 1, Loss: 2.0727029550471343e-05\n",
            "Epoch 1, Loss: 1.6730751667637378e-05\n",
            "Epoch 1, Loss: 1.4152557923807763e-05\n",
            "Epoch 1, Loss: 1.6000494724721648e-05\n",
            "Epoch 1, Loss: 1.7358717741444707e-05\n",
            "Epoch 1, Loss: 1.7838854546425864e-05\n",
            "Epoch 1, Loss: 1.5467538105440326e-05\n",
            "Epoch 1, Loss: 1.8178401660406962e-05\n",
            "Epoch 1, Loss: 1.3932082765677478e-05\n",
            "Epoch 1, Loss: 1.4496161384158768e-05\n",
            "Epoch 1, Loss: 1.654302468523383e-05\n",
            "Epoch 1, Loss: 1.8079892470268533e-05\n",
            "Epoch 1, Loss: 1.5818983229110017e-05\n",
            "Epoch 1, Loss: 1.7231484889634885e-05\n",
            "Epoch 1, Loss: 1.7486408978584222e-05\n",
            "Epoch 1, Loss: 1.6022633644752204e-05\n",
            "Epoch 1, Loss: 1.48115132105886e-05\n",
            "Epoch 1, Loss: 1.5361656551249325e-05\n",
            "Epoch 1, Loss: 1.868913932412397e-05\n",
            "Epoch 1, Loss: 1.6834457710501738e-05\n",
            "Epoch 1, Loss: 1.760896157065872e-05\n",
            "Epoch 1, Loss: 1.778906698746141e-05\n",
            "Epoch 1, Loss: 1.9660255929920822e-05\n",
            "Epoch 1, Loss: 1.5633813745807856e-05\n",
            "Epoch 1, Loss: 1.8347622244618833e-05\n",
            "Epoch 1, Loss: 1.4277949958341196e-05\n",
            "Epoch 1, Loss: 1.6644095012452453e-05\n",
            "Epoch 1, Loss: 1.9468679965939373e-05\n",
            "Epoch 1, Loss: 1.4300468137662392e-05\n",
            "Epoch 1, Loss: 1.7090349501813762e-05\n",
            "Epoch 1, Loss: 1.3177860637370031e-05\n",
            "Epoch 1, Loss: 1.6506804968230426e-05\n",
            "Epoch 1, Loss: 1.735626210574992e-05\n",
            "Epoch 1, Loss: 1.6484698790009134e-05\n",
            "Epoch 1, Loss: 1.4653744983661454e-05\n",
            "Epoch 1, Loss: 1.6438531019957736e-05\n",
            "Epoch 1, Loss: 1.647643330215942e-05\n",
            "Epoch 1, Loss: 1.490931481384905e-05\n",
            "Epoch 1, Loss: 1.405183138558641e-05\n",
            "Epoch 1, Loss: 1.600577888893895e-05\n",
            "Epoch 1, Loss: 1.4193640708981548e-05\n",
            "Epoch 1, Loss: 1.6140431398525834e-05\n",
            "Epoch 1, Loss: 1.5637946489732713e-05\n",
            "Epoch 1, Loss: 1.656390850257594e-05\n",
            "Epoch 1, Loss: 1.2852764484705403e-05\n",
            "Epoch 1, Loss: 1.558933945489116e-05\n",
            "Epoch 1, Loss: 1.4022438335814513e-05\n",
            "Epoch 1, Loss: 1.6269752450170927e-05\n",
            "Epoch 1, Loss: 1.549615444673691e-05\n",
            "Epoch 1, Loss: 2.1027964976383373e-05\n",
            "Epoch 1, Loss: 1.760637496772688e-05\n",
            "Epoch 1, Loss: 1.5070838344399817e-05\n",
            "Epoch 1, Loss: 1.3601093087345362e-05\n",
            "Epoch 1, Loss: 1.4168363122735173e-05\n",
            "Epoch 1, Loss: 1.6633615814498626e-05\n",
            "Epoch 1, Loss: 1.6749641872593202e-05\n",
            "Epoch 1, Loss: 1.9944807718275115e-05\n",
            "Epoch 1, Loss: 1.5869651178945787e-05\n",
            "Epoch 1, Loss: 1.6740030332584865e-05\n",
            "Epoch 1, Loss: 1.7377687981934287e-05\n",
            "Epoch 1, Loss: 1.4150338756735437e-05\n",
            "Epoch 1, Loss: 1.590930696693249e-05\n",
            "Epoch 1, Loss: 1.5200393136183266e-05\n",
            "Epoch 1, Loss: 1.5403158613480628e-05\n",
            "Epoch 1, Loss: 1.563339537824504e-05\n",
            "Epoch 1, Loss: 1.392669764754828e-05\n",
            "Epoch 1, Loss: 1.4312389794213232e-05\n",
            "Epoch 1, Loss: 1.6292211512336507e-05\n",
            "Epoch 1, Loss: 1.6260357369901612e-05\n",
            "Epoch 1, Loss: 1.494433672633022e-05\n",
            "Epoch 1, Loss: 1.9191707906429656e-05\n",
            "Epoch 1, Loss: 1.9716810129466467e-05\n",
            "Epoch 1, Loss: 1.4959511645429302e-05\n",
            "Epoch 1, Loss: 1.6443183994852006e-05\n",
            "Epoch 1, Loss: 1.589979001437314e-05\n",
            "Epoch 1, Loss: 1.386357871524524e-05\n",
            "Epoch 1, Loss: 1.8425434973323718e-05\n",
            "Epoch 1, Loss: 1.8402843124931678e-05\n",
            "Epoch 1, Loss: 1.491450075263856e-05\n",
            "Epoch 1, Loss: 1.8135864593205042e-05\n",
            "Epoch 1, Loss: 1.5545732821919955e-05\n",
            "Epoch 1, Loss: 1.36514372570673e-05\n",
            "Epoch 1, Loss: 1.5079015611263458e-05\n",
            "Epoch 1, Loss: 1.6240363038377836e-05\n",
            "Epoch 1, Loss: 1.7672122339718044e-05\n",
            "Epoch 1, Loss: 1.683075061009731e-05\n",
            "Epoch 1, Loss: 1.4802708392380737e-05\n",
            "Epoch 1, Loss: 1.580502612341661e-05\n",
            "Epoch 1, Loss: 1.4515831026074011e-05\n",
            "Epoch 1, Loss: 1.5504841940128244e-05\n",
            "Epoch 1, Loss: 1.433133911632467e-05\n",
            "Epoch 1, Loss: 1.861623240984045e-05\n",
            "Epoch 1, Loss: 1.524678009445779e-05\n",
            "Epoch 1, Loss: 1.7855183614301495e-05\n",
            "Epoch 1, Loss: 1.924504067574162e-05\n",
            "Epoch 1, Loss: 1.3843387023371179e-05\n",
            "Epoch 1, Loss: 1.5126327525649685e-05\n",
            "Epoch 1, Loss: 1.3658623174706008e-05\n",
            "Epoch 1, Loss: 1.5761866961838678e-05\n",
            "Epoch 1, Loss: 1.685655843175482e-05\n",
            "Epoch 1, Loss: 1.4498657037620433e-05\n",
            "Epoch 1, Loss: 1.2733347830362618e-05\n",
            "Epoch 1, Loss: 1.4324150470201857e-05\n",
            "Epoch 1, Loss: 1.286321275983937e-05\n",
            "Epoch 1, Loss: 1.5609421097906306e-05\n",
            "Epoch 1, Loss: 1.3990092156745959e-05\n",
            "Epoch 1, Loss: 1.3932901310909074e-05\n",
            "Epoch 1, Loss: 1.5063597857079003e-05\n",
            "Epoch 1, Loss: 1.2491206689446699e-05\n",
            "Epoch 1, Loss: 1.7362588550895452e-05\n",
            "Epoch 1, Loss: 1.746794987411704e-05\n",
            "Epoch 1, Loss: 1.2168930879852269e-05\n",
            "Epoch 1, Loss: 1.4642665519204456e-05\n",
            "Epoch 1, Loss: 1.3968329767521936e-05\n",
            "Epoch 1, Loss: 1.531710586277768e-05\n",
            "Epoch 1, Loss: 1.610695653653238e-05\n",
            "Epoch 1, Loss: 1.610182152944617e-05\n",
            "Epoch 1, Loss: 1.6394838894484565e-05\n",
            "Epoch 1, Loss: 1.6090220015030354e-05\n",
            "Epoch 1, Loss: 1.7618827769183554e-05\n",
            "Epoch 1, Loss: 1.3134026630723383e-05\n",
            "Epoch 1, Loss: 1.4070245015318505e-05\n",
            "Epoch 1, Loss: 1.638125286262948e-05\n",
            "Epoch 1, Loss: 1.3703807780984789e-05\n",
            "Epoch 1, Loss: 1.6982254237518646e-05\n",
            "Epoch 1, Loss: 1.581608557899017e-05\n",
            "Epoch 1, Loss: 2.0495317585300654e-05\n",
            "Epoch 1, Loss: 1.8048544006887823e-05\n",
            "Epoch 1, Loss: 1.7118281903094612e-05\n",
            "Epoch 1, Loss: 1.6334017345798202e-05\n",
            "Epoch 1, Loss: 1.5577896192553453e-05\n",
            "Epoch 1, Loss: 1.5886897017480806e-05\n",
            "Epoch 1, Loss: 1.5237066691042855e-05\n",
            "Epoch 1, Loss: 2.0691675672424026e-05\n",
            "Epoch 1, Loss: 1.5192774299066514e-05\n",
            "Epoch 1, Loss: 1.4364074559125584e-05\n",
            "Epoch 1, Loss: 1.616540248505771e-05\n",
            "Epoch 1, Loss: 1.5466184777324088e-05\n",
            "Epoch 1, Loss: 1.9276498278486542e-05\n",
            "Epoch 1, Loss: 1.9758434063987806e-05\n",
            "Epoch 1, Loss: 1.3250801202957518e-05\n",
            "Epoch 1, Loss: 1.673654514888767e-05\n",
            "Epoch 1, Loss: 1.7705000573187135e-05\n",
            "Epoch 1, Loss: 1.502377836004598e-05\n",
            "Epoch 1, Loss: 1.3782136193185579e-05\n",
            "Epoch 1, Loss: 1.537571006338112e-05\n",
            "Epoch 1, Loss: 1.939361754921265e-05\n",
            "Epoch 1, Loss: 1.6810339730000123e-05\n",
            "Epoch 1, Loss: 1.4030899365025107e-05\n",
            "Epoch 1, Loss: 1.4999243830970954e-05\n",
            "Epoch 1, Loss: 1.3914238479628693e-05\n",
            "Epoch 1, Loss: 1.4538517461915035e-05\n",
            "Epoch 1, Loss: 1.2711607269011438e-05\n",
            "Epoch 1, Loss: 1.4622195521951653e-05\n",
            "Epoch 1, Loss: 1.5764184354338795e-05\n",
            "Epoch 1, Loss: 1.3581666280515492e-05\n",
            "Epoch 1, Loss: 1.9339187929290347e-05\n",
            "Epoch 1, Loss: 1.3668442079506349e-05\n",
            "Epoch 1, Loss: 1.4196703887137119e-05\n",
            "Epoch 1, Loss: 1.2125361536163837e-05\n",
            "Epoch 1, Loss: 1.7385655155521818e-05\n",
            "Epoch 1, Loss: 1.4698381164635066e-05\n",
            "Epoch 1, Loss: 2.602942186058499e-05\n",
            "Epoch 1, Loss: 1.3462040442391299e-05\n",
            "Epoch 1, Loss: 1.3316947843122762e-05\n",
            "Epoch 1, Loss: 1.4744563486601692e-05\n",
            "Epoch 1, Loss: 1.5451480066985823e-05\n",
            "Epoch 1, Loss: 1.6581758245592937e-05\n",
            "Epoch 1, Loss: 1.687535950622987e-05\n",
            "Epoch 1, Loss: 1.978322870854754e-05\n",
            "Epoch 1, Loss: 1.5954046830302104e-05\n",
            "Epoch 1, Loss: 1.5485598851228133e-05\n",
            "Epoch 1, Loss: 1.392771810060367e-05\n",
            "Epoch 1, Loss: 2.033229793596547e-05\n",
            "Epoch 1, Loss: 1.6921801943681203e-05\n",
            "Epoch 1, Loss: 1.738388164085336e-05\n",
            "Epoch 1, Loss: 1.5943165635690093e-05\n",
            "Epoch 1, Loss: 1.804998464649543e-05\n",
            "Epoch 1, Loss: 1.5512550817220472e-05\n",
            "Epoch 1, Loss: 1.4466284483205527e-05\n",
            "Epoch 1, Loss: 1.3613255759992171e-05\n",
            "Epoch 1, Loss: 1.5066410014696885e-05\n",
            "Epoch 1, Loss: 1.709132266114466e-05\n",
            "Epoch 1, Loss: 1.498478559369687e-05\n",
            "Epoch 1, Loss: 1.854665606515482e-05\n",
            "Epoch 1, Loss: 1.6226733350777067e-05\n",
            "Epoch 1, Loss: 1.5390225598821416e-05\n",
            "Epoch 1, Loss: 1.4490004105027765e-05\n",
            "Epoch 1, Loss: 1.6178830264834687e-05\n",
            "Epoch 1, Loss: 1.3483103430189658e-05\n",
            "Epoch 1, Loss: 1.579471427248791e-05\n",
            "Epoch 1, Loss: 1.4723893400514498e-05\n",
            "Epoch 1, Loss: 1.4094058315095026e-05\n",
            "Epoch 1, Loss: 1.3969225619803183e-05\n",
            "Epoch 1, Loss: 1.7315687728114426e-05\n",
            "Epoch 1, Loss: 1.5385519873234443e-05\n",
            "Epoch 1, Loss: 1.4776888747292105e-05\n",
            "Epoch 1, Loss: 1.6167650755960494e-05\n",
            "Epoch 1, Loss: 1.4897361324983649e-05\n",
            "Epoch 1, Loss: 1.651237835176289e-05\n",
            "Epoch 1, Loss: 1.3863979802408721e-05\n",
            "Epoch 1, Loss: 1.5197222637652885e-05\n",
            "Epoch 1, Loss: 1.8343709598411806e-05\n",
            "Epoch 1, Loss: 1.5788797099958174e-05\n",
            "Epoch 1, Loss: 1.4169445421430282e-05\n",
            "Epoch 1, Loss: 1.2699919352598954e-05\n",
            "Epoch 1, Loss: 1.4438660400628578e-05\n",
            "Epoch 1, Loss: 1.4649054719484411e-05\n",
            "Epoch 1, Loss: 1.2931476703670342e-05\n",
            "Epoch 1, Loss: 1.491898910899181e-05\n",
            "Epoch 1, Loss: 1.539794720883947e-05\n",
            "Epoch 1, Loss: 1.6914676962187514e-05\n",
            "Epoch 1, Loss: 2.400908306299243e-05\n",
            "Epoch 1, Loss: 1.4361170542542823e-05\n",
            "Epoch 1, Loss: 1.8312350221094675e-05\n",
            "Epoch 1, Loss: 1.9844032067339867e-05\n",
            "Epoch 1, Loss: 1.5803665519342758e-05\n",
            "Epoch 1, Loss: 1.4527469829772599e-05\n",
            "Epoch 1, Loss: 1.6119778592837974e-05\n",
            "Epoch 1, Loss: 1.5396435628645122e-05\n",
            "Epoch 1, Loss: 2.0632502128137276e-05\n",
            "Epoch 1, Loss: 2.2148255084175617e-05\n",
            "Epoch 1, Loss: 1.2789646461897064e-05\n",
            "Epoch 1, Loss: 1.6743333617341705e-05\n",
            "Epoch 1, Loss: 1.7061356629710644e-05\n",
            "Epoch 1, Loss: 1.7407990526407957e-05\n",
            "Epoch 1, Loss: 1.731166230456438e-05\n",
            "Epoch 1, Loss: 1.5264706235029735e-05\n",
            "Epoch 1, Loss: 1.3621298421639949e-05\n",
            "Epoch 1, Loss: 1.3161389688320924e-05\n",
            "Epoch 1, Loss: 1.6001715266611427e-05\n",
            "Epoch 1, Loss: 1.4778121112613007e-05\n",
            "Epoch 1, Loss: 1.8321143215871416e-05\n",
            "Epoch 1, Loss: 1.931295992108062e-05\n",
            "Epoch 1, Loss: 1.5251724107656628e-05\n",
            "Epoch 1, Loss: 1.5983641787897795e-05\n",
            "Epoch 1, Loss: 1.604977296665311e-05\n",
            "Epoch 1, Loss: 1.5261106455000117e-05\n",
            "Epoch 1, Loss: 1.3809591109747998e-05\n",
            "Epoch 1, Loss: 1.4974957593949512e-05\n",
            "Epoch 1, Loss: 1.488419366069138e-05\n",
            "Epoch 1, Loss: 1.7107924577430822e-05\n",
            "Epoch 1, Loss: 1.3618363482237328e-05\n",
            "Epoch 1, Loss: 1.7143780496553518e-05\n",
            "Epoch 1, Loss: 1.4763183571631089e-05\n",
            "Epoch 1, Loss: 1.4698515769850928e-05\n",
            "Epoch 1, Loss: 1.1148049452458508e-05\n",
            "Epoch 1, Loss: 1.5284460459952243e-05\n",
            "Epoch 1, Loss: 1.787718247214798e-05\n",
            "Epoch 1, Loss: 1.3174152627470903e-05\n",
            "Epoch 1, Loss: 1.3231663615442812e-05\n",
            "Epoch 1, Loss: 1.625322511245031e-05\n",
            "Epoch 1, Loss: 1.3866729204892181e-05\n",
            "Epoch 1, Loss: 1.5877305486355908e-05\n",
            "Epoch 1, Loss: 1.4670340533484705e-05\n",
            "Epoch 1, Loss: 1.3232765923021361e-05\n",
            "Epoch 1, Loss: 1.4751673916180152e-05\n",
            "Epoch 1, Loss: 1.309038452745881e-05\n",
            "Epoch 1, Loss: 1.5040955986478366e-05\n",
            "Epoch 1, Loss: 1.5335341231548227e-05\n",
            "Epoch 1, Loss: 1.4061230103834532e-05\n",
            "Epoch 1, Loss: 1.4284765711636283e-05\n",
            "Epoch 1, Loss: 1.7594236851437017e-05\n",
            "Epoch 1, Loss: 1.5003610315034166e-05\n",
            "Epoch 1, Loss: 1.329933093074942e-05\n",
            "Epoch 1, Loss: 1.4690107491333038e-05\n",
            "Epoch 1, Loss: 1.3116577065375168e-05\n",
            "Epoch 1, Loss: 1.5017322766652796e-05\n",
            "Epoch 1, Loss: 1.796569995349273e-05\n",
            "Epoch 1, Loss: 1.3494814083969686e-05\n",
            "Epoch 1, Loss: 1.5011697541922331e-05\n",
            "Epoch 1, Loss: 1.257309577340493e-05\n",
            "Epoch 1, Loss: 1.3552161362895276e-05\n",
            "Epoch 1, Loss: 1.6433701603091322e-05\n",
            "Epoch 1, Loss: 1.3776886589766946e-05\n",
            "Epoch 1, Loss: 1.4557558642991353e-05\n",
            "Epoch 1, Loss: 1.3437645975500345e-05\n",
            "Epoch 1, Loss: 1.4495342838927172e-05\n",
            "Epoch 1, Loss: 1.3895786651119124e-05\n",
            "Epoch 1, Loss: 1.5042061932035722e-05\n",
            "Epoch 1, Loss: 1.535041337774601e-05\n",
            "Epoch 1, Loss: 1.6485400919918902e-05\n",
            "Epoch 1, Loss: 1.5080815501278266e-05\n",
            "Epoch 1, Loss: 1.3572758689406328e-05\n",
            "Epoch 1, Loss: 1.2364940630504861e-05\n",
            "Epoch 1, Loss: 1.3968925486551598e-05\n",
            "Epoch 1, Loss: 1.5315912605728954e-05\n",
            "Epoch 1, Loss: 1.827857704483904e-05\n",
            "Epoch 1, Loss: 1.6818015865283087e-05\n",
            "Epoch 1, Loss: 1.62716878548963e-05\n",
            "Epoch 1, Loss: 1.4966763046686538e-05\n",
            "Epoch 1, Loss: 1.4509188076772261e-05\n",
            "Epoch 1, Loss: 1.3568524082074873e-05\n",
            "Epoch 1, Loss: 1.67819089256227e-05\n",
            "Epoch 1, Loss: 1.3483164366334677e-05\n",
            "Epoch 1, Loss: 1.6206700820475817e-05\n",
            "Epoch 1, Loss: 1.283867641177494e-05\n",
            "Epoch 1, Loss: 1.3894060430175159e-05\n",
            "Epoch 1, Loss: 1.5029020687507e-05\n",
            "Epoch 1, Loss: 1.956926644197665e-05\n",
            "Epoch 1, Loss: 1.3652722373080906e-05\n",
            "Epoch 1, Loss: 1.6679779946571216e-05\n",
            "Epoch 1, Loss: 1.772188079485204e-05\n",
            "Epoch 1, Loss: 1.604614226380363e-05\n",
            "Epoch 1, Loss: 1.382658228976652e-05\n",
            "Epoch 1, Loss: 1.4743925930815749e-05\n",
            "Epoch 1, Loss: 1.6026384400902316e-05\n",
            "Epoch 1, Loss: 1.6885576769709587e-05\n",
            "Epoch 1, Loss: 1.4684565030620433e-05\n",
            "Epoch 1, Loss: 1.675104613241274e-05\n",
            "Epoch 1, Loss: 1.3083742487651762e-05\n",
            "Epoch 1, Loss: 1.2770066859957296e-05\n",
            "Epoch 1, Loss: 2.0225003027007915e-05\n",
            "Epoch 1, Loss: 1.6150921510416083e-05\n",
            "Epoch 1, Loss: 1.5385299775516614e-05\n",
            "Epoch 1, Loss: 1.53537948790472e-05\n",
            "Epoch 1, Loss: 1.6854381101438776e-05\n",
            "Epoch 1, Loss: 1.471026916988194e-05\n",
            "Epoch 1, Loss: 1.564627564221155e-05\n",
            "Epoch 1, Loss: 1.5530333257629536e-05\n",
            "Epoch 1, Loss: 1.652207356528379e-05\n",
            "Epoch 1, Loss: 1.3638792552228551e-05\n",
            "Epoch 1, Loss: 1.8653585357242264e-05\n",
            "Epoch 1, Loss: 1.4800495591771323e-05\n",
            "Epoch 1, Loss: 1.6607507859589532e-05\n",
            "Epoch 1, Loss: 1.0490915883565322e-05\n",
            "Epoch 1, Loss: 1.8828295651474036e-05\n",
            "Epoch 1, Loss: 1.4987374015618116e-05\n",
            "Epoch 1, Loss: 1.5803516362211667e-05\n",
            "Epoch 1, Loss: 1.2813448847737163e-05\n",
            "Epoch 1, Loss: 1.563713522045873e-05\n",
            "Epoch 1, Loss: 1.8923890820587985e-05\n",
            "Epoch 1, Loss: 1.2445434549590573e-05\n",
            "Epoch 1, Loss: 1.6063710063463077e-05\n",
            "Epoch 1, Loss: 1.5703117242082953e-05\n",
            "Epoch 1, Loss: 1.50467703861068e-05\n",
            "Epoch 1, Loss: 1.820611214498058e-05\n",
            "Epoch 1, Loss: 1.271734890906373e-05\n",
            "Epoch 1, Loss: 1.5601550330757163e-05\n",
            "Epoch 1, Loss: 1.3456118722388055e-05\n",
            "Epoch 1, Loss: 1.4708322851220146e-05\n",
            "Epoch 1, Loss: 1.2363153473415878e-05\n",
            "Epoch 1, Loss: 1.3095270332996733e-05\n",
            "Epoch 1, Loss: 1.4447803550865501e-05\n",
            "Epoch 1, Loss: 1.586193138791714e-05\n",
            "Epoch 1, Loss: 1.4418320461118128e-05\n",
            "Epoch 1, Loss: 1.249732758878963e-05\n",
            "Epoch 1, Loss: 1.2208709449623711e-05\n",
            "Epoch 1, Loss: 1.315079498453997e-05\n",
            "Epoch 1, Loss: 1.4693073353555519e-05\n",
            "Epoch 1, Loss: 1.3263664186524693e-05\n",
            "Epoch 1, Loss: 1.3826242138748057e-05\n",
            "Epoch 1, Loss: 1.4512924281007145e-05\n",
            "Epoch 1, Loss: 1.3588651199825108e-05\n",
            "Epoch 1, Loss: 1.5143948076001834e-05\n",
            "Epoch 1, Loss: 1.6966105249593966e-05\n",
            "Epoch 1, Loss: 1.4298370842880104e-05\n",
            "Epoch 1, Loss: 1.2270673323655501e-05\n",
            "Epoch 1, Loss: 1.5026803339424077e-05\n",
            "Epoch 1, Loss: 1.3729817510466091e-05\n",
            "Epoch 1, Loss: 1.329651422565803e-05\n",
            "Epoch 1, Loss: 1.6518100892426446e-05\n",
            "Epoch 1, Loss: 1.4183934581524227e-05\n",
            "Epoch 1, Loss: 1.4552192624250893e-05\n",
            "Epoch 1, Loss: 1.6035995940910652e-05\n",
            "Epoch 1, Loss: 1.4431382624024991e-05\n",
            "Epoch 1, Loss: 1.1601906408031937e-05\n",
            "Epoch 1, Loss: 1.3130784282111563e-05\n",
            "Epoch 1, Loss: 1.3620092431665398e-05\n",
            "Epoch 1, Loss: 1.4346062926051673e-05\n",
            "Epoch 1, Loss: 1.3838147424394265e-05\n",
            "Epoch 1, Loss: 1.2939086445840076e-05\n",
            "Epoch 1, Loss: 1.7446827769163065e-05\n",
            "Epoch 1, Loss: 1.5723780961707234e-05\n",
            "Epoch 1, Loss: 1.268808773602359e-05\n",
            "Epoch 1, Loss: 1.8837652532965876e-05\n",
            "Epoch 1, Loss: 1.3741049770032987e-05\n",
            "Epoch 1, Loss: 1.1002358405676205e-05\n",
            "Epoch 1, Loss: 1.6068930563051254e-05\n",
            "Epoch 1, Loss: 1.4755431038793176e-05\n",
            "Epoch 1, Loss: 1.3012815543334e-05\n",
            "Epoch 1, Loss: 1.546656494610943e-05\n",
            "Epoch 1, Loss: 1.4065475625102408e-05\n",
            "Epoch 1, Loss: 1.2796526789315976e-05\n",
            "Epoch 1, Loss: 1.5443571101059206e-05\n",
            "Epoch 1, Loss: 1.416486338712275e-05\n",
            "Epoch 1, Loss: 1.2395066733006388e-05\n",
            "Epoch 1, Loss: 1.450388845114503e-05\n",
            "Epoch 1, Loss: 1.7216396372532472e-05\n",
            "Epoch 1, Loss: 1.4769660083402414e-05\n",
            "Epoch 1, Loss: 1.4155659300740808e-05\n",
            "Epoch 1, Loss: 1.332905867457157e-05\n",
            "Epoch 1, Loss: 1.3310394933796488e-05\n",
            "Epoch 1, Loss: 1.1818787243100815e-05\n",
            "Epoch 1, Loss: 1.4592254956369288e-05\n",
            "Epoch 1, Loss: 1.3828139344695956e-05\n",
            "Epoch 1, Loss: 1.3179743291402701e-05\n",
            "Epoch 1, Loss: 1.451898515369976e-05\n",
            "Epoch 1, Loss: 1.3131084415363148e-05\n",
            "Epoch 1, Loss: 1.293302557314746e-05\n",
            "Epoch 1, Loss: 1.3561231753556058e-05\n",
            "Epoch 1, Loss: 1.717217128316406e-05\n",
            "Epoch 1, Loss: 1.1934528629353736e-05\n",
            "Epoch 1, Loss: 1.6824360500322655e-05\n",
            "Epoch 1, Loss: 1.3161647075321525e-05\n",
            "Epoch 1, Loss: 1.2710812370642088e-05\n",
            "Epoch 1, Loss: 1.2269720173208043e-05\n",
            "Epoch 1, Loss: 1.1154109415656421e-05\n",
            "Epoch 1, Loss: 1.3783293979940936e-05\n",
            "Epoch 1, Loss: 1.1697582522174343e-05\n",
            "Epoch 1, Loss: 1.353924108116189e-05\n",
            "Epoch 1, Loss: 1.5988405721145682e-05\n",
            "Epoch 1, Loss: 1.4765380910830572e-05\n",
            "Epoch 1, Loss: 1.1882643775606994e-05\n",
            "Epoch 1, Loss: 1.3407691767497454e-05\n",
            "Epoch 1, Loss: 1.701402652543038e-05\n",
            "Epoch 1, Loss: 1.2270854313101154e-05\n",
            "Epoch 1, Loss: 1.3819494597555604e-05\n",
            "Epoch 1, Loss: 1.5181572962319478e-05\n",
            "Epoch 1, Loss: 1.2706080269708764e-05\n",
            "Epoch 1, Loss: 1.3512511031876784e-05\n",
            "Epoch 1, Loss: 1.3765725270786788e-05\n",
            "Epoch 1, Loss: 1.2260431503818836e-05\n",
            "Epoch 1, Loss: 1.2039286957588047e-05\n",
            "Epoch 1, Loss: 1.4226212442736141e-05\n",
            "Epoch 1, Loss: 1.3935323295299895e-05\n",
            "Epoch 1, Loss: 1.619207796466071e-05\n",
            "Epoch 1, Loss: 1.190833791042678e-05\n",
            "Epoch 1, Loss: 1.2096345017198473e-05\n",
            "Epoch 1, Loss: 1.175267061626073e-05\n",
            "Epoch 1, Loss: 1.5215387975331396e-05\n",
            "Epoch 1, Loss: 1.373085342493141e-05\n",
            "Epoch 1, Loss: 1.5891693692537956e-05\n",
            "Epoch 1, Loss: 1.1740698028006591e-05\n",
            "Epoch 1, Loss: 1.4845839359622914e-05\n",
            "Epoch 1, Loss: 1.0850202670553699e-05\n",
            "Epoch 1, Loss: 1.4891363207425456e-05\n",
            "Epoch 1, Loss: 1.759556653269101e-05\n",
            "Epoch 1, Loss: 1.800592326617334e-05\n",
            "Epoch 1, Loss: 1.1291001101199072e-05\n",
            "Epoch 1, Loss: 1.3505807146430016e-05\n",
            "Epoch 1, Loss: 1.3452089660859201e-05\n",
            "Epoch 1, Loss: 1.1778547559515573e-05\n",
            "Epoch 1, Loss: 1.4383512279891875e-05\n",
            "Epoch 1, Loss: 1.413003155903425e-05\n",
            "Epoch 1, Loss: 1.429932308383286e-05\n",
            "Epoch 1, Loss: 1.4582462426915299e-05\n",
            "Epoch 1, Loss: 1.3389179912337568e-05\n",
            "Epoch 1, Loss: 1.3693246728507802e-05\n",
            "Epoch 1, Loss: 1.2953053555975202e-05\n",
            "Epoch 1, Loss: 1.0591397767711896e-05\n",
            "Epoch 1, Loss: 1.2480719306040555e-05\n",
            "Epoch 1, Loss: 1.386359963362338e-05\n",
            "Epoch 1, Loss: 1.4159668353386223e-05\n",
            "Epoch 1, Loss: 1.2606561540451366e-05\n",
            "Epoch 1, Loss: 1.4997858670540154e-05\n",
            "Epoch 1, Loss: 1.305004843743518e-05\n",
            "Epoch 1, Loss: 1.2398390026646666e-05\n",
            "Epoch 1, Loss: 1.3519435924536083e-05\n",
            "Epoch 1, Loss: 1.4405684851226397e-05\n",
            "Epoch 1, Loss: 1.3328208297025412e-05\n",
            "Epoch 1, Loss: 1.6374215192627162e-05\n",
            "Epoch 1, Loss: 1.6344649338861927e-05\n",
            "Epoch 1, Loss: 1.3348394531931262e-05\n",
            "Epoch 1, Loss: 1.2548681297630537e-05\n",
            "Epoch 1, Loss: 1.295950096391607e-05\n",
            "Epoch 1, Loss: 1.6319967471645214e-05\n",
            "Epoch 1, Loss: 1.4294264474301599e-05\n",
            "Epoch 1, Loss: 1.328483904217137e-05\n",
            "Epoch 1, Loss: 1.2249629435245879e-05\n",
            "Epoch 1, Loss: 1.4703194210596848e-05\n",
            "Epoch 1, Loss: 1.3548738024837803e-05\n",
            "Epoch 1, Loss: 1.2295192391320597e-05\n",
            "Epoch 1, Loss: 1.2776642506651115e-05\n",
            "Epoch 1, Loss: 1.6888734535314143e-05\n",
            "Epoch 1, Loss: 1.2096977116016205e-05\n",
            "Epoch 1, Loss: 1.3080875760351773e-05\n",
            "Epoch 1, Loss: 1.3217559171607718e-05\n",
            "Epoch 1, Loss: 1.118699128710432e-05\n",
            "Epoch 1, Loss: 1.354929554508999e-05\n",
            "Epoch 1, Loss: 1.3254502846393734e-05\n",
            "Epoch 1, Loss: 1.3938631127530243e-05\n",
            "Epoch 1, Loss: 1.1593919225560967e-05\n",
            "Epoch 1, Loss: 1.309175422647968e-05\n",
            "Epoch 1, Loss: 1.2091659300494939e-05\n",
            "Epoch 1, Loss: 1.5141798030526843e-05\n",
            "Epoch 1, Loss: 1.194147171190707e-05\n",
            "Epoch 1, Loss: 1.6314659660565667e-05\n",
            "Epoch 1, Loss: 1.051426625053864e-05\n",
            "Epoch 1, Loss: 1.397198411723366e-05\n",
            "Epoch 1, Loss: 1.2904995855933521e-05\n",
            "Epoch 1, Loss: 1.2165015505161136e-05\n",
            "Epoch 1, Loss: 1.3918524928158149e-05\n",
            "Epoch 1, Loss: 1.499518930359045e-05\n",
            "Epoch 1, Loss: 1.2445773791114334e-05\n",
            "Epoch 1, Loss: 1.2040759429510217e-05\n",
            "Epoch 1, Loss: 1.4321985872811638e-05\n",
            "Epoch 1, Loss: 1.4050664503884036e-05\n",
            "Epoch 1, Loss: 1.2074108781234827e-05\n",
            "Epoch 1, Loss: 1.4312176062958315e-05\n",
            "Epoch 1, Loss: 1.3961276636109687e-05\n",
            "Epoch 1, Loss: 1.4128486327535938e-05\n",
            "Epoch 1, Loss: 1.2576690096466336e-05\n",
            "Epoch 1, Loss: 1.4064314200368244e-05\n",
            "Epoch 1, Loss: 1.3371521163207944e-05\n",
            "Epoch 1, Loss: 1.4367858057084959e-05\n",
            "Epoch 1, Loss: 1.511075515736593e-05\n",
            "Epoch 1, Loss: 1.255291499546729e-05\n",
            "Epoch 1, Loss: 1.2225245882291347e-05\n",
            "Epoch 1, Loss: 1.2980552128283307e-05\n",
            "Epoch 1, Loss: 1.168966537079541e-05\n",
            "Epoch 1, Loss: 1.4181258848111611e-05\n",
            "Epoch 1, Loss: 1.205689477501437e-05\n",
            "Epoch 1, Loss: 1.3087088518659584e-05\n",
            "Epoch 1, Loss: 1.3447865057969466e-05\n",
            "Epoch 1, Loss: 1.2039624380122405e-05\n",
            "Epoch 1, Loss: 1.168512062577065e-05\n",
            "Epoch 1, Loss: 1.2713128853647504e-05\n",
            "Epoch 1, Loss: 1.3388248589762952e-05\n",
            "Epoch 1, Loss: 1.4676317732664756e-05\n",
            "Epoch 1, Loss: 1.4744157851964701e-05\n",
            "Epoch 1, Loss: 1.2241234799148515e-05\n",
            "Epoch 1, Loss: 1.4577405636373442e-05\n",
            "Epoch 1, Loss: 1.097427502827486e-05\n",
            "Epoch 1, Loss: 1.5036044715088792e-05\n",
            "Epoch 1, Loss: 1.2971678188478108e-05\n",
            "Epoch 1, Loss: 1.4568547157978173e-05\n",
            "Epoch 1, Loss: 1.4472895600192714e-05\n",
            "Epoch 1, Loss: 1.5205862837319728e-05\n",
            "Epoch 1, Loss: 1.2969961971975863e-05\n",
            "Epoch 1, Loss: 1.3498729458660819e-05\n",
            "Epoch 1, Loss: 1.5706315025454387e-05\n",
            "Epoch 1, Loss: 1.2006873475911561e-05\n",
            "Epoch 1, Loss: 1.2824529221688863e-05\n",
            "Epoch 1, Loss: 1.0866271622944623e-05\n",
            "Epoch 1, Loss: 1.3078476513328496e-05\n",
            "Epoch 1, Loss: 1.6105343092931435e-05\n",
            "Epoch 1, Loss: 1.2801770026271697e-05\n",
            "Epoch 1, Loss: 1.4296046174422372e-05\n",
            "Epoch 1, Loss: 1.2560112736537121e-05\n",
            "Epoch 1, Loss: 1.1751270903914701e-05\n",
            "Epoch 1, Loss: 1.3295243661559653e-05\n",
            "Epoch 1, Loss: 1.3841932741343044e-05\n",
            "Epoch 1, Loss: 1.1245916539337486e-05\n",
            "Epoch 1, Loss: 1.204259206133429e-05\n",
            "Epoch 1, Loss: 1.2315309504629113e-05\n",
            "Epoch 1, Loss: 1.3348897482501343e-05\n",
            "Epoch 1, Loss: 1.4837304661341477e-05\n",
            "Epoch 1, Loss: 1.3375980415730737e-05\n",
            "Epoch 1, Loss: 1.436083584849257e-05\n",
            "Epoch 1, Loss: 1.0862557246582583e-05\n",
            "Epoch 1, Loss: 1.1827781236206647e-05\n",
            "Epoch 1, Loss: 1.3537010090658441e-05\n",
            "Epoch 1, Loss: 1.3341376870812383e-05\n",
            "Epoch 1, Loss: 1.5439924027305096e-05\n",
            "Epoch 1, Loss: 1.1885977073688991e-05\n",
            "Epoch 1, Loss: 1.3669777217728551e-05\n",
            "Epoch 1, Loss: 1.1606231055338867e-05\n",
            "Epoch 1, Loss: 1.3823012523062062e-05\n",
            "Epoch 1, Loss: 1.3461274647852406e-05\n",
            "Epoch 1, Loss: 1.3038499673712067e-05\n",
            "Epoch 1, Loss: 1.1960763004026376e-05\n",
            "Epoch 1, Loss: 1.618765054445248e-05\n",
            "Epoch 1, Loss: 1.2007715668005403e-05\n",
            "Epoch 1, Loss: 1.3685030353371985e-05\n",
            "Epoch 1, Loss: 1.9132838133373298e-05\n",
            "Epoch 1, Loss: 1.292416618525749e-05\n",
            "Epoch 1, Loss: 1.3750611287832726e-05\n",
            "Epoch 1, Loss: 1.409754895576043e-05\n",
            "Epoch 1, Loss: 1.1616170013439842e-05\n",
            "Epoch 1, Loss: 1.482492280047154e-05\n",
            "Epoch 1, Loss: 1.500592588854488e-05\n",
            "Epoch 1, Loss: 1.4126279893389437e-05\n",
            "Epoch 1, Loss: 1.2004248674202245e-05\n",
            "Epoch 1, Loss: 1.418484953319421e-05\n",
            "Epoch 1, Loss: 1.259856071555987e-05\n",
            "Epoch 1, Loss: 1.3492753168975469e-05\n",
            "Epoch 1, Loss: 1.7402879166183993e-05\n",
            "Epoch 1, Loss: 1.3470760677591898e-05\n",
            "Epoch 1, Loss: 1.3714259694097564e-05\n",
            "Epoch 1, Loss: 1.0287426448485348e-05\n",
            "Epoch 1, Loss: 1.1645699487417005e-05\n",
            "Epoch 1, Loss: 1.4417735656024888e-05\n",
            "Epoch 1, Loss: 1.0241446943837218e-05\n",
            "Epoch 1, Loss: 1.1651212844299152e-05\n",
            "Epoch 1, Loss: 1.3698360817215871e-05\n",
            "Epoch 1, Loss: 1.4017247849551495e-05\n",
            "Epoch 1, Loss: 1.2941980457981117e-05\n",
            "Epoch 1, Loss: 1.1554624506970868e-05\n",
            "Epoch 1, Loss: 1.594524655956775e-05\n",
            "Epoch 1, Loss: 1.276827879337361e-05\n",
            "Epoch 1, Loss: 1.4210100744094234e-05\n",
            "Epoch 1, Loss: 1.4449412446992937e-05\n",
            "Epoch 1, Loss: 1.0890978046518285e-05\n",
            "Epoch 1, Loss: 1.6055317246355116e-05\n",
            "Epoch 1, Loss: 1.1214161531825084e-05\n",
            "Epoch 1, Loss: 1.4065264622331597e-05\n",
            "Epoch 1, Loss: 9.817084901442286e-06\n",
            "Epoch 1, Loss: 1.4557815120497253e-05\n",
            "Epoch 1, Loss: 1.3970910003990866e-05\n",
            "Epoch 1, Loss: 1.4814945643593092e-05\n",
            "Epoch 1, Loss: 1.6559375580982305e-05\n",
            "Epoch 1, Loss: 1.240437813976314e-05\n",
            "Epoch 1, Loss: 1.0745897270680871e-05\n",
            "Epoch 1, Loss: 1.2492992027546279e-05\n",
            "Epoch 1, Loss: 1.3774307262792718e-05\n",
            "Epoch 1, Loss: 1.2299735317355953e-05\n",
            "Epoch 1, Loss: 1.4586343240807764e-05\n",
            "Epoch 1, Loss: 1.5698684364906512e-05\n",
            "Epoch 1, Loss: 1.1247627298871521e-05\n",
            "Epoch 1, Loss: 1.1768423064495437e-05\n",
            "Epoch 1, Loss: 1.1945910955546424e-05\n",
            "Epoch 1, Loss: 1.3144645890861284e-05\n",
            "Epoch 1, Loss: 1.7312280760961585e-05\n",
            "Epoch 1, Loss: 1.6159847291419283e-05\n",
            "Epoch 1, Loss: 1.4604570424125995e-05\n",
            "Epoch 1, Loss: 1.351538685412379e-05\n",
            "Epoch 1, Loss: 1.3226623195805587e-05\n",
            "Epoch 1, Loss: 1.4004262084199581e-05\n",
            "Epoch 1, Loss: 1.4346129319164902e-05\n",
            "Epoch 1, Loss: 9.673764907347504e-06\n",
            "Epoch 1, Loss: 1.2529367268143687e-05\n",
            "Epoch 1, Loss: 1.4145050045044627e-05\n",
            "Epoch 1, Loss: 1.1401502888475079e-05\n",
            "Epoch 1, Loss: 1.4885010386933573e-05\n",
            "Epoch 1, Loss: 1.1737294698832557e-05\n",
            "Epoch 1, Loss: 1.2835702364100143e-05\n",
            "Epoch 1, Loss: 1.2868689736933447e-05\n",
            "Epoch 1, Loss: 1.4671187273052055e-05\n",
            "Epoch 1, Loss: 1.3916912394051906e-05\n",
            "Epoch 1, Loss: 1.3692347238247748e-05\n",
            "Epoch 1, Loss: 1.2399703336996026e-05\n",
            "Epoch 1, Loss: 1.439578045392409e-05\n",
            "Epoch 1, Loss: 1.2837663234677166e-05\n",
            "Epoch 1, Loss: 1.2211890862090513e-05\n",
            "Epoch 1, Loss: 1.677510044828523e-05\n",
            "Epoch 1, Loss: 1.115524264605483e-05\n",
            "Epoch 1, Loss: 1.4042741895536892e-05\n",
            "Epoch 1, Loss: 1.1007372449967079e-05\n",
            "Epoch 1, Loss: 1.0528931852604728e-05\n",
            "Epoch 1, Loss: 1.4895841559336986e-05\n",
            "Epoch 1, Loss: 1.3424916687654331e-05\n",
            "Epoch 1, Loss: 1.4387471310328692e-05\n",
            "Epoch 1, Loss: 1.467060519644292e-05\n",
            "Epoch 1, Loss: 1.326199071627343e-05\n",
            "Epoch 1, Loss: 1.264033835468581e-05\n",
            "Epoch 1, Loss: 1.1641147466434631e-05\n",
            "Epoch 1, Loss: 1.2792456800525542e-05\n",
            "Epoch 1, Loss: 1.3552051314036362e-05\n",
            "Epoch 1, Loss: 1.0815183486556634e-05\n",
            "Epoch 1, Loss: 1.3524967471312266e-05\n",
            "Epoch 1, Loss: 1.4880373782943934e-05\n",
            "Epoch 1, Loss: 1.3278007827466354e-05\n",
            "Epoch 1, Loss: 1.1132191502838396e-05\n",
            "Epoch 1, Loss: 1.2314978448557667e-05\n",
            "Epoch 1, Loss: 1.2026801414322108e-05\n",
            "Epoch 1, Loss: 1.745729605318047e-05\n",
            "Epoch 1, Loss: 1.1900498066097498e-05\n",
            "Epoch 1, Loss: 1.1964614714088384e-05\n",
            "Epoch 1, Loss: 1.3541556654672604e-05\n",
            "Epoch 1, Loss: 1.238549066329142e-05\n",
            "Epoch 1, Loss: 1.31848210003227e-05\n",
            "Epoch 1, Loss: 1.0386765097791795e-05\n",
            "Epoch 1, Loss: 1.2424628039298113e-05\n",
            "Epoch 1, Loss: 1.3993731045047753e-05\n",
            "Epoch 1, Loss: 1.073284602171043e-05\n",
            "Epoch 1, Loss: 1.1695724424498621e-05\n",
            "Epoch 1, Loss: 1.1040772733394988e-05\n",
            "Epoch 1, Loss: 1.1537277714523952e-05\n",
            "Epoch 1, Loss: 1.420168064214522e-05\n",
            "Epoch 1, Loss: 1.1641088349279016e-05\n",
            "Epoch 1, Loss: 1.2093277291569393e-05\n",
            "Epoch 1, Loss: 1.3287415640661493e-05\n",
            "Epoch 1, Loss: 1.391617115586996e-05\n",
            "Epoch 1, Loss: 1.1738473403966054e-05\n",
            "Epoch 1, Loss: 1.4592742445529439e-05\n",
            "Epoch 1, Loss: 1.7795418898458593e-05\n",
            "Epoch 1, Loss: 1.1397227353882045e-05\n",
            "Epoch 1, Loss: 1.0534851753618568e-05\n",
            "Epoch 1, Loss: 1.2731685274047777e-05\n",
            "Epoch 1, Loss: 1.4166244909574743e-05\n",
            "Epoch 1, Loss: 1.227889606525423e-05\n",
            "Epoch 1, Loss: 1.268772393814288e-05\n",
            "Epoch 1, Loss: 1.137174513132777e-05\n",
            "Epoch 1, Loss: 1.3501246939995326e-05\n",
            "Epoch 1, Loss: 1.4472692782874219e-05\n",
            "Epoch 1, Loss: 1.2345198229013477e-05\n",
            "Epoch 1, Loss: 1.1516340236994438e-05\n",
            "Epoch 1, Loss: 1.2598229659488425e-05\n",
            "Epoch 1, Loss: 1.622274430701509e-05\n",
            "Epoch 1, Loss: 1.3188373486627825e-05\n",
            "Epoch 1, Loss: 1.1564897249627393e-05\n",
            "Epoch 1, Loss: 1.559891643410083e-05\n",
            "Epoch 1, Loss: 1.1688245649565943e-05\n",
            "Epoch 1, Loss: 1.2149619578849524e-05\n",
            "Epoch 1, Loss: 1.4105960872257128e-05\n",
            "Epoch 1, Loss: 1.1249019735259935e-05\n",
            "Epoch 1, Loss: 1.3352783753362019e-05\n",
            "Epoch 1, Loss: 1.2593274732353166e-05\n",
            "Epoch 1, Loss: 1.7130329069914296e-05\n",
            "Epoch 1, Loss: 1.1510336662468035e-05\n",
            "Epoch 1, Loss: 1.5279536455636844e-05\n",
            "Epoch 1, Loss: 1.0845311408047564e-05\n",
            "Epoch 1, Loss: 9.846782631939277e-06\n",
            "Epoch 1, Loss: 1.2041321497235913e-05\n",
            "Epoch 1, Loss: 1.2135776159993839e-05\n",
            "Epoch 1, Loss: 1.3537935046770144e-05\n",
            "Epoch 1, Loss: 1.1507658200571314e-05\n",
            "Epoch 1, Loss: 1.1231707503611688e-05\n",
            "Epoch 1, Loss: 1.1363125850039069e-05\n",
            "Epoch 1, Loss: 1.634230102354195e-05\n",
            "Epoch 1, Loss: 1.1120351700810716e-05\n",
            "Epoch 1, Loss: 1.1988157893938478e-05\n",
            "Epoch 1, Loss: 1.1719677786459215e-05\n",
            "Epoch 1, Loss: 1.315644749411149e-05\n",
            "Epoch 1, Loss: 1.2072503523086198e-05\n",
            "Epoch 1, Loss: 1.2313278602960054e-05\n",
            "Epoch 1, Loss: 1.3323847269930411e-05\n",
            "Epoch 1, Loss: 1.2791082554031163e-05\n",
            "Epoch 1, Loss: 1.0958779057546053e-05\n",
            "Epoch 1, Loss: 1.2588235222210642e-05\n",
            "Epoch 1, Loss: 1.3620646313938778e-05\n",
            "Epoch 1, Loss: 1.1413214451749809e-05\n",
            "Epoch 1, Loss: 1.45013591463794e-05\n",
            "Epoch 1, Loss: 1.2123861779400613e-05\n",
            "Epoch 1, Loss: 1.1611960871960036e-05\n",
            "Epoch 1, Loss: 1.1645197446341626e-05\n",
            "Epoch 1, Loss: 1.1625219485722482e-05\n",
            "Epoch 1, Loss: 1.2707503628917038e-05\n",
            "Epoch 1, Loss: 1.2104529560019728e-05\n",
            "Epoch 1, Loss: 1.1599451681831852e-05\n",
            "Epoch 1, Loss: 1.4511698282149155e-05\n",
            "Epoch 1, Loss: 1.2999037608096842e-05\n",
            "Epoch 1, Loss: 1.2619972039829008e-05\n",
            "Epoch 1, Loss: 9.994067113439087e-06\n",
            "Epoch 1, Loss: 1.1325987543386873e-05\n",
            "Epoch 1, Loss: 1.5070289009599946e-05\n",
            "Epoch 1, Loss: 1.1709174941643141e-05\n",
            "Epoch 1, Loss: 1.072940449375892e-05\n",
            "Epoch 1, Loss: 1.0942359949694946e-05\n",
            "Epoch 1, Loss: 1.4187970919010695e-05\n",
            "Epoch 1, Loss: 1.3132762433087919e-05\n",
            "Epoch 1, Loss: 1.08670801637345e-05\n",
            "Epoch 1, Loss: 1.1725267540896311e-05\n",
            "Epoch 1, Loss: 1.1850107512145769e-05\n",
            "Epoch 1, Loss: 1.2649426025745925e-05\n",
            "Epoch 1, Loss: 1.3365047379920725e-05\n",
            "Epoch 1, Loss: 1.2742004400934093e-05\n",
            "Epoch 1, Loss: 1.0903894690272864e-05\n",
            "Epoch 1, Loss: 1.0741884580056649e-05\n",
            "Epoch 1, Loss: 1.2646635696000885e-05\n",
            "Epoch 1, Loss: 1.3651290828420315e-05\n",
            "Epoch 1, Loss: 1.2022009286738466e-05\n",
            "Epoch 1, Loss: 1.239576067746384e-05\n",
            "Epoch 1, Loss: 1.2362825145828538e-05\n",
            "Epoch 1, Loss: 1.1218219697184395e-05\n",
            "Epoch 1, Loss: 1.3398328519542702e-05\n",
            "Epoch 1, Loss: 1.1483775779197458e-05\n",
            "Epoch 1, Loss: 1.5234935744956601e-05\n",
            "Epoch 1, Loss: 1.4510848814097699e-05\n",
            "Epoch 1, Loss: 9.888835847959854e-06\n",
            "Epoch 1, Loss: 1.3098875569994561e-05\n",
            "Epoch 1, Loss: 1.0368117727921344e-05\n",
            "Epoch 1, Loss: 1.3611782378575299e-05\n",
            "Epoch 1, Loss: 1.0826933248608839e-05\n",
            "Epoch 1, Loss: 1.5038302080938593e-05\n",
            "Epoch 1, Loss: 1.0929236850643065e-05\n",
            "Epoch 1, Loss: 1.2960230378666893e-05\n",
            "Epoch 1, Loss: 1.1903508493560366e-05\n",
            "Epoch 1, Loss: 1.2508032341429498e-05\n",
            "Epoch 1, Loss: 1.2546118341560941e-05\n",
            "Epoch 1, Loss: 1.0930165444733575e-05\n",
            "Epoch 1, Loss: 1.2573949788929895e-05\n",
            "Epoch 1, Loss: 1.046809211402433e-05\n",
            "Epoch 1, Loss: 1.0863440365938004e-05\n",
            "Epoch 1, Loss: 1.0845723409147467e-05\n",
            "Epoch 1, Loss: 1.0508596460567787e-05\n",
            "Epoch 1, Loss: 1.2824782970710658e-05\n",
            "Epoch 1, Loss: 1.3554872566601261e-05\n",
            "Epoch 1, Loss: 1.5795558283571154e-05\n",
            "Epoch 1, Loss: 1.003957095235819e-05\n",
            "Epoch 1, Loss: 1.2165717635070905e-05\n",
            "Epoch 1, Loss: 1.2647968105738983e-05\n",
            "Epoch 1, Loss: 1.3258736544230487e-05\n",
            "Epoch 1, Loss: 1.3325246072781738e-05\n",
            "Epoch 1, Loss: 1.1448798431956675e-05\n",
            "Epoch 1, Loss: 1.3843891792930663e-05\n",
            "Epoch 1, Loss: 1.0413506970508024e-05\n",
            "Epoch 1, Loss: 1.1213790457986761e-05\n",
            "Epoch 1, Loss: 9.072547982214019e-06\n",
            "Epoch 1, Loss: 1.0844896678463556e-05\n",
            "Epoch 1, Loss: 1.1526346497703344e-05\n",
            "Epoch 1, Loss: 1.1447347787907347e-05\n",
            "Epoch 1, Loss: 1.1306771739327814e-05\n",
            "Epoch 1, Loss: 1.1951113265240565e-05\n",
            "Epoch 1, Loss: 1.3443112038658e-05\n",
            "Epoch 1, Loss: 1.1774423001043033e-05\n",
            "Epoch 1, Loss: 1.0987091627612244e-05\n",
            "Epoch 1, Loss: 1.2829553270421457e-05\n",
            "Epoch 1, Loss: 1.1237544640607666e-05\n",
            "Epoch 1, Loss: 1.1292844646959566e-05\n",
            "Epoch 1, Loss: 1.1195546903763898e-05\n",
            "Epoch 1, Loss: 1.2643548870983068e-05\n",
            "Epoch 1, Loss: 1.3313537237991113e-05\n",
            "Epoch 1, Loss: 1.1829945833596867e-05\n",
            "Epoch 1, Loss: 1.3283285625220742e-05\n",
            "Epoch 1, Loss: 1.2467770829971414e-05\n",
            "Epoch 1, Loss: 1.037995571095962e-05\n",
            "Epoch 1, Loss: 1.3159547052055132e-05\n",
            "Epoch 1, Loss: 1.1800098036474083e-05\n",
            "Epoch 1, Loss: 1.000046540866606e-05\n",
            "Epoch 1, Loss: 1.207915829581907e-05\n",
            "Epoch 1, Loss: 1.1614541108428966e-05\n",
            "Epoch 1, Loss: 1.0317059604858514e-05\n",
            "Epoch 1, Loss: 1.26414106489392e-05\n",
            "Epoch 1, Loss: 1.0604407179926056e-05\n",
            "Epoch 1, Loss: 1.0195702088822145e-05\n",
            "Epoch 1, Loss: 1.007911214401247e-05\n",
            "Epoch 1, Loss: 1.0352111530664843e-05\n",
            "Epoch 1, Loss: 1.1204658221686259e-05\n",
            "Epoch 1, Loss: 1.2932012396049686e-05\n",
            "Epoch 1, Loss: 1.0443690371175762e-05\n",
            "Epoch 1, Loss: 1.1894592716998886e-05\n",
            "Epoch 1, Loss: 1.2171698472229764e-05\n",
            "Epoch 1, Loss: 1.2729999980365392e-05\n",
            "Epoch 1, Loss: 1.3920142009737901e-05\n",
            "Epoch 1, Loss: 1.0508283594390377e-05\n",
            "Epoch 1, Loss: 1.1266316505498253e-05\n",
            "Epoch 1, Loss: 1.1640167940640822e-05\n",
            "Epoch 1, Loss: 1.0767854291771073e-05\n",
            "Epoch 1, Loss: 1.4615779946325347e-05\n",
            "Epoch 1, Loss: 1.2301630704314448e-05\n",
            "Epoch 1, Loss: 1.2162968232587446e-05\n",
            "Epoch 1, Loss: 1.1576842553040478e-05\n",
            "Epoch 1, Loss: 9.534097443975043e-06\n",
            "Epoch 1, Loss: 1.201350551127689e-05\n",
            "Epoch 1, Loss: 1.3206621588324197e-05\n",
            "Epoch 1, Loss: 1.3759455214312766e-05\n",
            "Epoch 1, Loss: 1.1213078323635273e-05\n",
            "Epoch 1, Loss: 1.572228029544931e-05\n",
            "Epoch 1, Loss: 1.5789535609656014e-05\n",
            "Epoch 1, Loss: 9.115709872276057e-06\n",
            "Epoch 1, Loss: 1.4011508937983308e-05\n",
            "Epoch 1, Loss: 1.1883355909958482e-05\n",
            "Epoch 1, Loss: 1.032841555570485e-05\n",
            "Epoch 1, Loss: 1.477622936363332e-05\n",
            "Epoch 1, Loss: 1.1992103281954769e-05\n",
            "Epoch 1, Loss: 1.56634359882446e-05\n",
            "Epoch 1, Loss: 1.1883049410243984e-05\n",
            "Epoch 1, Loss: 1.4522445781040005e-05\n",
            "Epoch 1, Loss: 1.3528568160836585e-05\n",
            "Epoch 1, Loss: 1.1330779670970514e-05\n",
            "Epoch 1, Loss: 1.548366890347097e-05\n",
            "Epoch 1, Loss: 1.5317078577936627e-05\n",
            "Epoch 1, Loss: 1.3388736988417804e-05\n",
            "Epoch 1, Loss: 1.1198065294593107e-05\n",
            "Epoch 1, Loss: 1.1292762792436406e-05\n",
            "Epoch 1, Loss: 1.1320634257572237e-05\n",
            "Epoch 1, Loss: 1.0432815543026663e-05\n",
            "Epoch 1, Loss: 1.5063158571138047e-05\n",
            "Epoch 1, Loss: 1.2220485587022267e-05\n",
            "Epoch 1, Loss: 1.044557211571373e-05\n",
            "Epoch 1, Loss: 1.0723885679908562e-05\n",
            "Epoch 1, Loss: 1.5077872376423329e-05\n",
            "Epoch 1, Loss: 1.1113023901998531e-05\n",
            "Epoch 1, Loss: 1.2787811101588886e-05\n",
            "Epoch 1, Loss: 1.3790045159112196e-05\n",
            "Epoch 1, Loss: 1.3335610674403142e-05\n",
            "Epoch 1, Loss: 1.1704549251589924e-05\n",
            "Epoch 1, Loss: 1.2011380931653548e-05\n",
            "Epoch 1, Loss: 1.2305169548199046e-05\n",
            "Epoch 1, Loss: 1.1969052138738334e-05\n",
            "Epoch 1, Loss: 1.1997273759334348e-05\n",
            "Epoch 1, Loss: 1.3168747500458267e-05\n",
            "Epoch 1, Loss: 1.1942977835133206e-05\n",
            "Epoch 1, Loss: 1.1627219464571681e-05\n",
            "Epoch 1, Loss: 2.7381953259464353e-05\n",
            "Epoch 1, Loss: 1.0189419299422298e-05\n",
            "Epoch 1, Loss: 1.2109815543226432e-05\n",
            "Epoch 1, Loss: 1.3093000234221108e-05\n",
            "Epoch 1, Loss: 3.37916862918064e-05\n",
            "Epoch 1, Loss: 1.2642981346289162e-05\n",
            "Epoch 1, Loss: 1.419159525539726e-05\n",
            "Epoch 1, Loss: 1.8847922547138296e-05\n",
            "Epoch 1, Loss: 2.6672356398194097e-05\n",
            "Epoch 1, Loss: 1.305729711020831e-05\n",
            "Epoch 1, Loss: 1.3050894267507829e-05\n",
            "Epoch 1, Loss: 4.5445121941156685e-05\n",
            "Epoch 1, Loss: 1.2400716514093801e-05\n",
            "Epoch 1, Loss: 1.340472499578027e-05\n",
            "Epoch 1, Loss: 1.541891833767295e-05\n",
            "Epoch 1, Loss: 2.18301920540398e-05\n",
            "Epoch 1, Loss: 1.583491757628508e-05\n",
            "Epoch 1, Loss: 1.8748705770121887e-05\n",
            "Epoch 1, Loss: 1.536298259452451e-05\n",
            "Epoch 1, Loss: 1.3468337783706374e-05\n",
            "Epoch 1, Loss: 1.997545041376725e-05\n",
            "Epoch 1, Loss: 2.0132254576310515e-05\n",
            "Epoch 1, Loss: 5.493086064234376e-05\n",
            "Epoch 1, Loss: 2.6291578251402825e-05\n",
            "Epoch 1, Loss: 4.50609004474245e-05\n",
            "Epoch 1, Loss: 2.6706766220740974e-05\n",
            "Epoch 1, Loss: 2.5017858206410892e-05\n",
            "Epoch 1, Loss: 1.8170298062614165e-05\n",
            "Epoch 1, Loss: 5.887559018447064e-05\n",
            "Epoch 1, Loss: 1.9153474568156525e-05\n",
            "Epoch 1, Loss: 2.362946906941943e-05\n",
            "Epoch 1, Loss: 0.00011654817353701219\n",
            "Epoch 1, Loss: 2.4914015739341266e-05\n",
            "Epoch 1, Loss: 3.399170600459911e-05\n",
            "Epoch 1, Loss: 0.00010690644558053464\n",
            "Epoch 1, Loss: 0.00044040667125955224\n",
            "Epoch 1, Loss: 4.2323776142438874e-05\n",
            "Epoch 1, Loss: 0.0018489048816263676\n",
            "Epoch 1, Loss: 4.9763093556975946e-05\n",
            "Epoch 1, Loss: 0.00019066888489760458\n",
            "Epoch 1, Loss: 0.0021997718140482903\n",
            "Epoch 1, Loss: 0.0002641754981596023\n",
            "Epoch 1, Loss: 5.655932181980461e-05\n",
            "Epoch 1, Loss: 8.33528974908404e-05\n",
            "Epoch 1, Loss: 0.00024361239047721028\n",
            "Epoch 1, Loss: 0.0014526924351230264\n",
            "Epoch 1, Loss: 0.0006050772499293089\n",
            "Epoch 1, Loss: 7.751715020276606e-05\n",
            "Epoch 1, Loss: 0.00010162194666918367\n",
            "Epoch 1, Loss: 0.0001816941803554073\n",
            "Epoch 1, Loss: 0.001252050162293017\n",
            "Epoch 1, Loss: 0.00014444967382587492\n",
            "Epoch 1, Loss: 0.00011986090248683468\n",
            "Epoch 1, Loss: 0.0002778897469397634\n",
            "Epoch 1, Loss: 0.00040389125933870673\n",
            "Epoch 1, Loss: 0.0009697820642031729\n",
            "Epoch 1, Loss: 0.0001914614113047719\n",
            "Epoch 1, Loss: 8.496981172356755e-05\n",
            "Epoch 1, Loss: 5.969592530163936e-05\n",
            "Epoch 1, Loss: 0.0002807159617077559\n",
            "Epoch 1, Loss: 0.00010731165093602613\n",
            "Epoch 1, Loss: 0.0006034118123352528\n",
            "Epoch 1, Loss: 0.0002160963776987046\n",
            "Epoch 1, Loss: 0.00013155215128790587\n",
            "Epoch 1, Loss: 0.00010622793342918158\n",
            "Epoch 1, Loss: 6.052055687177926e-05\n",
            "Epoch 1, Loss: 0.00011593037925194949\n",
            "Epoch 1, Loss: 0.00010084697714773938\n",
            "Epoch 1, Loss: 0.00011175307008670643\n",
            "Epoch 1, Loss: 9.565467917127535e-05\n",
            "Epoch 1, Loss: 8.045776485232636e-05\n",
            "Epoch 1, Loss: 0.00018631789134815335\n",
            "Epoch 1, Loss: 0.00013801972090732306\n",
            "Epoch 1, Loss: 6.352760101435706e-05\n",
            "Epoch 1, Loss: 4.58200229331851e-05\n",
            "Epoch 1, Loss: 7.00620876159519e-05\n",
            "Epoch 1, Loss: 6.747220322722569e-05\n",
            "Epoch 1, Loss: 4.910519783152267e-05\n",
            "Epoch 1, Loss: 6.738528463756666e-05\n",
            "Epoch 1, Loss: 4.9522470362717286e-05\n",
            "Epoch 1, Loss: 5.688205419573933e-05\n",
            "Epoch 1, Loss: 4.0418213757220656e-05\n",
            "Epoch 1, Loss: 4.257693944964558e-05\n",
            "Epoch 1, Loss: 7.111406011972576e-05\n",
            "Epoch 1, Loss: 4.7754972911207005e-05\n",
            "Epoch 1, Loss: 8.39851054479368e-05\n",
            "Epoch 1, Loss: 5.7101315178442746e-05\n",
            "Epoch 1, Loss: 4.730267755803652e-05\n",
            "Epoch 1, Loss: 3.9402832044288516e-05\n",
            "Epoch 1, Loss: 5.382294693845324e-05\n",
            "Epoch 1, Loss: 4.926557812723331e-05\n",
            "Epoch 1, Loss: 5.320144919096492e-05\n",
            "Epoch 1, Loss: 4.042877480969764e-05\n",
            "Epoch 1, Loss: 4.6787088649580255e-05\n",
            "Epoch 1, Loss: 5.77514547330793e-05\n",
            "Epoch 1, Loss: 3.347740130266175e-05\n",
            "Epoch 1, Loss: 4.197340604150668e-05\n",
            "Epoch 1, Loss: 4.6199202188290656e-05\n",
            "Epoch 1, Loss: 3.53045470546931e-05\n",
            "Epoch 1, Loss: 3.8848895201226696e-05\n",
            "Epoch 1, Loss: 3.5247878258815035e-05\n",
            "Epoch 1, Loss: 3.298898081993684e-05\n",
            "Epoch 1, Loss: 5.126501127961092e-05\n",
            "Epoch 1, Loss: 3.97946969314944e-05\n",
            "Epoch 1, Loss: 3.564945291145705e-05\n",
            "Epoch 1, Loss: 3.6847330193268135e-05\n",
            "Epoch 1, Loss: 3.657857814687304e-05\n",
            "Epoch 1, Loss: 3.4093798603862524e-05\n",
            "Epoch 1, Loss: 3.1062001653481275e-05\n",
            "Epoch 1, Loss: 4.04621496272739e-05\n",
            "Epoch 1, Loss: 2.4509989088983275e-05\n",
            "Epoch 1, Loss: 4.6600667701568455e-05\n",
            "Epoch 1, Loss: 4.3551859562285244e-05\n",
            "Epoch 1, Loss: 3.3015232475008816e-05\n",
            "Epoch 1, Loss: 2.5308539989055134e-05\n",
            "Epoch 1, Loss: 5.486961526912637e-05\n",
            "Epoch 1, Loss: 3.610899511841126e-05\n",
            "Epoch 1, Loss: 5.0588339945534244e-05\n",
            "Epoch 1, Loss: 2.430844324408099e-05\n",
            "Epoch 1, Loss: 3.629836646723561e-05\n",
            "Epoch 1, Loss: 2.8950978958164342e-05\n",
            "Epoch 1, Loss: 3.303790799691342e-05\n",
            "Epoch 1, Loss: 3.0003016945556737e-05\n",
            "Epoch 1, Loss: 2.7531817977433093e-05\n",
            "Epoch 1, Loss: 3.0000484912307e-05\n",
            "Epoch 1, Loss: 2.422387115075253e-05\n",
            "Epoch 1, Loss: 4.3578977056313306e-05\n",
            "Epoch 1, Loss: 3.051618296012748e-05\n",
            "Epoch 1, Loss: 2.305975249328185e-05\n",
            "Epoch 1, Loss: 2.628258334880229e-05\n",
            "Epoch 1, Loss: 2.9962649932713248e-05\n",
            "Epoch 1, Loss: 3.0299635909614153e-05\n",
            "Epoch 1, Loss: 3.1792264053365216e-05\n",
            "Epoch 1, Loss: 3.840103090624325e-05\n",
            "Epoch 1, Loss: 3.237184864701703e-05\n",
            "Epoch 1, Loss: 3.519206074997783e-05\n",
            "Epoch 1, Loss: 3.088321682298556e-05\n",
            "Epoch 1, Loss: 3.468107752269134e-05\n",
            "Epoch 1, Loss: 2.6231020456179976e-05\n",
            "Epoch 1, Loss: 3.6742578231496736e-05\n",
            "Epoch 1, Loss: 3.237014971091412e-05\n",
            "Epoch 1, Loss: 3.0623185011791065e-05\n",
            "Epoch 1, Loss: 2.9827628168277442e-05\n",
            "Epoch 1, Loss: 3.50748268829193e-05\n",
            "Epoch 1, Loss: 2.9107559385010973e-05\n",
            "Epoch 1, Loss: 3.5472203308017924e-05\n",
            "Epoch 1, Loss: 3.3852422347990796e-05\n",
            "Epoch 1, Loss: 2.6075493224198e-05\n",
            "Epoch 1, Loss: 2.5172454115818255e-05\n",
            "Epoch 1, Loss: 2.4642031348776072e-05\n",
            "Epoch 1, Loss: 3.156159073114395e-05\n",
            "Epoch 1, Loss: 2.723758552747313e-05\n",
            "Epoch 1, Loss: 2.3072056137607433e-05\n",
            "Epoch 1, Loss: 3.808776818914339e-05\n",
            "Epoch 1, Loss: 3.188615301041864e-05\n",
            "Epoch 1, Loss: 2.8965063393115997e-05\n",
            "Epoch 1, Loss: 2.844847404048778e-05\n",
            "Epoch 1, Loss: 1.9594546756707132e-05\n",
            "Epoch 1, Loss: 2.859565574908629e-05\n",
            "Epoch 1, Loss: 2.8206353817950003e-05\n",
            "Epoch 1, Loss: 2.4206621674238704e-05\n",
            "Epoch 1, Loss: 3.2533200283069164e-05\n",
            "Epoch 1, Loss: 2.5731480491231196e-05\n",
            "Epoch 1, Loss: 4.0441595047013834e-05\n",
            "Epoch 1, Loss: 3.085864955210127e-05\n",
            "Epoch 1, Loss: 2.211232276749797e-05\n",
            "Epoch 1, Loss: 3.5777524317381904e-05\n",
            "Epoch 1, Loss: 2.378176577622071e-05\n",
            "Epoch 1, Loss: 2.174403562094085e-05\n",
            "Epoch 1, Loss: 2.5615610866225325e-05\n",
            "Epoch 1, Loss: 2.5041950721060857e-05\n",
            "Epoch 1, Loss: 2.0780023987754248e-05\n",
            "Epoch 1, Loss: 2.702820893318858e-05\n",
            "Epoch 1, Loss: 2.2968803023104556e-05\n",
            "Epoch 1, Loss: 2.4119512090692297e-05\n",
            "Epoch 1, Loss: 3.560052209650166e-05\n",
            "Epoch 1, Loss: 2.35880052059656e-05\n",
            "Epoch 1, Loss: 2.2266112864599563e-05\n",
            "Epoch 1, Loss: 2.8601971280295402e-05\n",
            "Epoch 1, Loss: 2.1602269043796696e-05\n",
            "Epoch 1, Loss: 3.176582686137408e-05\n",
            "Epoch 1, Loss: 1.9478537069517188e-05\n",
            "Epoch 1, Loss: 2.5693145289551467e-05\n",
            "Epoch 1, Loss: 2.985519495268818e-05\n",
            "Epoch 1, Loss: 3.00536303257104e-05\n",
            "Epoch 1, Loss: 3.428246054681949e-05\n",
            "Epoch 1, Loss: 2.206853787356522e-05\n",
            "Epoch 1, Loss: 2.038819366134703e-05\n",
            "Epoch 1, Loss: 3.071387254749425e-05\n",
            "Epoch 1, Loss: 2.1619740437017754e-05\n",
            "Epoch 1, Loss: 2.4142176698660478e-05\n",
            "Epoch 1, Loss: 3.768885653698817e-05\n",
            "Epoch 1, Loss: 2.3220358343678527e-05\n",
            "Epoch 1, Loss: 2.2015599824953824e-05\n",
            "Epoch 1, Loss: 6.738289084751159e-05\n",
            "Epoch 1, Loss: 3.0276258257799782e-05\n",
            "Epoch 1, Loss: 2.4877250325516798e-05\n",
            "Epoch 1, Loss: 1.969741060747765e-05\n",
            "Epoch 1, Loss: 2.488234531483613e-05\n",
            "Epoch 1, Loss: 2.3689908630331047e-05\n",
            "Epoch 1, Loss: 2.168603168684058e-05\n",
            "Epoch 1, Loss: 2.222859075118322e-05\n",
            "Epoch 1, Loss: 1.8749904484138824e-05\n",
            "Epoch 1, Loss: 2.0265928469598293e-05\n",
            "Epoch 1, Loss: 2.1478159396792762e-05\n",
            "Epoch 1, Loss: 2.7817970476462506e-05\n",
            "Epoch 1, Loss: 2.9561679184553213e-05\n",
            "Epoch 1, Loss: 2.085281812469475e-05\n",
            "Epoch 1, Loss: 2.2060208721086383e-05\n",
            "Epoch 1, Loss: 1.8634107618709095e-05\n",
            "Epoch 1, Loss: 2.2110632926342078e-05\n",
            "Epoch 1, Loss: 2.9656444894499145e-05\n",
            "Epoch 1, Loss: 2.2278141841525212e-05\n",
            "Epoch 1, Loss: 2.4218214093707502e-05\n",
            "Epoch 1, Loss: 2.1152542103664018e-05\n",
            "Epoch 1, Loss: 2.3697977667325176e-05\n",
            "Epoch 1, Loss: 2.2659300157101825e-05\n",
            "Epoch 1, Loss: 2.2216659999685362e-05\n",
            "Epoch 1, Loss: 2.0296251022955403e-05\n",
            "Epoch 1, Loss: 2.3166187020251527e-05\n",
            "Epoch 1, Loss: 1.6541738659725524e-05\n",
            "Epoch 1, Loss: 1.6228676031460054e-05\n",
            "Epoch 1, Loss: 2.544351627875585e-05\n",
            "Epoch 1, Loss: 2.8779832064174116e-05\n",
            "Epoch 1, Loss: 2.528612094465643e-05\n",
            "Epoch 1, Loss: 2.601565938675776e-05\n",
            "Epoch 1, Loss: 1.8708629795582965e-05\n",
            "Epoch 1, Loss: 2.815293919411488e-05\n",
            "Epoch 1, Loss: 1.7398302588844672e-05\n",
            "Epoch 1, Loss: 2.7676676836563274e-05\n",
            "Epoch 1, Loss: 2.0555440642056055e-05\n",
            "Epoch 1, Loss: 3.089558958890848e-05\n",
            "Epoch 1, Loss: 1.6651943951728754e-05\n",
            "Epoch 1, Loss: 1.9939956473535858e-05\n",
            "Epoch 1, Loss: 1.860583506640978e-05\n",
            "Epoch 1, Loss: 2.178318754886277e-05\n",
            "Epoch 1, Loss: 2.7272100851405412e-05\n",
            "Epoch 1, Loss: 1.9131091903545894e-05\n",
            "Epoch 1, Loss: 2.1173671484575607e-05\n",
            "Epoch 1, Loss: 2.323931948922109e-05\n",
            "Epoch 1, Loss: 2.101208156091161e-05\n",
            "Epoch 1, Loss: 2.1098423530929722e-05\n",
            "Epoch 1, Loss: 2.1336591089493595e-05\n",
            "Epoch 1, Loss: 1.7140131603810005e-05\n",
            "Epoch 1, Loss: 2.1875646780245006e-05\n",
            "Epoch 1, Loss: 2.075570409942884e-05\n",
            "Epoch 1, Loss: 2.097021024383139e-05\n",
            "Epoch 1, Loss: 2.093158218485769e-05\n",
            "Epoch 1, Loss: 2.653538467711769e-05\n",
            "Epoch 1, Loss: 1.7600716091692448e-05\n",
            "Epoch 1, Loss: 2.518100882298313e-05\n",
            "Epoch 1, Loss: 2.3145696104620583e-05\n",
            "Epoch 1, Loss: 1.8542974430602044e-05\n",
            "Epoch 1, Loss: 3.073338302783668e-05\n",
            "Epoch 1, Loss: 2.2586542399949394e-05\n",
            "Epoch 1, Loss: 2.5071902200579643e-05\n",
            "Epoch 1, Loss: 2.0417070118128322e-05\n",
            "Epoch 1, Loss: 2.1429297703434713e-05\n",
            "Epoch 1, Loss: 1.946916563611012e-05\n",
            "Epoch 1, Loss: 1.8609509425004944e-05\n",
            "Epoch 1, Loss: 2.3193933884613216e-05\n",
            "Epoch 1, Loss: 4.148548032389954e-05\n",
            "Epoch 1, Loss: 1.908172998810187e-05\n",
            "Epoch 1, Loss: 2.0336214220151305e-05\n",
            "Epoch 1, Loss: 1.8135615391656756e-05\n",
            "Epoch 1, Loss: 2.3646703994018026e-05\n",
            "Epoch 1, Loss: 1.9935872842324898e-05\n",
            "Epoch 1, Loss: 2.1810343241668306e-05\n",
            "Epoch 1, Loss: 2.0557261450449005e-05\n",
            "Epoch 1, Loss: 2.0486002540565096e-05\n",
            "Epoch 1, Loss: 2.1658406694768928e-05\n",
            "Epoch 1, Loss: 2.1325387933757156e-05\n",
            "Epoch 1, Loss: 1.864253317762632e-05\n",
            "Epoch 1, Loss: 1.691777833912056e-05\n",
            "Epoch 1, Loss: 2.1189813196542673e-05\n",
            "Epoch 1, Loss: 1.8932576494989917e-05\n",
            "Epoch 1, Loss: 1.480014543631114e-05\n",
            "Epoch 1, Loss: 2.4405282601946965e-05\n",
            "Epoch 1, Loss: 1.5959967640810646e-05\n",
            "Epoch 1, Loss: 1.6249805412371643e-05\n",
            "Epoch 1, Loss: 2.2468406314146705e-05\n",
            "Epoch 1, Loss: 1.789706220733933e-05\n",
            "Epoch 1, Loss: 2.1905076209804974e-05\n",
            "Epoch 1, Loss: 2.4275366740766913e-05\n",
            "Epoch 1, Loss: 1.5605997759848833e-05\n",
            "Epoch 1, Loss: 1.8920247384812683e-05\n",
            "Epoch 1, Loss: 2.2935140805202536e-05\n",
            "Epoch 1, Loss: 2.059148573607672e-05\n",
            "Epoch 1, Loss: 1.8487524357624352e-05\n",
            "Epoch 1, Loss: 2.0807881810469553e-05\n",
            "Epoch 1, Loss: 2.581871194706764e-05\n",
            "Epoch 1, Loss: 1.7790798665373586e-05\n",
            "Epoch 1, Loss: 2.156785922124982e-05\n",
            "Epoch 1, Loss: 2.0518129531410523e-05\n",
            "Epoch 1, Loss: 1.7183516320073977e-05\n",
            "Epoch 1, Loss: 3.080060560023412e-05\n",
            "Epoch 1, Loss: 1.5099404663487803e-05\n",
            "Epoch 1, Loss: 1.6226938896579668e-05\n",
            "Epoch 1, Loss: 1.8254670067108236e-05\n",
            "Epoch 1, Loss: 2.126650906575378e-05\n",
            "Epoch 1, Loss: 1.4912973711034283e-05\n",
            "Epoch 1, Loss: 1.9034267097595148e-05\n",
            "Epoch 1, Loss: 1.4400622603716329e-05\n",
            "Epoch 1, Loss: 1.634834370634053e-05\n",
            "Epoch 1, Loss: 2.4681052309460938e-05\n",
            "Epoch 1, Loss: 1.9873456039931625e-05\n",
            "Epoch 1, Loss: 2.1259606000967324e-05\n",
            "Epoch 1, Loss: 1.7459851733292453e-05\n",
            "Epoch 1, Loss: 1.4742550774826668e-05\n",
            "Epoch 1, Loss: 1.5880725186434574e-05\n",
            "Epoch 1, Loss: 1.7726462829159573e-05\n",
            "Epoch 1, Loss: 1.6346488337148912e-05\n",
            "Epoch 1, Loss: 2.0927574951201677e-05\n",
            "Epoch 1, Loss: 1.817956581362523e-05\n",
            "Epoch 1, Loss: 1.771204188116826e-05\n",
            "Epoch 1, Loss: 1.8407103198114783e-05\n",
            "Epoch 1, Loss: 2.5043544155778363e-05\n",
            "Epoch 1, Loss: 2.6117428205907345e-05\n",
            "Epoch 1, Loss: 1.5047527995193377e-05\n",
            "Epoch 1, Loss: 2.4436201783828437e-05\n",
            "Epoch 1, Loss: 1.9676886950037442e-05\n",
            "Epoch 1, Loss: 2.046705048996955e-05\n",
            "Epoch 1, Loss: 2.4885210223146714e-05\n",
            "Epoch 1, Loss: 1.8010090570896864e-05\n",
            "Epoch 1, Loss: 2.759673043328803e-05\n",
            "Epoch 1, Loss: 1.630612496228423e-05\n",
            "Epoch 1, Loss: 1.8864351659431122e-05\n",
            "Epoch 1, Loss: 4.540480222203769e-05\n",
            "Epoch 1, Loss: 1.8387272575637326e-05\n",
            "Epoch 1, Loss: 1.6620509995846078e-05\n",
            "Epoch 1, Loss: 1.905265344248619e-05\n",
            "Epoch 1, Loss: 2.090315319946967e-05\n",
            "Epoch 1, Loss: 2.88811388600152e-05\n",
            "Epoch 1, Loss: 1.8985107089974917e-05\n",
            "Epoch 1, Loss: 1.771271854522638e-05\n",
            "Epoch 1, Loss: 2.0520403268164955e-05\n",
            "Epoch 1, Loss: 1.4329762962006498e-05\n",
            "Epoch 1, Loss: 1.7561131244292483e-05\n",
            "Epoch 1, Loss: 2.5328468836960383e-05\n",
            "Epoch 1, Loss: 1.5937097487039864e-05\n",
            "Epoch 1, Loss: 2.0345505618024617e-05\n",
            "Epoch 1, Loss: 1.760397026373539e-05\n",
            "Epoch 1, Loss: 1.3163000403437763e-05\n",
            "Epoch 1, Loss: 1.4671852113679051e-05\n",
            "Epoch 1, Loss: 1.9169014194631018e-05\n",
            "Epoch 1, Loss: 2.3006312403595075e-05\n",
            "Epoch 1, Loss: 1.6709431292838417e-05\n",
            "Epoch 1, Loss: 1.83344727702206e-05\n",
            "Epoch 1, Loss: 1.9617136786109768e-05\n",
            "Epoch 1, Loss: 1.8366828953730874e-05\n",
            "Epoch 1, Loss: 1.8015873138210736e-05\n",
            "Epoch 1, Loss: 2.0711500837933272e-05\n",
            "Epoch 1, Loss: 1.7844866306404583e-05\n",
            "Epoch 1, Loss: 1.5364907085313462e-05\n",
            "Epoch 1, Loss: 1.5490591977140866e-05\n",
            "Epoch 1, Loss: 1.9080302081420086e-05\n",
            "Epoch 1, Loss: 1.9079418052569963e-05\n",
            "Epoch 1, Loss: 1.5500221707043238e-05\n",
            "Epoch 1, Loss: 2.1441830540425144e-05\n",
            "Epoch 1, Loss: 1.6023583157220855e-05\n",
            "Epoch 1, Loss: 3.098418892477639e-05\n",
            "Epoch 1, Loss: 1.5955492926877923e-05\n",
            "Epoch 1, Loss: 2.026112997555174e-05\n",
            "Epoch 1, Loss: 1.614191751286853e-05\n",
            "Epoch 1, Loss: 1.7979051335714757e-05\n",
            "Epoch 1, Loss: 1.488422913098475e-05\n",
            "Epoch 1, Loss: 2.0620969735318795e-05\n",
            "Epoch 1, Loss: 2.115311326633673e-05\n",
            "Epoch 1, Loss: 1.495403193985112e-05\n",
            "Epoch 1, Loss: 1.7636253687669523e-05\n",
            "Epoch 1, Loss: 1.6311129002133384e-05\n",
            "Epoch 1, Loss: 1.561007411510218e-05\n",
            "Epoch 1, Loss: 1.5011514733487274e-05\n",
            "Epoch 1, Loss: 1.767436151567381e-05\n",
            "Epoch 1, Loss: 1.7875150660984218e-05\n",
            "Epoch 1, Loss: 3.8021775253582746e-05\n",
            "Epoch 1, Loss: 2.7384359782445244e-05\n",
            "Epoch 1, Loss: 1.6674135622452013e-05\n",
            "Epoch 1, Loss: 1.5946507119224407e-05\n",
            "Epoch 1, Loss: 1.9700390112120658e-05\n",
            "Epoch 1, Loss: 1.581648029969074e-05\n",
            "Epoch 1, Loss: 1.6082001820905134e-05\n",
            "Epoch 1, Loss: 1.7825916074798442e-05\n",
            "Epoch 1, Loss: 1.6596768546150997e-05\n",
            "Epoch 1, Loss: 2.2442151021095924e-05\n",
            "Epoch 1, Loss: 1.392611738992855e-05\n",
            "Epoch 1, Loss: 2.572894845798146e-05\n",
            "Epoch 1, Loss: 3.11902113026008e-05\n",
            "Epoch 1, Loss: 1.6838734154589474e-05\n",
            "Epoch 1, Loss: 1.774475458660163e-05\n",
            "Epoch 1, Loss: 1.560643795528449e-05\n",
            "Epoch 1, Loss: 1.9102015357930213e-05\n",
            "Epoch 1, Loss: 2.049393515335396e-05\n",
            "Epoch 1, Loss: 2.1269559510983527e-05\n",
            "Epoch 1, Loss: 1.9054421500186436e-05\n",
            "Epoch 1, Loss: 1.7991946151596494e-05\n",
            "Epoch 1, Loss: 1.737095954013057e-05\n",
            "Epoch 1, Loss: 1.4029165868123528e-05\n",
            "Epoch 1, Loss: 1.1602457561821211e-05\n",
            "Epoch 1, Loss: 1.580201569595374e-05\n",
            "Epoch 1, Loss: 1.6529103959328495e-05\n",
            "Epoch 1, Loss: 1.7802074580686167e-05\n",
            "Epoch 1, Loss: 1.7863918401417322e-05\n",
            "Epoch 1, Loss: 1.3949042113381438e-05\n",
            "Epoch 1, Loss: 1.952121419890318e-05\n",
            "Epoch 1, Loss: 1.949435318238102e-05\n",
            "Epoch 1, Loss: 2.0666850105044432e-05\n",
            "Epoch 1, Loss: 1.764074113452807e-05\n",
            "Epoch 1, Loss: 1.5646917745471e-05\n",
            "Epoch 1, Loss: 1.594736568222288e-05\n",
            "Epoch 1, Loss: 1.7742406271281652e-05\n",
            "Epoch 1, Loss: 1.3764995856035966e-05\n",
            "Epoch 1, Loss: 1.5446952602360398e-05\n",
            "Epoch 1, Loss: 1.679350680205971e-05\n",
            "Epoch 1, Loss: 2.0052288164151832e-05\n",
            "Epoch 1, Loss: 1.620857437956147e-05\n",
            "Epoch 1, Loss: 1.7853983081295155e-05\n",
            "Epoch 1, Loss: 1.3792721802019514e-05\n",
            "Epoch 1, Loss: 1.8121276298188604e-05\n",
            "Epoch 1, Loss: 1.5534609701717272e-05\n",
            "Epoch 1, Loss: 1.8971126337419264e-05\n",
            "Epoch 1, Loss: 1.859131225501187e-05\n",
            "Epoch 1, Loss: 1.4174919670040254e-05\n",
            "Epoch 1, Loss: 1.8294051187695004e-05\n",
            "Epoch 1, Loss: 1.6877971575013362e-05\n",
            "Epoch 1, Loss: 1.491609145887196e-05\n",
            "Epoch 1, Loss: 1.5296855053748004e-05\n",
            "Epoch 1, Loss: 4.6029294026084244e-05\n",
            "Epoch 1, Loss: 2.5439310775254853e-05\n",
            "Epoch 1, Loss: 2.1793906853417866e-05\n",
            "Epoch 1, Loss: 1.8092889149556868e-05\n",
            "Epoch 1, Loss: 1.7106258383137174e-05\n",
            "Epoch 1, Loss: 2.6404328309581615e-05\n",
            "Epoch 1, Loss: 1.7529942851979285e-05\n",
            "Epoch 1, Loss: 2.319422310392838e-05\n",
            "Epoch 1, Loss: 2.316545032954309e-05\n",
            "Epoch 1, Loss: 2.398680771875661e-05\n",
            "Epoch 1, Loss: 1.6854524801601656e-05\n",
            "Epoch 1, Loss: 2.0424186004674993e-05\n",
            "Epoch 1, Loss: 1.4514710528601427e-05\n",
            "Epoch 1, Loss: 1.8609855032991618e-05\n",
            "Epoch 1, Loss: 1.5602470739395358e-05\n",
            "Epoch 1, Loss: 1.5559988241875544e-05\n",
            "Epoch 1, Loss: 1.582828008395154e-05\n",
            "Epoch 1, Loss: 1.4507768355542794e-05\n",
            "Epoch 1, Loss: 1.7369780834997073e-05\n",
            "Epoch 1, Loss: 1.893716944323387e-05\n",
            "Epoch 1, Loss: 1.762457577569876e-05\n",
            "Epoch 1, Loss: 1.781364881026093e-05\n",
            "Epoch 1, Loss: 1.2679646715696435e-05\n",
            "Epoch 1, Loss: 1.8687345800572075e-05\n",
            "Epoch 1, Loss: 1.5494424587814137e-05\n",
            "Epoch 1, Loss: 1.7293787095695734e-05\n",
            "Epoch 1, Loss: 2.1907277186983265e-05\n",
            "Epoch 1, Loss: 1.6093426893348806e-05\n",
            "Epoch 1, Loss: 2.509978185116779e-05\n",
            "Epoch 1, Loss: 1.485189568484202e-05\n",
            "Epoch 1, Loss: 1.9825434719678015e-05\n",
            "Epoch 1, Loss: 1.4538713003275916e-05\n",
            "Epoch 1, Loss: 1.7024045519065112e-05\n",
            "Epoch 1, Loss: 1.6021398550947197e-05\n",
            "Epoch 1, Loss: 1.3473911167238839e-05\n",
            "Epoch 1, Loss: 1.2642131878237706e-05\n",
            "Epoch 1, Loss: 1.411478024238022e-05\n",
            "Epoch 1, Loss: 1.8029775674222037e-05\n",
            "Epoch 1, Loss: 1.732627242745366e-05\n",
            "Epoch 1, Loss: 1.6426003639935516e-05\n",
            "Epoch 1, Loss: 1.8298056602361612e-05\n",
            "Epoch 1, Loss: 1.5335490388679318e-05\n",
            "Epoch 1, Loss: 1.567127947055269e-05\n",
            "Epoch 1, Loss: 1.856041853898205e-05\n",
            "Epoch 1, Loss: 1.3847145055478904e-05\n",
            "Epoch 1, Loss: 1.541390702186618e-05\n",
            "Epoch 1, Loss: 1.828124914027285e-05\n",
            "Epoch 1, Loss: 1.516026441095164e-05\n",
            "Epoch 1, Loss: 1.3239980034995824e-05\n",
            "Epoch 1, Loss: 1.7697673683869652e-05\n",
            "Epoch 1, Loss: 1.6064566807472147e-05\n",
            "Epoch 1, Loss: 1.3328660315892193e-05\n",
            "Epoch 1, Loss: 1.4787964573770296e-05\n",
            "Epoch 1, Loss: 1.3680291885975748e-05\n",
            "Epoch 1, Loss: 1.6907986719161272e-05\n",
            "Epoch 1, Loss: 1.7253112673643045e-05\n",
            "Epoch 1, Loss: 1.8001985154114664e-05\n",
            "Epoch 1, Loss: 1.677820910117589e-05\n",
            "Epoch 1, Loss: 1.9467152014840394e-05\n",
            "Epoch 1, Loss: 1.8520404410082847e-05\n",
            "Epoch 1, Loss: 1.5935924238874577e-05\n",
            "Epoch 1, Loss: 1.8541404642746784e-05\n",
            "Epoch 1, Loss: 1.798983612388838e-05\n",
            "Epoch 1, Loss: 1.698472442512866e-05\n",
            "Epoch 1, Loss: 1.3590603884949815e-05\n",
            "Epoch 1, Loss: 1.5974463167367503e-05\n",
            "Epoch 1, Loss: 1.647031240281649e-05\n",
            "Epoch 1, Loss: 1.4790593922953121e-05\n",
            "Epoch 1, Loss: 1.700071879895404e-05\n",
            "Epoch 1, Loss: 1.3971904081699904e-05\n",
            "Epoch 1, Loss: 1.5431909559993073e-05\n",
            "Epoch 1, Loss: 1.3870460861653555e-05\n",
            "Epoch 1, Loss: 1.8891107174567878e-05\n",
            "Epoch 1, Loss: 1.8728829672909342e-05\n",
            "Epoch 1, Loss: 1.29753670989885e-05\n",
            "Epoch 1, Loss: 1.781372702680528e-05\n",
            "Epoch 1, Loss: 1.7160004063043743e-05\n",
            "Epoch 1, Loss: 1.2618312211998273e-05\n",
            "Epoch 1, Loss: 1.612690721231047e-05\n",
            "Epoch 1, Loss: 1.8449878552928567e-05\n",
            "Epoch 1, Loss: 1.618446913198568e-05\n",
            "Epoch 1, Loss: 1.4590861610486172e-05\n",
            "Epoch 1, Loss: 1.4397315680980682e-05\n",
            "Epoch 1, Loss: 1.7486388969700783e-05\n",
            "Epoch 1, Loss: 1.6357555068680085e-05\n",
            "Epoch 1, Loss: 1.3272925571072847e-05\n",
            "Epoch 1, Loss: 1.3648939784616232e-05\n",
            "Epoch 1, Loss: 1.5044639440020546e-05\n",
            "Epoch 1, Loss: 1.809455716283992e-05\n",
            "Epoch 1, Loss: 1.309018443862442e-05\n",
            "Epoch 1, Loss: 1.4046012438484468e-05\n",
            "Epoch 1, Loss: 1.4376545550476294e-05\n",
            "Epoch 1, Loss: 1.5857322068768553e-05\n",
            "Epoch 1, Loss: 1.8523795006331056e-05\n",
            "Epoch 1, Loss: 1.5308090951293707e-05\n",
            "Epoch 1, Loss: 1.2642338333535008e-05\n",
            "Epoch 1, Loss: 1.80029273906257e-05\n",
            "Epoch 1, Loss: 1.4348091099236626e-05\n",
            "Epoch 1, Loss: 1.5418028851854615e-05\n",
            "Epoch 1, Loss: 1.3284902706800494e-05\n",
            "Epoch 1, Loss: 1.4956949598854408e-05\n",
            "Epoch 1, Loss: 1.5453486412297934e-05\n",
            "Epoch 1, Loss: 1.546223029436078e-05\n",
            "Epoch 1, Loss: 1.3829104318574537e-05\n",
            "Epoch 1, Loss: 1.4828301573288627e-05\n",
            "Epoch 1, Loss: 1.130314740294125e-05\n",
            "Epoch 1, Loss: 1.8063336028717458e-05\n",
            "Epoch 1, Loss: 1.409223932569148e-05\n",
            "Epoch 1, Loss: 1.5871459254412912e-05\n",
            "Epoch 1, Loss: 1.7017227946780622e-05\n",
            "Epoch 1, Loss: 1.2939182852278464e-05\n",
            "Epoch 1, Loss: 1.3277578545967117e-05\n",
            "Epoch 1, Loss: 1.4942924281058367e-05\n",
            "Epoch 1, Loss: 1.85900444193976e-05\n",
            "Epoch 1, Loss: 1.930239704961423e-05\n",
            "Epoch 1, Loss: 1.7530615878058597e-05\n",
            "Epoch 1, Loss: 1.6466736269649118e-05\n",
            "Epoch 1, Loss: 1.4960696717025712e-05\n",
            "Epoch 1, Loss: 1.5380610420834273e-05\n",
            "Epoch 1, Loss: 1.4760240446776152e-05\n",
            "Epoch 1, Loss: 1.2106135727663059e-05\n",
            "Epoch 1, Loss: 1.378762590320548e-05\n",
            "Epoch 1, Loss: 1.6202104234253056e-05\n",
            "Epoch 1, Loss: 1.7109874534071423e-05\n",
            "Epoch 1, Loss: 1.544016231491696e-05\n",
            "Epoch 1, Loss: 1.2706915185844991e-05\n",
            "Epoch 1, Loss: 1.401818371959962e-05\n",
            "Epoch 1, Loss: 1.675696694292128e-05\n",
            "Epoch 1, Loss: 2.460929681546986e-05\n",
            "Epoch 1, Loss: 1.707806768536102e-05\n",
            "Epoch 1, Loss: 1.2615057130460627e-05\n",
            "Epoch 1, Loss: 1.274593796551926e-05\n",
            "Epoch 1, Loss: 1.681785761320498e-05\n",
            "Epoch 1, Loss: 1.4779147932131309e-05\n",
            "Epoch 1, Loss: 1.380060984956799e-05\n",
            "Epoch 1, Loss: 1.3965762263978831e-05\n",
            "Epoch 1, Loss: 1.352940671495162e-05\n",
            "Epoch 1, Loss: 1.3948804735264275e-05\n",
            "Epoch 1, Loss: 1.56609730765922e-05\n",
            "Epoch 1, Loss: 1.2443447303667199e-05\n",
            "Epoch 1, Loss: 1.474497275921749e-05\n",
            "Epoch 1, Loss: 1.4745402950211428e-05\n",
            "Epoch 1, Loss: 1.9141900338581763e-05\n",
            "Epoch 1, Loss: 1.2245276593603194e-05\n",
            "Epoch 1, Loss: 1.3903777471568901e-05\n",
            "Epoch 1, Loss: 1.7389125787303783e-05\n",
            "Epoch 1, Loss: 1.2310491911193822e-05\n",
            "Epoch 1, Loss: 1.3961064723844174e-05\n",
            "Epoch 1, Loss: 1.561823592055589e-05\n",
            "Epoch 1, Loss: 1.715877624519635e-05\n",
            "Epoch 1, Loss: 1.4040263522474561e-05\n",
            "Epoch 1, Loss: 1.3951509572507348e-05\n",
            "Epoch 1, Loss: 1.9207436707802117e-05\n",
            "Epoch 1, Loss: 1.5509203876717947e-05\n",
            "Epoch 1, Loss: 1.71299197972985e-05\n",
            "Epoch 1, Loss: 1.3726571523875464e-05\n",
            "Epoch 1, Loss: 1.3916905118094292e-05\n",
            "Epoch 1, Loss: 1.8283397366758436e-05\n",
            "Epoch 1, Loss: 1.625311233510729e-05\n",
            "Epoch 1, Loss: 1.3577483514382038e-05\n",
            "Epoch 1, Loss: 1.0869945072045084e-05\n",
            "Epoch 1, Loss: 1.5097586583578959e-05\n",
            "Epoch 1, Loss: 1.1700599316100124e-05\n",
            "Epoch 1, Loss: 1.5311916286009364e-05\n",
            "Epoch 1, Loss: 1.6949046766967513e-05\n",
            "Epoch 1, Loss: 1.3644325917994138e-05\n",
            "Epoch 1, Loss: 1.635552689549513e-05\n",
            "Epoch 1, Loss: 1.5370424080174416e-05\n",
            "Epoch 1, Loss: 1.313801112701185e-05\n",
            "Epoch 1, Loss: 1.4155703865981195e-05\n",
            "Epoch 1, Loss: 1.5090417036844883e-05\n",
            "Epoch 1, Loss: 1.4407560229301453e-05\n",
            "Epoch 1, Loss: 1.1182601156178862e-05\n",
            "Epoch 1, Loss: 1.4983563232817687e-05\n",
            "Epoch 1, Loss: 1.7918198864208534e-05\n",
            "Epoch 1, Loss: 2.272166238981299e-05\n",
            "Epoch 1, Loss: 1.589336898177862e-05\n",
            "Epoch 1, Loss: 1.667744800215587e-05\n",
            "Epoch 1, Loss: 1.87150089914212e-05\n",
            "Epoch 1, Loss: 1.597944356035441e-05\n",
            "Epoch 1, Loss: 1.2474875802581664e-05\n",
            "Epoch 1, Loss: 1.47184564411873e-05\n",
            "Epoch 1, Loss: 1.4279885363066569e-05\n",
            "Epoch 1, Loss: 1.1005848136846907e-05\n",
            "Epoch 1, Loss: 1.4553344954038039e-05\n",
            "Epoch 1, Loss: 1.1634519978542812e-05\n",
            "Epoch 1, Loss: 1.5149769751587883e-05\n",
            "Epoch 1, Loss: 1.6862166376085952e-05\n",
            "Epoch 1, Loss: 2.0738538296427578e-05\n",
            "Epoch 1, Loss: 1.4184081919665914e-05\n",
            "Epoch 1, Loss: 1.804702333174646e-05\n",
            "Epoch 1, Loss: 1.3400956049736124e-05\n",
            "Epoch 1, Loss: 1.2664232599490788e-05\n",
            "Epoch 1, Loss: 1.616419103811495e-05\n",
            "Epoch 1, Loss: 1.770122253219597e-05\n",
            "Epoch 1, Loss: 1.6864491044543684e-05\n",
            "Epoch 1, Loss: 1.2847207472077571e-05\n",
            "Epoch 1, Loss: 1.3296423276187852e-05\n",
            "Epoch 1, Loss: 1.5990181054803543e-05\n",
            "Epoch 1, Loss: 1.2229251296957955e-05\n",
            "Epoch 1, Loss: 1.5174539839790668e-05\n",
            "Epoch 1, Loss: 1.1472339792817365e-05\n",
            "Epoch 1, Loss: 1.5082685422385111e-05\n",
            "Epoch 1, Loss: 1.932055238285102e-05\n",
            "Epoch 1, Loss: 1.3439032954920549e-05\n",
            "Epoch 1, Loss: 1.3085996215522755e-05\n",
            "Epoch 1, Loss: 2.7103109459858388e-05\n",
            "Epoch 1, Loss: 2.7529704311746173e-05\n",
            "Epoch 1, Loss: 1.359089401375968e-05\n",
            "Epoch 1, Loss: 1.753983633534517e-05\n",
            "Epoch 1, Loss: 1.3762019079877064e-05\n",
            "Epoch 1, Loss: 1.425563186785439e-05\n",
            "Epoch 1, Loss: 1.4968442883400712e-05\n",
            "Epoch 1, Loss: 1.259022974409163e-05\n",
            "Epoch 1, Loss: 1.9188059013686143e-05\n",
            "Epoch 1, Loss: 1.2655126738536637e-05\n",
            "Epoch 1, Loss: 1.6696323655196466e-05\n",
            "Epoch 1, Loss: 1.3547795788326766e-05\n",
            "Epoch 1, Loss: 1.7450383893446997e-05\n",
            "Epoch 1, Loss: 1.279983280255692e-05\n",
            "Epoch 1, Loss: 1.0948870112770237e-05\n",
            "Epoch 1, Loss: 1.585341124155093e-05\n",
            "Epoch 1, Loss: 2.4107497665681876e-05\n",
            "Epoch 1, Loss: 1.4167659173836e-05\n",
            "Epoch 1, Loss: 1.3065421626379248e-05\n",
            "Epoch 1, Loss: 1.3323637176654302e-05\n",
            "Epoch 1, Loss: 1.5082225218066014e-05\n",
            "Epoch 1, Loss: 1.907978548842948e-05\n",
            "Epoch 1, Loss: 1.3433162166620605e-05\n",
            "Epoch 1, Loss: 1.2637516192626208e-05\n",
            "Epoch 1, Loss: 1.505483942310093e-05\n",
            "Epoch 1, Loss: 1.9175800844095647e-05\n",
            "Epoch 1, Loss: 1.1705677025020123e-05\n",
            "Epoch 1, Loss: 1.3396917893260252e-05\n",
            "Epoch 1, Loss: 1.3180423593439627e-05\n",
            "Epoch 1, Loss: 1.8820435798261315e-05\n",
            "Epoch 1, Loss: 1.026736936182715e-05\n",
            "Epoch 1, Loss: 1.7016587662510574e-05\n",
            "Epoch 1, Loss: 1.2052828424202744e-05\n",
            "Epoch 1, Loss: 2.0524126739474013e-05\n",
            "Epoch 1, Loss: 1.3769667020824272e-05\n",
            "Epoch 1, Loss: 1.162090939033078e-05\n",
            "Epoch 1, Loss: 1.1432166502345353e-05\n",
            "Epoch 1, Loss: 1.3038466931902803e-05\n",
            "Epoch 1, Loss: 1.394180526403943e-05\n",
            "Epoch 1, Loss: 1.4099830877967179e-05\n",
            "Epoch 1, Loss: 1.4502132216875907e-05\n",
            "Epoch 1, Loss: 1.373208942823112e-05\n",
            "Epoch 1, Loss: 1.6440160834463313e-05\n",
            "Epoch 1, Loss: 1.4081729204917792e-05\n",
            "Epoch 1, Loss: 1.3768694770988077e-05\n",
            "Epoch 1, Loss: 1.84242981049465e-05\n",
            "Epoch 1, Loss: 1.3395770110946614e-05\n",
            "Epoch 1, Loss: 1.3876633602194488e-05\n",
            "Epoch 1, Loss: 1.4625521544076037e-05\n",
            "Epoch 1, Loss: 1.97155441128416e-05\n",
            "Epoch 1, Loss: 1.4302379895525519e-05\n",
            "Epoch 1, Loss: 1.683732079982292e-05\n",
            "Epoch 1, Loss: 1.2717498975689523e-05\n",
            "Epoch 1, Loss: 1.269740369025385e-05\n",
            "Epoch 1, Loss: 1.8134844140149653e-05\n",
            "Epoch 1, Loss: 1.8180453480454162e-05\n",
            "Epoch 1, Loss: 1.1994367014267482e-05\n",
            "Epoch 1, Loss: 1.4661291061202064e-05\n",
            "Epoch 1, Loss: 1.35550462800893e-05\n",
            "Epoch 1, Loss: 1.7148133338196203e-05\n",
            "Epoch 1, Loss: 1.2549230632430408e-05\n",
            "Epoch 1, Loss: 1.3924918675911613e-05\n",
            "Epoch 1, Loss: 1.710390097287018e-05\n",
            "Epoch 1, Loss: 1.250387322215829e-05\n",
            "Epoch 1, Loss: 1.3993532775202766e-05\n",
            "Epoch 1, Loss: 1.3823445442540105e-05\n",
            "Epoch 1, Loss: 1.552474896016065e-05\n",
            "Epoch 1, Loss: 1.1061924851674121e-05\n",
            "Epoch 1, Loss: 1.3447376659314614e-05\n",
            "Epoch 1, Loss: 1.2342346963123418e-05\n",
            "Epoch 1, Loss: 1.4349433513416443e-05\n",
            "Epoch 1, Loss: 1.2934457117808051e-05\n",
            "Epoch 1, Loss: 1.3834121091349516e-05\n",
            "Epoch 1, Loss: 1.1179495231772307e-05\n",
            "Epoch 1, Loss: 1.3534283425542526e-05\n",
            "Epoch 1, Loss: 1.5029577298264485e-05\n",
            "Epoch 1, Loss: 1.812336267903447e-05\n",
            "Epoch 1, Loss: 1.4161390936351381e-05\n",
            "Epoch 1, Loss: 1.4398396160686389e-05\n",
            "Epoch 1, Loss: 1.335363594989758e-05\n",
            "Epoch 1, Loss: 1.1472750884422567e-05\n",
            "Epoch 1, Loss: 1.154332949226955e-05\n",
            "Epoch 1, Loss: 1.4939440006855875e-05\n",
            "Epoch 1, Loss: 1.578156116011087e-05\n",
            "Epoch 1, Loss: 1.3871475857740734e-05\n",
            "Epoch 1, Loss: 1.2154387150076218e-05\n",
            "Epoch 1, Loss: 1.5408080798806623e-05\n",
            "Epoch 1, Loss: 1.1898543561983388e-05\n",
            "Epoch 1, Loss: 1.2786606930603739e-05\n",
            "Epoch 1, Loss: 1.3061015124549158e-05\n",
            "Epoch 1, Loss: 1.7388869309797883e-05\n",
            "Epoch 1, Loss: 1.2083919500582851e-05\n",
            "Epoch 1, Loss: 2.0162573491688818e-05\n",
            "Epoch 1, Loss: 1.4397128325072117e-05\n",
            "Epoch 1, Loss: 1.3252712051325943e-05\n",
            "Epoch 1, Loss: 1.3252873031888157e-05\n",
            "Epoch 1, Loss: 1.1399319191696122e-05\n",
            "Epoch 1, Loss: 1.2574370884976815e-05\n",
            "Epoch 1, Loss: 1.3913365364714991e-05\n",
            "Epoch 1, Loss: 1.5590499970130622e-05\n",
            "Epoch 1, Loss: 1.0547407327976543e-05\n",
            "Epoch 1, Loss: 1.8170963812735863e-05\n",
            "Epoch 1, Loss: 1.2773821254086215e-05\n",
            "Epoch 1, Loss: 1.3068204680166673e-05\n",
            "Epoch 1, Loss: 1.5047398846945725e-05\n",
            "Epoch 1, Loss: 1.3707490325032268e-05\n",
            "Epoch 1, Loss: 1.4768382243346423e-05\n",
            "Epoch 1, Loss: 2.0696446881629527e-05\n",
            "Epoch 1, Loss: 1.80267306859605e-05\n",
            "Epoch 1, Loss: 1.1693469787132926e-05\n",
            "Epoch 1, Loss: 1.6625745047349483e-05\n",
            "Epoch 1, Loss: 1.4135862329567317e-05\n",
            "Epoch 1, Loss: 1.4547782484441996e-05\n",
            "Epoch 1, Loss: 1.1156957953062374e-05\n",
            "Epoch 1, Loss: 1.557300129206851e-05\n",
            "Epoch 1, Loss: 1.5506677300436422e-05\n",
            "Epoch 1, Loss: 1.2971639080205932e-05\n",
            "Epoch 1, Loss: 1.1374539099051617e-05\n",
            "Epoch 1, Loss: 1.0279882189934142e-05\n",
            "Epoch 1, Loss: 1.2794419490091968e-05\n",
            "Epoch 1, Loss: 1.3025207408645656e-05\n",
            "Epoch 1, Loss: 1.8231903595733456e-05\n",
            "Epoch 1, Loss: 1.105047977034701e-05\n",
            "Epoch 1, Loss: 1.4631973499490414e-05\n",
            "Epoch 1, Loss: 1.4989793271524832e-05\n",
            "Epoch 1, Loss: 1.3099238458380569e-05\n",
            "Epoch 1, Loss: 1.2460174730222207e-05\n",
            "Epoch 1, Loss: 1.2367510862532072e-05\n",
            "Epoch 1, Loss: 1.431583586963825e-05\n",
            "Epoch 1, Loss: 1.4093192476138938e-05\n",
            "Epoch 1, Loss: 1.359121688437881e-05\n",
            "Epoch 1, Loss: 1.1316189556964673e-05\n",
            "Epoch 1, Loss: 1.4953845493437257e-05\n",
            "Epoch 1, Loss: 1.5045403415570036e-05\n",
            "Epoch 1, Loss: 1.135396450990811e-05\n",
            "Epoch 1, Loss: 1.584186975378543e-05\n",
            "Epoch 1, Loss: 1.548172986076679e-05\n",
            "Epoch 1, Loss: 1.5876559700700454e-05\n",
            "Epoch 1, Loss: 1.2707118003163487e-05\n",
            "Epoch 1, Loss: 1.3091417713440023e-05\n",
            "Epoch 1, Loss: 1.175701072497759e-05\n",
            "Epoch 1, Loss: 1.225066080223769e-05\n",
            "Epoch 1, Loss: 1.258684915228514e-05\n",
            "Epoch 1, Loss: 1.3850319191988092e-05\n",
            "Epoch 1, Loss: 1.2163307474111207e-05\n",
            "Epoch 1, Loss: 1.363883802696364e-05\n",
            "Epoch 1, Loss: 1.3226806004240643e-05\n",
            "Epoch 1, Loss: 1.684622111497447e-05\n",
            "Epoch 1, Loss: 1.0473309885128401e-05\n",
            "Epoch 1, Loss: 1.6813999536680058e-05\n",
            "Epoch 1, Loss: 1.3250931260699872e-05\n",
            "Epoch 1, Loss: 1.1986780918959994e-05\n",
            "Epoch 1, Loss: 1.229452209372539e-05\n",
            "Epoch 1, Loss: 1.3041702914051712e-05\n",
            "Epoch 1, Loss: 1.0752408343250863e-05\n",
            "Epoch 1, Loss: 1.4953068784961943e-05\n",
            "Epoch 1, Loss: 1.1955222362303175e-05\n",
            "Epoch 1, Loss: 1.3012895578867756e-05\n",
            "Epoch 1, Loss: 1.3624198800243903e-05\n",
            "Epoch 1, Loss: 1.1215114682272542e-05\n",
            "Epoch 1, Loss: 1.2690041330642998e-05\n",
            "Epoch 1, Loss: 1.2839892406191211e-05\n",
            "Epoch 1, Loss: 1.3930837667430751e-05\n",
            "Epoch 1, Loss: 1.0747652595455293e-05\n",
            "Epoch 1, Loss: 1.1037765034416225e-05\n",
            "Epoch 1, Loss: 1.0867791388591286e-05\n",
            "Epoch 1, Loss: 1.3257255886856001e-05\n",
            "Epoch 1, Loss: 1.8331453247810714e-05\n",
            "Epoch 1, Loss: 1.1270396498730406e-05\n",
            "Epoch 1, Loss: 1.1631967026914936e-05\n",
            "Epoch 1, Loss: 1.1833305507025216e-05\n",
            "Epoch 1, Loss: 1.4549049410561565e-05\n",
            "Epoch 1, Loss: 1.0877850399992894e-05\n",
            "Epoch 1, Loss: 1.5302712199627422e-05\n",
            "Epoch 1, Loss: 1.0668324648577254e-05\n",
            "Epoch 1, Loss: 1.172250722447643e-05\n",
            "Epoch 1, Loss: 1.0319789907953236e-05\n",
            "Epoch 1, Loss: 1.3352049791137688e-05\n",
            "Epoch 1, Loss: 1.295451966143446e-05\n",
            "Epoch 1, Loss: 1.5639994671801105e-05\n",
            "Epoch 1, Loss: 1.5186183190962765e-05\n",
            "Epoch 1, Loss: 1.7773874787962995e-05\n",
            "Epoch 1, Loss: 1.1232587894483004e-05\n",
            "Epoch 1, Loss: 1.2786917068297043e-05\n",
            "Epoch 1, Loss: 1.3688981198356487e-05\n",
            "Epoch 1, Loss: 1.613090353203006e-05\n",
            "Epoch 1, Loss: 1.0588821169221774e-05\n",
            "Epoch 1, Loss: 1.8483351595932618e-05\n",
            "Epoch 1, Loss: 1.163622164312983e-05\n",
            "Epoch 1, Loss: 1.5144718418014236e-05\n",
            "Epoch 1, Loss: 1.7704758647596464e-05\n",
            "Epoch 1, Loss: 1.4166374967317097e-05\n",
            "Epoch 1, Loss: 1.5098101357580163e-05\n",
            "Epoch 1, Loss: 1.1383859600755386e-05\n",
            "Epoch 1, Loss: 1.142734254244715e-05\n",
            "Epoch 1, Loss: 1.0583426046650857e-05\n",
            "Epoch 1, Loss: 1.3736374057771172e-05\n",
            "Epoch 1, Loss: 1.1338460353726987e-05\n",
            "Epoch 1, Loss: 1.0828513040905818e-05\n",
            "Epoch 1, Loss: 1.274658370675752e-05\n",
            "Epoch 1, Loss: 1.0385349014541134e-05\n",
            "Epoch 1, Loss: 1.04860309875221e-05\n",
            "Epoch 1, Loss: 1.2533720109786373e-05\n",
            "Epoch 1, Loss: 1.7869182556751184e-05\n",
            "Epoch 1, Loss: 1.178211641672533e-05\n",
            "Epoch 1, Loss: 1.5559708117507398e-05\n",
            "Epoch 1, Loss: 1.1554750926734414e-05\n",
            "Epoch 1, Loss: 1.0618899068504106e-05\n",
            "Epoch 1, Loss: 1.2826090824091807e-05\n",
            "Epoch 1, Loss: 1.322949265158968e-05\n",
            "Epoch 1, Loss: 1.633080501051154e-05\n",
            "Epoch 1, Loss: 1.325433640886331e-05\n",
            "Epoch 1, Loss: 1.1740971785911825e-05\n",
            "Epoch 1, Loss: 1.1568694390007295e-05\n",
            "Epoch 1, Loss: 1.1898428056156263e-05\n",
            "Epoch 1, Loss: 1.2870632417616434e-05\n",
            "Epoch 1, Loss: 1.1219373845960945e-05\n",
            "Epoch 1, Loss: 1.081139544112375e-05\n",
            "Epoch 1, Loss: 1.100991266866913e-05\n",
            "Epoch 1, Loss: 1.1472113328636624e-05\n",
            "Epoch 1, Loss: 1.0693009244278073e-05\n",
            "Epoch 1, Loss: 1.3815892998536583e-05\n",
            "Epoch 1, Loss: 1.6852814951562323e-05\n",
            "Epoch 1, Loss: 1.3330386536836158e-05\n",
            "Epoch 1, Loss: 2.373146708123386e-05\n",
            "Epoch 1, Loss: 1.0834908607648686e-05\n",
            "Epoch 1, Loss: 1.3095146641717292e-05\n",
            "Epoch 1, Loss: 1.4816960174357519e-05\n",
            "Epoch 1, Loss: 1.3800324268231634e-05\n",
            "Epoch 1, Loss: 9.810042683966458e-06\n",
            "Epoch 1, Loss: 1.0642807865224313e-05\n",
            "Epoch 1, Loss: 1.2035707186441869e-05\n",
            "Epoch 1, Loss: 1.639251240703743e-05\n",
            "Epoch 1, Loss: 1.1857327081088442e-05\n",
            "Epoch 1, Loss: 1.40380780067062e-05\n",
            "Epoch 1, Loss: 1.1356620234437287e-05\n",
            "Epoch 1, Loss: 1.1834496945084538e-05\n",
            "Epoch 1, Loss: 1.3882143321097828e-05\n",
            "Epoch 1, Loss: 1.3366909115575254e-05\n",
            "Epoch 1, Loss: 1.418897409166675e-05\n",
            "Epoch 1, Loss: 1.3692418178834487e-05\n",
            "Epoch 1, Loss: 1.2994118151254952e-05\n",
            "Epoch 1, Loss: 1.3224838767200708e-05\n",
            "Epoch 1, Loss: 1.2166998203611001e-05\n",
            "Epoch 1, Loss: 1.209107995236991e-05\n",
            "Epoch 1, Loss: 1.2250503459654283e-05\n",
            "Epoch 1, Loss: 1.1101510608568788e-05\n",
            "Epoch 1, Loss: 1.3671968190465122e-05\n",
            "Epoch 1, Loss: 1.3510860298993066e-05\n",
            "Epoch 1, Loss: 9.46289856074145e-06\n",
            "Epoch 1, Loss: 1.4351765457831789e-05\n",
            "Epoch 1, Loss: 1.4056729014555458e-05\n",
            "Epoch 1, Loss: 1.2841037460020743e-05\n",
            "Epoch 1, Loss: 1.303193948842818e-05\n",
            "Epoch 1, Loss: 1.344838528893888e-05\n",
            "Epoch 1, Loss: 1.2886814147350378e-05\n",
            "Epoch 1, Loss: 1.0792059583764058e-05\n",
            "Epoch 1, Loss: 1.100781901186565e-05\n",
            "Epoch 1, Loss: 1.4706002730235923e-05\n",
            "Epoch 1, Loss: 1.3564461369242053e-05\n",
            "Epoch 1, Loss: 1.2218857591506094e-05\n",
            "Epoch 1, Loss: 1.1768905096687376e-05\n",
            "Epoch 1, Loss: 1.2894577594124712e-05\n",
            "Epoch 1, Loss: 1.2637669897230808e-05\n",
            "Epoch 1, Loss: 1.1518571227497887e-05\n",
            "Epoch 1, Loss: 1.3462157767207827e-05\n",
            "Epoch 1, Loss: 1.6234160284511745e-05\n",
            "Epoch 1, Loss: 1.2753839655488264e-05\n",
            "Epoch 1, Loss: 1.2070150660292711e-05\n",
            "Epoch 1, Loss: 1.579933268658351e-05\n",
            "Epoch 1, Loss: 1.341563620371744e-05\n",
            "Epoch 1, Loss: 1.2062288078595884e-05\n",
            "Epoch 1, Loss: 1.2459388017305173e-05\n",
            "Epoch 1, Loss: 1.542541394883301e-05\n",
            "Epoch 1, Loss: 1.3979859431856312e-05\n",
            "Epoch 1, Loss: 1.1363625162630342e-05\n",
            "Epoch 1, Loss: 1.2142493687861133e-05\n",
            "Epoch 1, Loss: 1.0807832950376906e-05\n",
            "Epoch 1, Loss: 1.094516755983932e-05\n",
            "Epoch 1, Loss: 1.7847991330199875e-05\n",
            "Epoch 1, Loss: 1.2217058610985987e-05\n",
            "Epoch 1, Loss: 1.2821763448300771e-05\n",
            "Epoch 1, Loss: 1.2202049219922628e-05\n",
            "Epoch 1, Loss: 1.1822971828223672e-05\n",
            "Epoch 1, Loss: 1.3061157005722634e-05\n",
            "Epoch 1, Loss: 1.2093420991732273e-05\n",
            "Epoch 1, Loss: 1.0296997061232105e-05\n",
            "Epoch 1, Loss: 9.448677701584529e-06\n",
            "Epoch 1, Loss: 1.222372429765528e-05\n",
            "Epoch 1, Loss: 1.2358557796687819e-05\n",
            "Epoch 1, Loss: 1.8366605218034238e-05\n",
            "Epoch 1, Loss: 1.4620907677453943e-05\n",
            "Epoch 1, Loss: 1.8304135664948262e-05\n",
            "Epoch 1, Loss: 1.2058606444043107e-05\n",
            "Epoch 1, Loss: 1.4963658941269387e-05\n",
            "Epoch 1, Loss: 1.4702482985740062e-05\n",
            "Epoch 1, Loss: 1.3173335901228711e-05\n",
            "Epoch 1, Loss: 1.3039036275586113e-05\n",
            "Epoch 1, Loss: 1.3091645087115467e-05\n",
            "Epoch 1, Loss: 1.2278192116355058e-05\n",
            "Epoch 1, Loss: 1.07519144876278e-05\n",
            "Epoch 1, Loss: 1.2641495231946465e-05\n",
            "Epoch 1, Loss: 1.1109720617241692e-05\n",
            "Epoch 1, Loss: 1.0344421752961352e-05\n",
            "Epoch 1, Loss: 1.3117259186401498e-05\n",
            "Epoch 1, Loss: 1.0017452950705774e-05\n",
            "Epoch 1, Loss: 1.1856227501993999e-05\n",
            "Epoch 1, Loss: 1.3718157788389362e-05\n",
            "Epoch 1, Loss: 1.1295790500298608e-05\n",
            "Epoch 1, Loss: 1.3435358596325386e-05\n",
            "Epoch 1, Loss: 1.1638983778539114e-05\n",
            "Epoch 1, Loss: 1.5361763871624134e-05\n",
            "Epoch 1, Loss: 1.1046582585549913e-05\n",
            "Epoch 1, Loss: 9.737931577546988e-06\n",
            "Epoch 1, Loss: 1.0456516974954866e-05\n",
            "Epoch 1, Loss: 1.0358377949160058e-05\n",
            "Epoch 1, Loss: 1.1063084457418881e-05\n",
            "Epoch 1, Loss: 1.5839681509532966e-05\n",
            "Epoch 1, Loss: 1.555166090838611e-05\n",
            "Epoch 1, Loss: 1.1583167179196607e-05\n",
            "Epoch 1, Loss: 1.4121796084509697e-05\n",
            "Epoch 1, Loss: 9.581983249518089e-06\n",
            "Epoch 1, Loss: 1.1075476322730538e-05\n",
            "Epoch 1, Loss: 1.2579464964801446e-05\n",
            "Epoch 1, Loss: 1.416922896169126e-05\n",
            "Epoch 1, Loss: 1.2741244972858112e-05\n",
            "Epoch 1, Loss: 1.8499191355658695e-05\n",
            "Epoch 1, Loss: 1.4228086001821794e-05\n",
            "Epoch 1, Loss: 1.2739128578687087e-05\n",
            "Epoch 1, Loss: 1.2422194231476169e-05\n",
            "Epoch 1, Loss: 1.7236923667951487e-05\n",
            "Epoch 1, Loss: 1.31552733364515e-05\n",
            "Epoch 1, Loss: 8.454783710476477e-06\n",
            "Epoch 1, Loss: 1.3924900486017577e-05\n",
            "Epoch 1, Loss: 1.1019144039892126e-05\n",
            "Epoch 1, Loss: 1.241880909219617e-05\n",
            "Epoch 1, Loss: 1.4332407772599254e-05\n",
            "Epoch 1, Loss: 1.1069375432271045e-05\n",
            "Epoch 1, Loss: 1.296248137805378e-05\n",
            "Epoch 1, Loss: 1.4091087905399036e-05\n",
            "Epoch 1, Loss: 9.783489986148197e-06\n",
            "Epoch 1, Loss: 1.8773363990476355e-05\n",
            "Epoch 1, Loss: 1.1815945072157774e-05\n",
            "Epoch 1, Loss: 1.1526851267262828e-05\n",
            "Epoch 1, Loss: 1.2801967386621982e-05\n",
            "Epoch 1, Loss: 1.110471293941373e-05\n",
            "Epoch 1, Loss: 1.1277943485765718e-05\n",
            "Epoch 1, Loss: 1.381628135277424e-05\n",
            "Epoch 1, Loss: 1.2690916264546104e-05\n",
            "Epoch 1, Loss: 1.1748755241569597e-05\n",
            "Epoch 1, Loss: 1.6487376342411153e-05\n",
            "Epoch 1, Loss: 1.765639717632439e-05\n",
            "Epoch 1, Loss: 9.779101674212143e-06\n",
            "Epoch 1, Loss: 1.9115606846753508e-05\n",
            "Epoch 1, Loss: 1.1124725460831542e-05\n",
            "Epoch 1, Loss: 1.0867959645111114e-05\n",
            "Epoch 1, Loss: 1.3854643839295022e-05\n",
            "Epoch 1, Loss: 1.373118175251875e-05\n",
            "Epoch 1, Loss: 1.04410937638022e-05\n",
            "Epoch 1, Loss: 9.97019924398046e-06\n",
            "Epoch 1, Loss: 1.1503308996907435e-05\n",
            "Epoch 1, Loss: 1.2566379155032337e-05\n",
            "Epoch 1, Loss: 1.1365478712832555e-05\n",
            "Epoch 1, Loss: 1.0824426681210753e-05\n",
            "Epoch 1, Loss: 9.163441973214503e-06\n",
            "Epoch 1, Loss: 9.266115739592351e-06\n",
            "Epoch 1, Loss: 1.4550249034073204e-05\n",
            "Epoch 1, Loss: 1.3749873687629588e-05\n",
            "Epoch 1, Loss: 9.825240340433083e-06\n",
            "Epoch 1, Loss: 1.4977053979237098e-05\n",
            "Epoch 1, Loss: 1.080225410987623e-05\n",
            "Epoch 1, Loss: 1.3148202015145216e-05\n",
            "Epoch 1, Loss: 1.2922368114232086e-05\n",
            "Epoch 1, Loss: 1.2070553566445597e-05\n",
            "Epoch 1, Loss: 1.0152837603527587e-05\n",
            "Epoch 1, Loss: 1.1713731510099024e-05\n",
            "Epoch 1, Loss: 1.1895525858562905e-05\n",
            "Epoch 1, Loss: 1.0447919521539006e-05\n",
            "Epoch 1, Loss: 1.129601696447935e-05\n",
            "Epoch 1, Loss: 1.1611217814788688e-05\n",
            "Epoch 1, Loss: 1.1951470696658362e-05\n",
            "Epoch 1, Loss: 1.2648386473301798e-05\n",
            "Epoch 1, Loss: 1.132063061959343e-05\n",
            "Epoch 1, Loss: 1.4521702723868657e-05\n",
            "Epoch 1, Loss: 1.1112682841485366e-05\n",
            "Epoch 1, Loss: 1.1600545803958084e-05\n",
            "Epoch 1, Loss: 1.2757411241182126e-05\n",
            "Epoch 1, Loss: 1.372713359160116e-05\n",
            "Epoch 1, Loss: 1.1609959983616136e-05\n",
            "Epoch 1, Loss: 1.0805974852701183e-05\n",
            "Epoch 1, Loss: 1.1395118235668633e-05\n",
            "Epoch 1, Loss: 1.143607369158417e-05\n",
            "Epoch 1, Loss: 1.1271494258835446e-05\n",
            "Epoch 1, Loss: 1.1112326319562271e-05\n",
            "Epoch 1, Loss: 1.1930030268558767e-05\n",
            "Epoch 1, Loss: 1.2231052096467465e-05\n",
            "Epoch 1, Loss: 1.0962421583826654e-05\n",
            "Epoch 1, Loss: 1.5027405424916651e-05\n",
            "Epoch 1, Loss: 9.732842954690568e-06\n",
            "Epoch 1, Loss: 1.2463125131034758e-05\n",
            "Epoch 1, Loss: 1.2210017303004861e-05\n",
            "Epoch 1, Loss: 1.209821039083181e-05\n",
            "Epoch 1, Loss: 1.4723274944117293e-05\n",
            "Epoch 1, Loss: 1.0252606443827972e-05\n",
            "Epoch 1, Loss: 1.178551246994175e-05\n",
            "Epoch 1, Loss: 1.4635166735388339e-05\n",
            "Epoch 1, Loss: 1.538147080282215e-05\n",
            "Epoch 1, Loss: 1.0005984222516418e-05\n",
            "Epoch 1, Loss: 1.2181300917291082e-05\n",
            "Epoch 1, Loss: 1.1778300176956691e-05\n",
            "Epoch 1, Loss: 1.3209322787588462e-05\n",
            "Epoch 1, Loss: 1.077185424946947e-05\n",
            "Epoch 1, Loss: 1.102346595871495e-05\n",
            "Epoch 1, Loss: 1.345491546089761e-05\n",
            "Epoch 1, Loss: 1.0103478416567668e-05\n",
            "Epoch 1, Loss: 1.5371329936897382e-05\n",
            "Epoch 1, Loss: 1.1430396625655703e-05\n",
            "Epoch 1, Loss: 9.5539280664525e-06\n",
            "Epoch 1, Loss: 1.6288255210383795e-05\n",
            "Epoch 1, Loss: 1.1114353583252523e-05\n",
            "Epoch 1, Loss: 1.1076732334913686e-05\n",
            "Epoch 1, Loss: 1.2039064131386112e-05\n",
            "Epoch 1, Loss: 1.3175875210436061e-05\n",
            "Epoch 1, Loss: 1.5435587556567043e-05\n",
            "Epoch 1, Loss: 9.017270713229664e-06\n",
            "Epoch 1, Loss: 1.1169254321430344e-05\n",
            "Epoch 1, Loss: 9.181136192637496e-06\n",
            "Epoch 1, Loss: 1.6821471945149824e-05\n",
            "Epoch 1, Loss: 1.070992584573105e-05\n",
            "Epoch 1, Loss: 1.1968443686782848e-05\n",
            "Epoch 1, Loss: 1.1930103028134909e-05\n",
            "Epoch 1, Loss: 1.0549949365667999e-05\n",
            "Epoch 1, Loss: 9.639904419600498e-06\n",
            "Epoch 1, Loss: 1.478985996072879e-05\n",
            "Epoch 1, Loss: 9.65571052802261e-06\n",
            "Epoch 1, Loss: 1.2472864000301342e-05\n",
            "Epoch 1, Loss: 1.0363443834648933e-05\n",
            "Epoch 1, Loss: 1.2322720067459159e-05\n",
            "Epoch 1, Loss: 9.474607395532075e-06\n",
            "Epoch 1, Loss: 1.1975923371210229e-05\n",
            "Epoch 1, Loss: 1.03705060610082e-05\n",
            "Epoch 1, Loss: 1.3058791410003323e-05\n",
            "Epoch 1, Loss: 9.889011380437296e-06\n",
            "Epoch 1, Loss: 1.3154141925042495e-05\n",
            "Epoch 1, Loss: 1.2090570635336917e-05\n",
            "Epoch 1, Loss: 1.2488143511291128e-05\n",
            "Epoch 1, Loss: 1.0433735042170156e-05\n",
            "Epoch 1, Loss: 1.2593724022735842e-05\n",
            "Epoch 1, Loss: 1.1657545655907597e-05\n",
            "Epoch 1, Loss: 1.3662365745403804e-05\n",
            "Epoch 1, Loss: 1.1802514563896693e-05\n",
            "Epoch 1, Loss: 1.1767139767471235e-05\n",
            "Epoch 1, Loss: 1.0017479326052126e-05\n",
            "Epoch 1, Loss: 1.1703784366545733e-05\n",
            "Epoch 1, Loss: 1.1620702025538776e-05\n",
            "Epoch 1, Loss: 1.0761957128124777e-05\n",
            "Epoch 1, Loss: 1.2075938684574794e-05\n",
            "Epoch 1, Loss: 1.2391326890792698e-05\n",
            "Epoch 1, Loss: 1.4601211660192348e-05\n",
            "Epoch 1, Loss: 1.2239548595971428e-05\n",
            "Epoch 1, Loss: 1.5477869965252466e-05\n",
            "Epoch 1, Loss: 1.070386224455433e-05\n",
            "Epoch 1, Loss: 9.977260560845025e-06\n",
            "Epoch 1, Loss: 1.1594904208322987e-05\n",
            "Epoch 1, Loss: 9.619695447327103e-06\n",
            "Epoch 1, Loss: 8.790738320385572e-06\n",
            "Epoch 1, Loss: 1.039716062223306e-05\n",
            "Epoch 1, Loss: 1.402966972818831e-05\n",
            "Epoch 1, Loss: 1.3140769624442328e-05\n",
            "Epoch 1, Loss: 1.1334707778587472e-05\n",
            "Epoch 1, Loss: 1.1115141205664258e-05\n",
            "Epoch 1, Loss: 1.549677472212352e-05\n",
            "Epoch 1, Loss: 1.1752905265893787e-05\n",
            "Epoch 1, Loss: 1.182161668111803e-05\n",
            "Epoch 1, Loss: 8.71792326506693e-06\n",
            "Epoch 1, Loss: 1.2843819604313467e-05\n",
            "Epoch 1, Loss: 1.3383048099058215e-05\n",
            "Epoch 1, Loss: 9.454574865230825e-06\n",
            "Epoch 1, Loss: 1.149276431533508e-05\n",
            "Epoch 1, Loss: 1.1214120604563504e-05\n",
            "Epoch 1, Loss: 1.1822528904303908e-05\n",
            "Epoch 1, Loss: 1.369104484183481e-05\n",
            "Epoch 1, Loss: 1.0695128366933204e-05\n",
            "Epoch 1, Loss: 1.1061718396376818e-05\n",
            "Epoch 1, Loss: 1.2267101737961639e-05\n",
            "Epoch 1, Loss: 1.2694094039034098e-05\n",
            "Epoch 1, Loss: 8.701494152774103e-06\n",
            "Epoch 1, Loss: 1.389416320307646e-05\n",
            "Epoch 1, Loss: 1.0677836144168396e-05\n",
            "Epoch 1, Loss: 1.140709991886979e-05\n",
            "Epoch 1, Loss: 8.961933417594992e-06\n",
            "Epoch 1, Loss: 8.73424232850084e-06\n",
            "Epoch 1, Loss: 1.3396119356912095e-05\n",
            "Epoch 1, Loss: 9.527218026050832e-06\n",
            "Epoch 1, Loss: 1.3191347534302622e-05\n",
            "Epoch 1, Loss: 1.2512437024270184e-05\n",
            "Epoch 1, Loss: 1.0296839718648698e-05\n",
            "Epoch 1, Loss: 1.1408764294174034e-05\n",
            "Epoch 1, Loss: 1.309430444962345e-05\n",
            "Epoch 1, Loss: 1.1907689440704416e-05\n",
            "Epoch 1, Loss: 1.088986755348742e-05\n",
            "Epoch 1, Loss: 9.209082236338872e-06\n",
            "Epoch 1, Loss: 1.0528362508921418e-05\n",
            "Epoch 1, Loss: 8.430973139184061e-06\n",
            "Epoch 1, Loss: 1.1017257747880649e-05\n",
            "Epoch 1, Loss: 1.1972178072028328e-05\n",
            "Epoch 1, Loss: 1.8821519915945828e-05\n",
            "Epoch 1, Loss: 1.1935101611015853e-05\n",
            "Epoch 1, Loss: 9.931112799677067e-06\n",
            "Epoch 1, Loss: 2.6715497369877994e-05\n",
            "Epoch 1, Loss: 1.1022862054232974e-05\n",
            "Epoch 1, Loss: 1.1002782230207231e-05\n",
            "Epoch 1, Loss: 1.1785238712036517e-05\n",
            "Epoch 1, Loss: 1.1740597983589396e-05\n",
            "Epoch 1, Loss: 9.310390851169359e-06\n",
            "Epoch 1, Loss: 9.704517651698552e-06\n",
            "Epoch 1, Loss: 1.2563729796966072e-05\n",
            "Epoch 1, Loss: 1.3540326108341105e-05\n",
            "Epoch 1, Loss: 1.555779999762308e-05\n",
            "Epoch 1, Loss: 1.1332920621498488e-05\n",
            "Epoch 1, Loss: 9.972057341656182e-06\n",
            "Epoch 1, Loss: 1.0654356628947426e-05\n",
            "Epoch 1, Loss: 1.236415482708253e-05\n",
            "Epoch 1, Loss: 9.320516255684197e-06\n",
            "Epoch 1, Loss: 1.3194988241593819e-05\n",
            "Epoch 1, Loss: 1.1517686289153062e-05\n",
            "Epoch 1, Loss: 1.2402663742250297e-05\n",
            "Epoch 1, Loss: 1.2669900570472237e-05\n",
            "Epoch 1, Loss: 1.0116174962604418e-05\n",
            "Epoch 1, Loss: 1.0682331776479259e-05\n",
            "Epoch 1, Loss: 1.2413212971296161e-05\n",
            "Epoch 1, Loss: 1.2425522982084658e-05\n",
            "Epoch 1, Loss: 9.980324648495298e-06\n",
            "Epoch 1, Loss: 1.428886844223598e-05\n",
            "Epoch 1, Loss: 1.1545370398380328e-05\n",
            "Epoch 1, Loss: 1.0132858733413741e-05\n",
            "Epoch 1, Loss: 1.2163881365268026e-05\n",
            "Epoch 1, Loss: 1.073205112334108e-05\n",
            "Epoch 1, Loss: 1.011581662169192e-05\n",
            "Epoch 1, Loss: 1.076419994205935e-05\n",
            "Epoch 1, Loss: 1.6405487258452922e-05\n",
            "Epoch 1, Loss: 1.1907486623385921e-05\n",
            "Epoch 1, Loss: 1.2191089808766264e-05\n",
            "Epoch 1, Loss: 1.051915478456067e-05\n",
            "Epoch 1, Loss: 1.1266044566582423e-05\n",
            "Epoch 1, Loss: 1.0013155588239897e-05\n",
            "Epoch 1, Loss: 1.1483984053484164e-05\n",
            "Epoch 1, Loss: 1.012788197840564e-05\n",
            "Epoch 1, Loss: 1.2966787835466675e-05\n",
            "Epoch 1, Loss: 1.285473808820825e-05\n",
            "Epoch 1, Loss: 1.0852433661057148e-05\n",
            "Epoch 1, Loss: 9.36841570364777e-06\n",
            "Epoch 1, Loss: 1.562898250995204e-05\n",
            "Epoch 1, Loss: 9.6088697318919e-06\n",
            "Epoch 1, Loss: 1.097720905818278e-05\n",
            "Epoch 1, Loss: 1.008239541988587e-05\n",
            "Epoch 1, Loss: 1.3224093891039956e-05\n",
            "Epoch 1, Loss: 9.75854436546797e-06\n",
            "Epoch 1, Loss: 1.2813392459065653e-05\n",
            "Epoch 1, Loss: 1.186827830679249e-05\n",
            "Epoch 1, Loss: 1.1478979104140308e-05\n",
            "Epoch 1, Loss: 1.3448059689835645e-05\n",
            "Epoch 1, Loss: 1.1726407137757633e-05\n",
            "Epoch 1, Loss: 1.1829177310573868e-05\n",
            "Epoch 1, Loss: 1.0925593414867762e-05\n",
            "Epoch 1, Loss: 1.0562715942796785e-05\n",
            "Epoch 1, Loss: 1.6326022887369618e-05\n",
            "Epoch 1, Loss: 1.3604584637505468e-05\n",
            "Epoch 1, Loss: 9.931020940712187e-06\n",
            "Epoch 1, Loss: 8.709528628969565e-06\n",
            "Epoch 1, Loss: 1.3311730981513392e-05\n",
            "Epoch 1, Loss: 1.1596600415941793e-05\n",
            "Epoch 1, Loss: 1.1805596841441002e-05\n",
            "Epoch 1, Loss: 8.849324331094977e-06\n",
            "Epoch 1, Loss: 1.1957536116824485e-05\n",
            "Epoch 1, Loss: 1.105229057429824e-05\n",
            "Epoch 1, Loss: 1.0756275514722802e-05\n",
            "Epoch 1, Loss: 1.0951795047731139e-05\n",
            "Epoch 1, Loss: 1.0276111424900591e-05\n",
            "Epoch 1, Loss: 1.4296412700787187e-05\n",
            "Epoch 1, Loss: 1.0885529263759963e-05\n",
            "Epoch 1, Loss: 1.0357942301197909e-05\n",
            "Epoch 1, Loss: 1.2347392839728855e-05\n",
            "Epoch 1, Loss: 1.542999962111935e-05\n",
            "Epoch 1, Loss: 1.6030322512960993e-05\n",
            "Epoch 1, Loss: 1.1598602213780396e-05\n",
            "Epoch 1, Loss: 9.069664884009399e-06\n",
            "Epoch 1, Loss: 1.0987604582624044e-05\n",
            "Epoch 1, Loss: 1.1325649211357813e-05\n",
            "Epoch 1, Loss: 1.0431303053337615e-05\n",
            "Epoch 1, Loss: 1.310154220846016e-05\n",
            "Epoch 1, Loss: 1.0393581760581583e-05\n",
            "Epoch 1, Loss: 1.706282637314871e-05\n",
            "Epoch 1, Loss: 1.2500503544288222e-05\n",
            "Epoch 1, Loss: 9.563924322719686e-06\n",
            "Epoch 1, Loss: 1.1241882930335123e-05\n",
            "Epoch 1, Loss: 1.1964880286541302e-05\n",
            "Epoch 1, Loss: 1.4782673133595381e-05\n",
            "Epoch 1, Loss: 2.4148088414222002e-05\n",
            "Epoch 1, Loss: 1.0344997463107575e-05\n",
            "Epoch 1, Loss: 1.2068614523741417e-05\n",
            "Epoch 1, Loss: 1.3015687727602199e-05\n",
            "Epoch 1, Loss: 1.2399749721225817e-05\n",
            "Epoch 1, Loss: 1.1686871403071564e-05\n",
            "Epoch 1, Loss: 1.3427857084025163e-05\n",
            "Epoch 1, Loss: 1.000378961180104e-05\n",
            "Epoch 1, Loss: 1.0341069355490617e-05\n",
            "Epoch 1, Loss: 1.0665027730283327e-05\n",
            "Epoch 1, Loss: 1.1537015780049842e-05\n",
            "Epoch 1, Loss: 1.101814086723607e-05\n",
            "Epoch 1, Loss: 1.5915646145003848e-05\n",
            "Epoch 1, Loss: 1.040374263538979e-05\n",
            "Epoch 1, Loss: 1.3596674762084149e-05\n",
            "Epoch 1, Loss: 1.0728535926318727e-05\n",
            "Epoch 1, Loss: 1.0359956831962336e-05\n",
            "Epoch 1, Loss: 1.0667167771316599e-05\n",
            "Epoch 1, Loss: 9.141400369117036e-06\n",
            "Epoch 1, Loss: 1.1771811841754243e-05\n",
            "Epoch 1, Loss: 1.2735935342789162e-05\n",
            "Epoch 1, Loss: 1.0303534509148449e-05\n",
            "Epoch 1, Loss: 1.0805858437379356e-05\n",
            "Epoch 1, Loss: 1.0648663192114327e-05\n",
            "Epoch 1, Loss: 1.240075653186068e-05\n",
            "Epoch 1, Loss: 1.3189057426643558e-05\n",
            "Epoch 1, Loss: 1.1504323992994614e-05\n",
            "Epoch 1, Loss: 1.0176268006034661e-05\n",
            "Epoch 1, Loss: 9.4542028818978e-06\n",
            "Epoch 1, Loss: 1.233555030921707e-05\n",
            "Epoch 1, Loss: 1.0764096259663347e-05\n",
            "Epoch 1, Loss: 1.3431884326564614e-05\n",
            "Epoch 1, Loss: 1.1443745279393625e-05\n",
            "Epoch 1, Loss: 9.941309144778643e-06\n",
            "Epoch 1, Loss: 9.284697625844274e-06\n",
            "Epoch 1, Loss: 1.0114701581187546e-05\n",
            "Epoch 1, Loss: 1.0262391697324347e-05\n",
            "Epoch 1, Loss: 9.319823220721446e-06\n",
            "Epoch 1, Loss: 1.390519264532486e-05\n",
            "Epoch 1, Loss: 1.001054624794051e-05\n",
            "Epoch 1, Loss: 1.2619660992641002e-05\n",
            "Epoch 1, Loss: 1.727558446873445e-05\n",
            "Epoch 1, Loss: 1.1661506505333818e-05\n",
            "Epoch 1, Loss: 1.126665847550612e-05\n",
            "Epoch 1, Loss: 1.4227593055693433e-05\n",
            "Epoch 1, Loss: 9.15674536372535e-06\n",
            "Epoch 1, Loss: 9.339762982563116e-06\n",
            "Epoch 1, Loss: 9.790333024284337e-06\n",
            "Epoch 1, Loss: 1.1353349691489711e-05\n",
            "Epoch 1, Loss: 9.044150829140563e-06\n",
            "Epoch 1, Loss: 9.64144965109881e-06\n",
            "Epoch 1, Loss: 1.1376339898561127e-05\n",
            "Epoch 1, Loss: 1.1561097380763385e-05\n",
            "Epoch 1, Loss: 8.28508837003028e-06\n",
            "Epoch 1, Loss: 9.814250915951561e-06\n",
            "Epoch 1, Loss: 1.2271774721739348e-05\n",
            "Epoch 1, Loss: 1.2704476830549538e-05\n",
            "Epoch 1, Loss: 1.0001456757890992e-05\n",
            "Epoch 1, Loss: 1.038583923218539e-05\n",
            "Epoch 1, Loss: 9.844072337727994e-06\n",
            "Epoch 1, Loss: 1.0678522812668234e-05\n",
            "Epoch 1, Loss: 1.1527137758093886e-05\n",
            "Epoch 1, Loss: 9.113161468121689e-06\n",
            "Epoch 1, Loss: 1.1914333299500868e-05\n",
            "Epoch 1, Loss: 1.4700806787004694e-05\n",
            "Epoch 1, Loss: 9.369878171128221e-06\n",
            "Epoch 1, Loss: 1.0429414942336734e-05\n",
            "Epoch 1, Loss: 1.0872634447878227e-05\n",
            "Epoch 1, Loss: 1.2778761629306246e-05\n",
            "Epoch 1, Loss: 1.095514016924426e-05\n",
            "Epoch 1, Loss: 1.080265883501852e-05\n",
            "Epoch 1, Loss: 1.3224766917119268e-05\n",
            "Epoch 1, Loss: 1.1752093996619806e-05\n",
            "Epoch 1, Loss: 1.14625081550912e-05\n",
            "Epoch 1, Loss: 1.2611660167749505e-05\n",
            "Epoch 1, Loss: 8.178474672604352e-06\n",
            "Epoch 1, Loss: 8.456106115772855e-06\n",
            "Epoch 1, Loss: 1.0451801244926173e-05\n",
            "Epoch 1, Loss: 1.7834134268923663e-05\n",
            "Epoch 1, Loss: 9.20907041290775e-06\n",
            "Epoch 1, Loss: 1.3479184417519718e-05\n",
            "Epoch 1, Loss: 1.1358682058926206e-05\n",
            "Epoch 1, Loss: 1.2154910109529737e-05\n",
            "Epoch 1, Loss: 1.005700232781237e-05\n",
            "Epoch 1, Loss: 1.015374709822936e-05\n",
            "Epoch 1, Loss: 1.5292622265405953e-05\n",
            "Epoch 1, Loss: 9.479625077801757e-06\n",
            "Epoch 1, Loss: 1.2533727385743987e-05\n",
            "Epoch 1, Loss: 7.758859283057973e-06\n",
            "Epoch 1, Loss: 1.6758704077801667e-05\n",
            "Epoch 1, Loss: 1.1837679267046042e-05\n",
            "Epoch 1, Loss: 1.0771624147309922e-05\n",
            "Epoch 1, Loss: 1.1536452802829444e-05\n",
            "Epoch 1, Loss: 1.0148184628633317e-05\n",
            "Epoch 1, Loss: 1.1609587090788409e-05\n",
            "Epoch 1, Loss: 1.0271316568832844e-05\n",
            "Epoch 1, Loss: 1.2641761713894084e-05\n",
            "Epoch 1, Loss: 1.0186048712057527e-05\n",
            "Epoch 1, Loss: 9.229525858245324e-06\n",
            "Epoch 1, Loss: 8.346865797648206e-06\n",
            "Epoch 1, Loss: 1.0902735084528103e-05\n",
            "Epoch 1, Loss: 8.841427188599482e-06\n",
            "Epoch 1, Loss: 8.62984870764194e-06\n",
            "Epoch 1, Loss: 1.256840187124908e-05\n",
            "Epoch 1, Loss: 8.262899427791126e-06\n",
            "Epoch 1, Loss: 1.070995676855091e-05\n",
            "Epoch 1, Loss: 1.04603304862394e-05\n",
            "Epoch 1, Loss: 1.389063891110709e-05\n",
            "Epoch 1, Loss: 9.765582035470288e-06\n",
            "Epoch 1, Loss: 1.0195146387559362e-05\n",
            "Epoch 1, Loss: 1.1320855264784768e-05\n",
            "Epoch 1, Loss: 1.2552929547382519e-05\n",
            "Epoch 1, Loss: 1.072140184987802e-05\n",
            "Epoch 1, Loss: 1.0072219083667733e-05\n",
            "Epoch 1, Loss: 1.2513610272435471e-05\n",
            "Epoch 1, Loss: 1.1737707609427162e-05\n",
            "Epoch 1, Loss: 1.0557586392678786e-05\n",
            "Epoch 1, Loss: 1.0407175977888983e-05\n",
            "Epoch 1, Loss: 7.644387551408727e-06\n",
            "Epoch 1, Loss: 1.0158898476220202e-05\n",
            "Epoch 1, Loss: 1.1800309948739596e-05\n",
            "Epoch 1, Loss: 8.859082299750298e-06\n",
            "Epoch 1, Loss: 1.014079407468671e-05\n",
            "Epoch 1, Loss: 1.0647661838447675e-05\n",
            "Epoch 1, Loss: 9.889435204968322e-06\n",
            "Epoch 1, Loss: 9.334854439657647e-06\n",
            "Epoch 1, Loss: 1.123258061852539e-05\n",
            "Epoch 1, Loss: 9.898060852719937e-06\n",
            "Epoch 1, Loss: 9.90369517239742e-06\n",
            "Epoch 1, Loss: 1.0743814527813811e-05\n",
            "Epoch 1, Loss: 9.983299605664797e-06\n",
            "Epoch 1, Loss: 9.46585805650102e-06\n",
            "Epoch 1, Loss: 1.06931765913032e-05\n",
            "Epoch 1, Loss: 1.1332510439387988e-05\n",
            "Epoch 1, Loss: 1.4915702195139602e-05\n",
            "Epoch 1, Loss: 8.53260098665487e-06\n",
            "Epoch 1, Loss: 8.282151611638255e-06\n",
            "Epoch 1, Loss: 9.496013262833003e-06\n",
            "Epoch 1, Loss: 8.872500075085554e-06\n",
            "Epoch 1, Loss: 9.606476851331536e-06\n",
            "Epoch 1, Loss: 9.218469131155871e-06\n",
            "Epoch 1, Loss: 1.1189883480255958e-05\n",
            "Epoch 1, Loss: 1.0521250260353554e-05\n",
            "Epoch 1, Loss: 1.0278830814058892e-05\n",
            "Epoch 1, Loss: 1.082088601833675e-05\n",
            "Epoch 1, Loss: 1.1918554264411796e-05\n",
            "Epoch 1, Loss: 9.397776921105105e-06\n",
            "Epoch 1, Loss: 9.864283128990792e-06\n",
            "Epoch 1, Loss: 8.869237717590295e-06\n",
            "Epoch 1, Loss: 1.2540162970253732e-05\n",
            "Epoch 1, Loss: 9.94696074485546e-06\n",
            "Epoch 1, Loss: 1.2294714906602167e-05\n",
            "Epoch 1, Loss: 1.048633384925779e-05\n",
            "Epoch 1, Loss: 9.394136213813908e-06\n",
            "Epoch 1, Loss: 1.1343985534040257e-05\n",
            "Epoch 1, Loss: 9.84527559921844e-06\n",
            "Epoch 1, Loss: 1.0692793694033753e-05\n",
            "Epoch 1, Loss: 8.648702532809693e-06\n",
            "Epoch 1, Loss: 1.2374423022265546e-05\n",
            "Epoch 1, Loss: 9.243571184924804e-06\n",
            "Epoch 1, Loss: 1.1308729881420732e-05\n",
            "Epoch 1, Loss: 8.27146322990302e-06\n",
            "Epoch 1, Loss: 1.0428382665850222e-05\n",
            "Epoch 1, Loss: 9.54127244767733e-06\n",
            "Epoch 1, Loss: 1.4119877960183658e-05\n",
            "Epoch 1, Loss: 1.1971043022640515e-05\n",
            "Epoch 1, Loss: 9.412821782461833e-06\n",
            "Epoch 1, Loss: 1.2645608876482584e-05\n",
            "Epoch 1, Loss: 1.1494385944388341e-05\n",
            "Epoch 1, Loss: 8.771543434704654e-06\n",
            "Epoch 1, Loss: 1.0332229976484086e-05\n",
            "Epoch 1, Loss: 1.014359986584168e-05\n",
            "Epoch 1, Loss: 9.80906406766735e-06\n",
            "Epoch 1, Loss: 1.1291677765257191e-05\n",
            "Epoch 1, Loss: 9.7994970928994e-06\n",
            "Epoch 1, Loss: 1.1153194463986438e-05\n",
            "Epoch 1, Loss: 1.0253632353851572e-05\n",
            "Epoch 1, Loss: 1.2953906662005465e-05\n",
            "Epoch 1, Loss: 9.774754289537668e-06\n",
            "Epoch 1, Loss: 7.433443897753023e-06\n",
            "Epoch 1, Loss: 1.0269932317896746e-05\n",
            "Epoch 1, Loss: 9.532114745525178e-06\n",
            "Epoch 1, Loss: 9.98934410745278e-06\n",
            "Epoch 1, Loss: 1.3283295629662462e-05\n",
            "Epoch 1, Loss: 1.6439393220935017e-05\n",
            "Epoch 1, Loss: 9.306322681368329e-06\n",
            "Epoch 1, Loss: 9.678924470790662e-06\n",
            "Epoch 1, Loss: 1.2209015949338209e-05\n",
            "Epoch 1, Loss: 9.33834417082835e-06\n",
            "Epoch 1, Loss: 1.4551398635376245e-05\n",
            "Epoch 1, Loss: 8.948545655584894e-06\n",
            "Epoch 1, Loss: 9.529190720058978e-06\n",
            "Epoch 1, Loss: 1.2389872608764563e-05\n",
            "Epoch 1, Loss: 1.0314418432244565e-05\n",
            "Epoch 1, Loss: 9.849983143794816e-06\n",
            "Epoch 1, Loss: 1.1019087651220616e-05\n",
            "Epoch 1, Loss: 1.1122770956717432e-05\n",
            "Epoch 1, Loss: 9.595063602318987e-06\n",
            "Epoch 1, Loss: 8.968819201982114e-06\n",
            "Epoch 1, Loss: 1.0626926268741954e-05\n",
            "Epoch 1, Loss: 9.492880963080097e-06\n",
            "Epoch 1, Loss: 1.1830865332740359e-05\n",
            "Epoch 1, Loss: 8.976683602668345e-06\n",
            "Epoch 1, Loss: 1.0490774002391845e-05\n",
            "Epoch 1, Loss: 1.3199552995502017e-05\n",
            "Epoch 1, Loss: 1.0720464160840493e-05\n",
            "Epoch 1, Loss: 1.3347829735721461e-05\n",
            "Epoch 1, Loss: 8.785945283307228e-06\n",
            "Epoch 1, Loss: 1.1013587936758995e-05\n",
            "Epoch 1, Loss: 9.039077667694073e-06\n",
            "Epoch 1, Loss: 1.0814277629833668e-05\n",
            "Epoch 1, Loss: 1.0377607395639643e-05\n",
            "Epoch 1, Loss: 8.883617738320027e-06\n",
            "Epoch 1, Loss: 9.510945346846711e-06\n",
            "Epoch 1, Loss: 9.47458920563804e-06\n",
            "Epoch 1, Loss: 1.2423351108736824e-05\n",
            "Epoch 1, Loss: 1.0026268682850059e-05\n",
            "Epoch 1, Loss: 1.411383072991157e-05\n",
            "Epoch 1, Loss: 9.388896614836995e-06\n",
            "Epoch 1, Loss: 8.729638466320466e-06\n",
            "Epoch 1, Loss: 9.945257261279039e-06\n",
            "Epoch 1, Loss: 7.223499778774567e-06\n",
            "Epoch 1, Loss: 1.3142937859811354e-05\n",
            "Epoch 1, Loss: 1.1141675713588484e-05\n",
            "Epoch 1, Loss: 8.7402750068577e-06\n",
            "Epoch 1, Loss: 9.458563908992801e-06\n",
            "Epoch 1, Loss: 9.00522354640998e-06\n",
            "Epoch 1, Loss: 1.218336728925351e-05\n",
            "Epoch 1, Loss: 1.2932355275552254e-05\n",
            "Epoch 1, Loss: 9.901148587232456e-06\n",
            "Epoch 1, Loss: 9.269611837225966e-06\n",
            "Epoch 1, Loss: 9.379333278047852e-06\n",
            "Epoch 1, Loss: 1.1168874152645003e-05\n",
            "Epoch 1, Loss: 9.590626177669037e-06\n",
            "Epoch 1, Loss: 9.838645382842515e-06\n",
            "Epoch 1, Loss: 1.1413718311814591e-05\n",
            "Epoch 1, Loss: 9.213421435561031e-06\n",
            "Epoch 1, Loss: 9.657926057116129e-06\n",
            "Epoch 1, Loss: 9.477930689172354e-06\n",
            "Epoch 1, Loss: 1.9734476154553704e-05\n",
            "Epoch 1, Loss: 9.857129043666646e-06\n",
            "Epoch 1, Loss: 9.771420081960969e-06\n",
            "Epoch 1, Loss: 1.1586300388444215e-05\n",
            "Epoch 1, Loss: 1.2000450624327641e-05\n",
            "Epoch 1, Loss: 1.1374967471056152e-05\n",
            "Epoch 1, Loss: 8.639635780127719e-06\n",
            "Epoch 1, Loss: 1.1680325769702904e-05\n",
            "Epoch 1, Loss: 1.07812575151911e-05\n",
            "Epoch 1, Loss: 1.0508871127967723e-05\n",
            "Epoch 1, Loss: 1.1106340025435202e-05\n",
            "Epoch 1, Loss: 7.959466529428028e-06\n",
            "Epoch 1, Loss: 1.1425126103858929e-05\n",
            "Epoch 1, Loss: 1.0817296242748853e-05\n",
            "Epoch 1, Loss: 9.865439096756745e-06\n",
            "Epoch 1, Loss: 1.0521310287003871e-05\n",
            "Epoch 1, Loss: 9.56574240262853e-06\n",
            "Epoch 1, Loss: 8.961903404269833e-06\n",
            "Epoch 1, Loss: 1.3321126061782707e-05\n",
            "Epoch 1, Loss: 8.86214093043236e-06\n",
            "Epoch 1, Loss: 1.1555644960026257e-05\n",
            "Epoch 1, Loss: 1.8190965420217253e-05\n",
            "Epoch 1, Loss: 1.1704500138876028e-05\n",
            "Epoch 1, Loss: 8.576093023293652e-06\n",
            "Epoch 1, Loss: 1.0469556400494184e-05\n",
            "Epoch 1, Loss: 9.017793672683183e-06\n",
            "Epoch 1, Loss: 1.194587275676895e-05\n",
            "Epoch 1, Loss: 9.170679732051212e-06\n",
            "Epoch 1, Loss: 8.733976756047923e-06\n",
            "Epoch 1, Loss: 9.880011930363253e-06\n",
            "Epoch 1, Loss: 1.2342657100816723e-05\n",
            "Epoch 1, Loss: 8.83321808942128e-06\n",
            "Epoch 1, Loss: 1.055525444826344e-05\n",
            "Epoch 1, Loss: 1.1549502232810482e-05\n",
            "Epoch 1, Loss: 1.1647629435174167e-05\n",
            "Epoch 1, Loss: 9.03900399862323e-06\n",
            "Epoch 1, Loss: 9.863667401077691e-06\n",
            "Epoch 1, Loss: 9.396570021635853e-06\n",
            "Epoch 1, Loss: 1.5593564967275597e-05\n",
            "Epoch 1, Loss: 9.934519766829908e-06\n",
            "Epoch 1, Loss: 1.767520370776765e-05\n",
            "Epoch 1, Loss: 9.292330105381552e-06\n",
            "Epoch 1, Loss: 9.95953905658098e-06\n",
            "Epoch 1, Loss: 8.77155162015697e-06\n",
            "Epoch 1, Loss: 1.2284146578167565e-05\n",
            "Epoch 1, Loss: 1.2853020962211303e-05\n",
            "Epoch 1, Loss: 1.2755614079651423e-05\n",
            "Epoch 1, Loss: 8.762788638705388e-06\n",
            "Epoch 1, Loss: 9.900677468976937e-06\n",
            "Epoch 1, Loss: 9.81424545898335e-06\n",
            "Epoch 1, Loss: 8.531168532499578e-06\n",
            "Epoch 1, Loss: 1.1769104276027065e-05\n",
            "Epoch 1, Loss: 8.725164661882445e-06\n",
            "Epoch 1, Loss: 9.607345418771729e-06\n",
            "Epoch 1, Loss: 9.882504855340812e-06\n",
            "Epoch 1, Loss: 1.1283829735475592e-05\n",
            "Epoch 1, Loss: 1.0494652997294907e-05\n",
            "Epoch 1, Loss: 1.0216946066066157e-05\n",
            "Epoch 1, Loss: 1.1605831787164789e-05\n",
            "Epoch 1, Loss: 8.608421921962872e-06\n",
            "Epoch 1, Loss: 9.138988389167935e-06\n",
            "Epoch 1, Loss: 8.404474101553205e-06\n",
            "Epoch 1, Loss: 1.0413149539090227e-05\n",
            "Epoch 1, Loss: 1.7096466763177887e-05\n",
            "Epoch 1, Loss: 9.643610610510223e-06\n",
            "Epoch 1, Loss: 9.409082849742845e-06\n",
            "Epoch 1, Loss: 1.0313590792065952e-05\n",
            "Epoch 1, Loss: 1.1822894521174021e-05\n",
            "Epoch 1, Loss: 1.1483441085147206e-05\n",
            "Epoch 1, Loss: 9.65511026151944e-06\n",
            "Epoch 1, Loss: 8.271418664662633e-06\n",
            "Epoch 1, Loss: 9.133834282692987e-06\n",
            "Epoch 1, Loss: 9.468470125284512e-06\n",
            "Epoch 1, Loss: 1.1314770745229907e-05\n",
            "Epoch 1, Loss: 1.0457589269208256e-05\n",
            "Epoch 1, Loss: 9.922217941493727e-06\n",
            "Epoch 1, Loss: 9.050328117155004e-06\n",
            "Epoch 1, Loss: 8.565044481656514e-06\n",
            "Epoch 1, Loss: 9.441743713978212e-06\n",
            "Epoch 1, Loss: 8.869684279488865e-06\n",
            "Epoch 1, Loss: 1.2776523362845182e-05\n",
            "Epoch 1, Loss: 1.0597434084047563e-05\n",
            "Epoch 1, Loss: 1.1617376003414392e-05\n",
            "Epoch 1, Loss: 1.065986816684017e-05\n",
            "Epoch 1, Loss: 9.623097867006436e-06\n",
            "Epoch 1, Loss: 7.6260721471044235e-06\n",
            "Epoch 1, Loss: 1.0246963938698173e-05\n",
            "Epoch 1, Loss: 1.0699118320189882e-05\n",
            "Epoch 1, Loss: 9.856384167505894e-06\n",
            "Epoch 1, Loss: 9.227945156453643e-06\n",
            "Epoch 1, Loss: 8.80468542163726e-06\n",
            "Epoch 1, Loss: 1.1053400157834403e-05\n",
            "Epoch 1, Loss: 1.1596534022828564e-05\n",
            "Epoch 1, Loss: 9.414359738002531e-06\n",
            "Epoch 1, Loss: 1.2148441783210728e-05\n",
            "Epoch 1, Loss: 1.2291293387534097e-05\n",
            "Epoch 1, Loss: 9.591365596861579e-06\n",
            "Epoch 1, Loss: 1.0863293027796317e-05\n",
            "Epoch 1, Loss: 8.294431609101593e-06\n",
            "Epoch 1, Loss: 1.0118706995854154e-05\n",
            "Epoch 1, Loss: 1.1937499039049726e-05\n",
            "Epoch 1, Loss: 8.815733963274397e-06\n",
            "Epoch 1, Loss: 1.0129391739610583e-05\n",
            "Epoch 1, Loss: 1.5002485270088073e-05\n",
            "Epoch 1, Loss: 9.086124009627383e-06\n",
            "Epoch 1, Loss: 8.405737389693968e-06\n",
            "Epoch 1, Loss: 8.62789420352783e-06\n",
            "Epoch 1, Loss: 8.671428986417595e-06\n",
            "Epoch 1, Loss: 8.703801540832501e-06\n",
            "Epoch 1, Loss: 1.0612301593937445e-05\n",
            "Epoch 1, Loss: 1.2355902981653344e-05\n",
            "Epoch 1, Loss: 8.551188329875004e-06\n",
            "Epoch 1, Loss: 7.763586836517788e-06\n",
            "Epoch 1, Loss: 1.0509068488318007e-05\n",
            "Epoch 1, Loss: 9.287648936151527e-06\n",
            "Epoch 1, Loss: 8.350020834768657e-06\n",
            "Epoch 1, Loss: 1.0699285667215008e-05\n",
            "Epoch 1, Loss: 1.1446038115536794e-05\n",
            "Epoch 1, Loss: 8.789218554738909e-06\n",
            "Epoch 1, Loss: 9.736580977914855e-06\n",
            "Epoch 1, Loss: 1.141230222856393e-05\n",
            "Epoch 1, Loss: 1.3701725947612431e-05\n",
            "Epoch 1, Loss: 1.050153423420852e-05\n",
            "Epoch 1, Loss: 8.775285095907748e-06\n",
            "Epoch 1, Loss: 1.1609390639932826e-05\n",
            "Epoch 1, Loss: 1.0176489013247192e-05\n",
            "Epoch 1, Loss: 1.2384358342387713e-05\n",
            "Epoch 1, Loss: 1.037203492160188e-05\n",
            "Epoch 1, Loss: 8.734284165257122e-06\n",
            "Epoch 1, Loss: 8.289419383800123e-06\n",
            "Epoch 1, Loss: 8.590812285547145e-06\n",
            "Epoch 1, Loss: 9.846389730228111e-06\n",
            "Epoch 1, Loss: 1.033821354212705e-05\n",
            "Epoch 1, Loss: 7.977728273544926e-06\n",
            "Epoch 1, Loss: 8.66549089550972e-06\n",
            "Epoch 1, Loss: 1.1484875358291902e-05\n",
            "Epoch 1, Loss: 1.0306971489626449e-05\n",
            "Epoch 1, Loss: 9.206302820530254e-06\n",
            "Epoch 1, Loss: 8.749828339205123e-06\n",
            "Epoch 1, Loss: 1.0832557563844603e-05\n",
            "Epoch 1, Loss: 8.448771041003056e-06\n",
            "Epoch 1, Loss: 1.0396010111435317e-05\n",
            "Epoch 1, Loss: 8.326165698235855e-06\n",
            "Epoch 1, Loss: 1.0790303349494934e-05\n",
            "Epoch 1, Loss: 9.31167869566707e-06\n",
            "Epoch 1, Loss: 1.2976556718058418e-05\n",
            "Epoch 1, Loss: 1.0005858712247573e-05\n",
            "Epoch 1, Loss: 1.1673132576106582e-05\n",
            "Epoch 1, Loss: 1.0106786248798016e-05\n",
            "Epoch 1, Loss: 1.0732775990618393e-05\n",
            "Epoch 1, Loss: 8.415791853622068e-06\n",
            "Epoch 1, Loss: 1.255525421584025e-05\n",
            "Epoch 1, Loss: 1.0518450835661497e-05\n",
            "Epoch 1, Loss: 8.67619201017078e-06\n",
            "Epoch 1, Loss: 9.149413017439656e-06\n",
            "Epoch 1, Loss: 1.1897653166670352e-05\n",
            "Epoch 1, Loss: 1.0220485819445457e-05\n",
            "Epoch 1, Loss: 1.3431835213850718e-05\n",
            "Epoch 1, Loss: 1.1074351277784444e-05\n",
            "Epoch 1, Loss: 1.159380281023914e-05\n",
            "Epoch 1, Loss: 8.571962098358199e-06\n",
            "Epoch 1, Loss: 9.798895916901529e-06\n",
            "Epoch 1, Loss: 8.052800694713369e-06\n",
            "Epoch 1, Loss: 8.689778951520566e-06\n",
            "Epoch 1, Loss: 1.03871780083864e-05\n",
            "Epoch 1, Loss: 9.951938409358263e-06\n",
            "Epoch 1, Loss: 9.307432264904492e-06\n",
            "Epoch 1, Loss: 7.801991159794852e-06\n",
            "Epoch 1, Loss: 1.0125073458766565e-05\n",
            "Epoch 1, Loss: 1.0970680705213454e-05\n",
            "Epoch 1, Loss: 8.450144378002733e-06\n",
            "Epoch 1, Loss: 9.022059202834498e-06\n",
            "Epoch 1, Loss: 9.696029337646905e-06\n",
            "Epoch 1, Loss: 9.664412573329173e-06\n",
            "Epoch 1, Loss: 1.1476628060336225e-05\n",
            "Epoch 1, Loss: 9.345306352770422e-06\n",
            "Epoch 1, Loss: 1.0014850886364002e-05\n",
            "Epoch 1, Loss: 8.528791113349143e-06\n",
            "Epoch 1, Loss: 8.780596544966102e-06\n",
            "Epoch 1, Loss: 1.2906434676551726e-05\n",
            "Epoch 1, Loss: 9.318566299043596e-06\n",
            "Epoch 1, Loss: 8.205768608604558e-06\n",
            "Epoch 1, Loss: 8.813590284262318e-06\n",
            "Epoch 1, Loss: 1.2297121429583058e-05\n",
            "Epoch 1, Loss: 8.051627446548082e-06\n",
            "Epoch 1, Loss: 9.650299944041763e-06\n",
            "Epoch 1, Loss: 1.0934939382423181e-05\n",
            "Epoch 1, Loss: 1.1612120033532847e-05\n",
            "Epoch 1, Loss: 9.408195182913914e-06\n",
            "Epoch 1, Loss: 1.0630465112626553e-05\n",
            "Epoch 1, Loss: 8.909906682674773e-06\n",
            "Epoch 1, Loss: 1.0942957487714011e-05\n",
            "Epoch 1, Loss: 1.206141860166099e-05\n",
            "Epoch 1, Loss: 9.627627150621265e-06\n",
            "Epoch 1, Loss: 9.541947292746045e-06\n",
            "Epoch 1, Loss: 1.021231491904473e-05\n",
            "Epoch 1, Loss: 8.463101949018892e-06\n",
            "Epoch 1, Loss: 9.279200639866758e-06\n",
            "Epoch 1, Loss: 8.63211062096525e-06\n",
            "Epoch 1, Loss: 8.06435400590999e-06\n",
            "Epoch 1, Loss: 1.0824479431903455e-05\n",
            "Epoch 1, Loss: 1.1507699127832893e-05\n",
            "Epoch 1, Loss: 8.43216275825398e-06\n",
            "Epoch 1, Loss: 7.55995097279083e-06\n",
            "Epoch 1, Loss: 9.150669029622804e-06\n",
            "Epoch 1, Loss: 8.640407031634822e-06\n",
            "Epoch 1, Loss: 1.0278312402078882e-05\n",
            "Epoch 1, Loss: 7.079034730850253e-06\n",
            "Epoch 1, Loss: 9.273207069782075e-06\n",
            "Epoch 1, Loss: 7.313983132917201e-06\n",
            "Epoch 1, Loss: 8.55305370350834e-06\n",
            "Epoch 1, Loss: 9.309196684625931e-06\n",
            "Epoch 1, Loss: 1.0092401680594776e-05\n",
            "Epoch 1, Loss: 9.080398740479723e-06\n",
            "Epoch 1, Loss: 9.860666978056543e-06\n",
            "Epoch 1, Loss: 1.1024703781004064e-05\n",
            "Epoch 1, Loss: 8.752327630645595e-06\n",
            "Epoch 1, Loss: 9.888619388220832e-06\n",
            "Epoch 1, Loss: 8.011291356524453e-06\n",
            "Epoch 1, Loss: 8.560528840462212e-06\n",
            "Epoch 1, Loss: 1.053787400451256e-05\n",
            "Epoch 1, Loss: 8.850291123962961e-06\n",
            "Epoch 1, Loss: 9.792370292416308e-06\n",
            "Epoch 1, Loss: 1.19447704491904e-05\n",
            "Epoch 1, Loss: 1.1178372005815618e-05\n",
            "Epoch 1, Loss: 8.874485502019525e-06\n",
            "Epoch 1, Loss: 7.42809197618044e-06\n",
            "Epoch 1, Loss: 9.268420399166644e-06\n",
            "Epoch 1, Loss: 1.1343637197569478e-05\n",
            "Epoch 1, Loss: 8.029404853004962e-06\n",
            "Epoch 1, Loss: 8.646845344628673e-06\n",
            "Epoch 1, Loss: 9.423155461263377e-06\n",
            "Epoch 1, Loss: 1.0199616554018576e-05\n",
            "Epoch 1, Loss: 9.230833711626474e-06\n",
            "Epoch 1, Loss: 8.945975423557684e-06\n",
            "Epoch 1, Loss: 8.505474397679791e-06\n",
            "Epoch 1, Loss: 8.153446287906263e-06\n",
            "Epoch 1, Loss: 8.842373063089326e-06\n",
            "Epoch 1, Loss: 1.060026897903299e-05\n",
            "Epoch 1, Loss: 9.357218914374243e-06\n",
            "Epoch 1, Loss: 7.402762093988713e-06\n",
            "Epoch 1, Loss: 9.617742762202397e-06\n",
            "Epoch 1, Loss: 8.32600926514715e-06\n",
            "Epoch 1, Loss: 7.679695954720955e-06\n",
            "Epoch 1, Loss: 1.0643451787473168e-05\n",
            "Epoch 1, Loss: 9.431679245608393e-06\n",
            "Epoch 1, Loss: 9.785469956113957e-06\n",
            "Epoch 1, Loss: 8.672516742080916e-06\n",
            "Epoch 1, Loss: 8.640322448627558e-06\n",
            "Epoch 1, Loss: 1.125904054788407e-05\n",
            "Epoch 1, Loss: 1.0851590559468605e-05\n",
            "Epoch 1, Loss: 1.0636679689923767e-05\n",
            "Epoch 1, Loss: 1.0436836419103201e-05\n",
            "Epoch 1, Loss: 9.119939932134002e-06\n",
            "Epoch 1, Loss: 9.920180673361756e-06\n",
            "Epoch 1, Loss: 8.171502486220561e-06\n",
            "Epoch 1, Loss: 1.0046707757283002e-05\n",
            "Epoch 1, Loss: 1.1054392416554037e-05\n",
            "Epoch 1, Loss: 8.169176908268128e-06\n",
            "Epoch 1, Loss: 1.0063688932859804e-05\n",
            "Epoch 1, Loss: 9.620491255191155e-06\n",
            "Epoch 1, Loss: 9.558475539961364e-06\n",
            "Epoch 1, Loss: 7.657289643248077e-06\n",
            "Epoch 1, Loss: 8.043566595006268e-06\n",
            "Epoch 1, Loss: 8.345863534486853e-06\n",
            "Epoch 1, Loss: 8.08569438959239e-06\n",
            "Epoch 1, Loss: 8.531218554708175e-06\n",
            "Epoch 1, Loss: 9.62069952947786e-06\n",
            "Epoch 1, Loss: 8.657249054522254e-06\n",
            "Epoch 1, Loss: 7.297286174434703e-06\n",
            "Epoch 1, Loss: 9.681674782768823e-06\n",
            "Epoch 1, Loss: 8.871849786373787e-06\n",
            "Epoch 1, Loss: 8.43576890474651e-06\n",
            "Epoch 1, Loss: 9.347917512059212e-06\n",
            "Epoch 1, Loss: 8.114312549878377e-06\n",
            "Epoch 1, Loss: 1.5639558114344254e-05\n",
            "Epoch 1, Loss: 1.0340515473217238e-05\n",
            "Epoch 1, Loss: 9.24001960811438e-06\n",
            "Epoch 1, Loss: 9.9790431704605e-06\n",
            "Epoch 1, Loss: 1.2257016351213679e-05\n",
            "Epoch 1, Loss: 9.864088497124612e-06\n",
            "Epoch 1, Loss: 1.2508294275903609e-05\n",
            "Epoch 1, Loss: 7.648300197615754e-06\n",
            "Epoch 1, Loss: 1.6567664715694264e-05\n",
            "Epoch 1, Loss: 1.0575986379990354e-05\n",
            "Epoch 1, Loss: 8.243011507147457e-06\n",
            "Epoch 1, Loss: 9.48250999499578e-06\n",
            "Epoch 1, Loss: 7.752949386485852e-06\n",
            "Epoch 1, Loss: 1.0527595804887824e-05\n",
            "Epoch 1, Loss: 1.177460126200458e-05\n",
            "Epoch 1, Loss: 8.67736162035726e-06\n",
            "Epoch 1, Loss: 8.374141543754376e-06\n",
            "Epoch 1, Loss: 8.555981366953347e-06\n",
            "Epoch 1, Loss: 8.682031875650864e-06\n",
            "Epoch 1, Loss: 8.092051757557783e-06\n",
            "Epoch 1, Loss: 9.189871889248025e-06\n",
            "Epoch 1, Loss: 9.463782589591574e-06\n",
            "Epoch 1, Loss: 8.275285836134572e-06\n",
            "Epoch 1, Loss: 9.665902325650677e-06\n",
            "Epoch 1, Loss: 8.905270988179836e-06\n",
            "Epoch 1, Loss: 1.109179083869094e-05\n",
            "Epoch 1, Loss: 1.7455618944950402e-05\n",
            "Epoch 1, Loss: 8.448660992144141e-06\n",
            "Epoch 1, Loss: 1.0425061191199347e-05\n",
            "Epoch 1, Loss: 8.021413123060483e-06\n",
            "Epoch 1, Loss: 7.523003660026006e-06\n",
            "Epoch 1, Loss: 9.246111403626855e-06\n",
            "Epoch 1, Loss: 8.967635949375108e-06\n",
            "Epoch 1, Loss: 8.178547432180494e-06\n",
            "Epoch 1, Loss: 8.949710718297865e-06\n",
            "Epoch 1, Loss: 1.0129384463652968e-05\n",
            "Epoch 1, Loss: 8.653434633743018e-06\n",
            "Epoch 1, Loss: 1.1386413461877964e-05\n",
            "Epoch 1, Loss: 8.946791240305174e-06\n",
            "Epoch 1, Loss: 8.841672752168961e-06\n",
            "Epoch 1, Loss: 1.0387979273218662e-05\n",
            "Epoch 1, Loss: 8.73762746778084e-06\n",
            "Epoch 1, Loss: 8.90002502274001e-06\n",
            "Epoch 1, Loss: 9.412305189471226e-06\n",
            "Epoch 1, Loss: 9.049263098859228e-06\n",
            "Epoch 1, Loss: 7.332531367865158e-06\n",
            "Epoch 1, Loss: 8.642569810035639e-06\n",
            "Epoch 1, Loss: 9.318996490037534e-06\n",
            "Epoch 1, Loss: 9.482492714596447e-06\n",
            "Epoch 1, Loss: 8.337114195455797e-06\n",
            "Epoch 1, Loss: 8.083476132014766e-06\n",
            "Epoch 1, Loss: 7.745352377241943e-06\n",
            "Epoch 1, Loss: 9.524374036118388e-06\n",
            "Epoch 1, Loss: 7.786177775415126e-06\n",
            "Epoch 1, Loss: 9.245172805094626e-06\n",
            "Epoch 1, Loss: 1.036483718053205e-05\n",
            "Epoch 1, Loss: 1.257364965567831e-05\n",
            "Epoch 1, Loss: 1.00333172667888e-05\n",
            "Epoch 1, Loss: 9.267406312574167e-06\n",
            "Epoch 1, Loss: 9.256878911401145e-06\n",
            "Epoch 1, Loss: 8.430166417383589e-06\n",
            "Epoch 1, Loss: 9.539531674818136e-06\n",
            "Epoch 1, Loss: 9.949388186214492e-06\n",
            "Epoch 1, Loss: 8.857568900566548e-06\n",
            "Epoch 1, Loss: 8.151569090841804e-06\n",
            "Epoch 1, Loss: 1.1425709089962766e-05\n",
            "Epoch 1, Loss: 9.249090908269864e-06\n",
            "Epoch 1, Loss: 8.741619240026921e-06\n",
            "Epoch 1, Loss: 6.655354809481651e-06\n",
            "Epoch 1, Loss: 9.057430361281149e-06\n",
            "Epoch 1, Loss: 7.044142876111437e-06\n",
            "Epoch 1, Loss: 8.57520990393823e-06\n",
            "Epoch 1, Loss: 7.714755156484898e-06\n",
            "Epoch 1, Loss: 8.644180525152478e-06\n",
            "Epoch 1, Loss: 8.908809832064435e-06\n",
            "Epoch 1, Loss: 9.146262527792715e-06\n",
            "Epoch 1, Loss: 9.82566962193232e-06\n",
            "Epoch 1, Loss: 1.139250070991693e-05\n",
            "Epoch 1, Loss: 9.187138857669197e-06\n",
            "Epoch 1, Loss: 8.930535841500387e-06\n",
            "Epoch 1, Loss: 9.512610631645657e-06\n",
            "Epoch 1, Loss: 9.979054084396921e-06\n",
            "Epoch 1, Loss: 9.911203960655257e-06\n",
            "Epoch 1, Loss: 9.773245437827427e-06\n",
            "Epoch 1, Loss: 9.356452210340649e-06\n",
            "Epoch 1, Loss: 9.294387382396962e-06\n",
            "Epoch 1, Loss: 9.311936992162373e-06\n",
            "Epoch 1, Loss: 7.673458640056197e-06\n",
            "Epoch 1, Loss: 9.628288353269454e-06\n",
            "Epoch 1, Loss: 1.0333648788218852e-05\n",
            "Epoch 1, Loss: 8.18729222373804e-06\n",
            "Epoch 1, Loss: 1.0552016647125129e-05\n",
            "Epoch 1, Loss: 9.420110473001841e-06\n",
            "Epoch 1, Loss: 1.0154039046028629e-05\n",
            "Epoch 1, Loss: 9.372379281558096e-06\n",
            "Epoch 1, Loss: 8.205943231587298e-06\n",
            "Epoch 1, Loss: 8.45896101964172e-06\n",
            "Epoch 1, Loss: 1.0722411388996989e-05\n",
            "Epoch 1, Loss: 1.3798776308249217e-05\n",
            "Epoch 1, Loss: 8.768439329287503e-06\n",
            "Epoch 1, Loss: 7.732337508059572e-06\n",
            "Epoch 1, Loss: 8.217446520575322e-06\n",
            "Epoch 1, Loss: 8.963354048319161e-06\n",
            "Epoch 1, Loss: 8.882396286935546e-06\n",
            "Epoch 1, Loss: 8.843957402859814e-06\n",
            "Epoch 1, Loss: 9.05485012481222e-06\n",
            "Epoch 1, Loss: 1.0028586075350177e-05\n",
            "Epoch 1, Loss: 1.0229012332274579e-05\n",
            "Epoch 1, Loss: 7.823742635082453e-06\n",
            "Epoch 1, Loss: 8.391127266804688e-06\n",
            "Epoch 1, Loss: 7.225986337289214e-06\n",
            "Epoch 1, Loss: 8.704997526365332e-06\n",
            "Epoch 1, Loss: 1.0265169294143561e-05\n",
            "Epoch 1, Loss: 8.430912203039043e-06\n",
            "Epoch 1, Loss: 7.736499355814885e-06\n",
            "Epoch 1, Loss: 7.844984793337062e-06\n",
            "Epoch 1, Loss: 1.0645236216078047e-05\n",
            "Epoch 1, Loss: 9.701492672320455e-06\n",
            "Epoch 1, Loss: 9.230046089214738e-06\n",
            "Epoch 1, Loss: 1.0616029612720013e-05\n",
            "Epoch 1, Loss: 7.77079549152404e-06\n",
            "Epoch 1, Loss: 1.1879443263751455e-05\n",
            "Epoch 1, Loss: 1.0191931323788594e-05\n",
            "Epoch 1, Loss: 1.0197880328632891e-05\n",
            "Epoch 1, Loss: 1.2677308404818177e-05\n",
            "Epoch 1, Loss: 7.804100278008264e-06\n",
            "Epoch 1, Loss: 1.1503684618219268e-05\n",
            "Epoch 1, Loss: 7.5494585871638265e-06\n",
            "Epoch 1, Loss: 8.795655048743356e-06\n",
            "Epoch 1, Loss: 8.478265954181552e-06\n",
            "Epoch 1, Loss: 1.0494997695786878e-05\n",
            "Epoch 1, Loss: 7.908623956609517e-06\n",
            "Epoch 1, Loss: 8.780799362284597e-06\n",
            "Epoch 1, Loss: 1.2272605999896768e-05\n",
            "Epoch 1, Loss: 9.74110298557207e-06\n",
            "Epoch 1, Loss: 6.645344001299236e-06\n",
            "Epoch 1, Loss: 9.81213179329643e-06\n",
            "Epoch 1, Loss: 1.2425690329109784e-05\n",
            "Epoch 1, Loss: 8.433821676590014e-06\n",
            "Epoch 1, Loss: 8.444311788480263e-06\n",
            "Epoch 1, Loss: 9.325197424914222e-06\n",
            "Epoch 1, Loss: 1.073653493222082e-05\n",
            "Epoch 1, Loss: 8.351719770871568e-06\n",
            "Epoch 1, Loss: 9.476058949076105e-06\n",
            "Epoch 1, Loss: 7.370863841060782e-06\n",
            "Epoch 1, Loss: 1.1491186342027504e-05\n",
            "Epoch 1, Loss: 8.954534678196069e-06\n",
            "Epoch 1, Loss: 7.88498164183693e-06\n",
            "Epoch 1, Loss: 1.2006230463157408e-05\n",
            "Epoch 1, Loss: 8.877098480297718e-06\n",
            "Epoch 1, Loss: 8.355991667485796e-06\n",
            "Epoch 1, Loss: 7.246866516652517e-06\n",
            "Epoch 1, Loss: 7.655258741579019e-06\n",
            "Epoch 1, Loss: 1.183424683404155e-05\n",
            "Epoch 1, Loss: 8.065208021434955e-06\n",
            "Epoch 1, Loss: 1.1114491826447193e-05\n",
            "Epoch 1, Loss: 7.079572696966352e-06\n",
            "Epoch 1, Loss: 9.572455383022316e-06\n",
            "Epoch 1, Loss: 1.188109763461398e-05\n",
            "Epoch 1, Loss: 9.402671821590047e-06\n",
            "Epoch 1, Loss: 1.0609522178128827e-05\n",
            "Epoch 1, Loss: 8.637879545858596e-06\n",
            "Epoch 1, Loss: 7.914773959782906e-06\n",
            "Epoch 1, Loss: 9.036552910401952e-06\n",
            "Epoch 1, Loss: 8.375111974601168e-06\n",
            "Epoch 1, Loss: 9.336728908238001e-06\n",
            "Epoch 1, Loss: 8.468583473586477e-06\n",
            "Epoch 1, Loss: 9.515297278994694e-06\n",
            "Epoch 1, Loss: 9.362896889797412e-06\n",
            "Epoch 1, Loss: 8.87982332642423e-06\n",
            "Epoch 1, Loss: 9.320011486124713e-06\n",
            "Epoch 1, Loss: 9.218404557032045e-06\n",
            "Epoch 1, Loss: 9.408749974681996e-06\n",
            "Epoch 1, Loss: 8.223887562053278e-06\n",
            "Epoch 1, Loss: 9.950912499334663e-06\n",
            "Epoch 1, Loss: 9.451962796447333e-06\n",
            "Epoch 1, Loss: 9.871182555798441e-06\n",
            "Epoch 1, Loss: 8.53782330523245e-06\n",
            "Epoch 1, Loss: 8.798488124739379e-06\n",
            "Epoch 1, Loss: 8.303677532239817e-06\n",
            "Epoch 1, Loss: 7.890010238043033e-06\n",
            "Epoch 1, Loss: 6.9939605964464135e-06\n",
            "Epoch 1, Loss: 7.964194082887843e-06\n",
            "Epoch 1, Loss: 8.966117093223147e-06\n",
            "Epoch 1, Loss: 7.5335810834076256e-06\n",
            "Epoch 1, Loss: 8.437062206212431e-06\n",
            "Epoch 1, Loss: 7.421504051308148e-06\n",
            "Epoch 1, Loss: 7.823145097063389e-06\n",
            "Epoch 1, Loss: 1.2570737453643233e-05\n",
            "Epoch 1, Loss: 8.062545930442866e-06\n",
            "Epoch 1, Loss: 8.754209375183564e-06\n",
            "Epoch 1, Loss: 8.9405457401881e-06\n",
            "Epoch 1, Loss: 8.993454684969038e-06\n",
            "Epoch 1, Loss: 9.264532309316564e-06\n",
            "Epoch 1, Loss: 7.228342383314157e-06\n",
            "Epoch 1, Loss: 8.727748536330182e-06\n",
            "Epoch 1, Loss: 8.38340838527074e-06\n",
            "Epoch 1, Loss: 7.217058737296611e-06\n",
            "Epoch 1, Loss: 8.127320143103134e-06\n",
            "Epoch 1, Loss: 8.728996363061015e-06\n",
            "Epoch 1, Loss: 9.068868166650645e-06\n",
            "Epoch 1, Loss: 9.224867426382843e-06\n",
            "Epoch 1, Loss: 1.0886622476391494e-05\n",
            "Epoch 1, Loss: 9.929504813044332e-06\n",
            "Epoch 1, Loss: 8.041523869906086e-06\n",
            "Epoch 1, Loss: 8.871223144524265e-06\n",
            "Epoch 1, Loss: 8.308500582643319e-06\n",
            "Epoch 1, Loss: 1.1403828466427512e-05\n",
            "Epoch 1, Loss: 7.584522791148629e-06\n",
            "Epoch 1, Loss: 9.573146598995663e-06\n",
            "Epoch 1, Loss: 9.790534022613429e-06\n",
            "Epoch 1, Loss: 7.87256703915773e-06\n",
            "Epoch 1, Loss: 8.405084372498095e-06\n",
            "Epoch 1, Loss: 1.0520486284804065e-05\n",
            "Epoch 1, Loss: 8.177195013558958e-06\n",
            "Epoch 1, Loss: 9.406583558302373e-06\n",
            "Epoch 1, Loss: 7.668450962228235e-06\n",
            "Epoch 1, Loss: 8.823284588288516e-06\n",
            "Epoch 1, Loss: 9.845837666944135e-06\n",
            "Epoch 1, Loss: 8.17078398540616e-06\n",
            "Epoch 1, Loss: 8.099168553599156e-06\n",
            "Epoch 1, Loss: 7.48631146052503e-06\n",
            "Epoch 1, Loss: 9.29308862396283e-06\n",
            "Epoch 1, Loss: 7.685098353249487e-06\n",
            "Epoch 1, Loss: 9.43639679462649e-06\n",
            "Epoch 1, Loss: 9.894140930555295e-06\n",
            "Epoch 1, Loss: 9.380467417940963e-06\n",
            "Epoch 1, Loss: 8.503425306116696e-06\n",
            "Epoch 1, Loss: 8.896371582522988e-06\n",
            "Epoch 1, Loss: 1.1087801794928964e-05\n",
            "Epoch 1, Loss: 8.400893420912325e-06\n",
            "Epoch 1, Loss: 7.600145181640983e-06\n",
            "Epoch 1, Loss: 7.545881999249104e-06\n",
            "Epoch 1, Loss: 1.2730272828775924e-05\n",
            "Epoch 1, Loss: 8.187053936126176e-06\n",
            "Epoch 1, Loss: 6.914850928296801e-06\n",
            "Epoch 1, Loss: 1.440278265363304e-05\n",
            "Epoch 1, Loss: 7.641261618118733e-06\n",
            "Epoch 1, Loss: 9.357633643958252e-06\n",
            "Epoch 1, Loss: 1.0329312317480799e-05\n",
            "Epoch 1, Loss: 1.2175170923001133e-05\n",
            "Epoch 1, Loss: 9.1461524789338e-06\n",
            "Epoch 1, Loss: 8.192761015379801e-06\n",
            "Epoch 1, Loss: 7.906745850050356e-06\n",
            "Epoch 1, Loss: 1.0157524229725823e-05\n",
            "Epoch 1, Loss: 9.754700840858277e-06\n",
            "Epoch 1, Loss: 8.321246241393965e-06\n",
            "Epoch 1, Loss: 8.254774002125487e-06\n",
            "Epoch 1, Loss: 7.249293503264198e-06\n",
            "Epoch 1, Loss: 8.049737516557798e-06\n",
            "Epoch 1, Loss: 9.89816544461064e-06\n",
            "Epoch 1, Loss: 8.292182428704109e-06\n",
            "Epoch 1, Loss: 8.435115887550637e-06\n",
            "Epoch 1, Loss: 8.280931979243178e-06\n",
            "Epoch 1, Loss: 9.409509402757976e-06\n",
            "Epoch 1, Loss: 1.0985279914166313e-05\n",
            "Epoch 1, Loss: 1.1940654076170176e-05\n",
            "Epoch 1, Loss: 8.770375643507577e-06\n",
            "Epoch 1, Loss: 7.656785783183295e-06\n",
            "Epoch 1, Loss: 9.640758435125463e-06\n",
            "Epoch 1, Loss: 9.131575097853784e-06\n",
            "Epoch 1, Loss: 8.798017915978562e-06\n",
            "Epoch 1, Loss: 8.516544767189771e-06\n",
            "Epoch 1, Loss: 9.14617339731194e-06\n",
            "Epoch 1, Loss: 7.442751211783616e-06\n",
            "Epoch 1, Loss: 7.949840437504463e-06\n",
            "Epoch 1, Loss: 9.421486538485624e-06\n",
            "Epoch 1, Loss: 8.349841664312407e-06\n",
            "Epoch 1, Loss: 6.871062396385241e-06\n",
            "Epoch 1, Loss: 8.890399840311147e-06\n",
            "Epoch 1, Loss: 8.104263542918488e-06\n",
            "Epoch 1, Loss: 8.903196430765092e-06\n",
            "Epoch 1, Loss: 7.67767232900951e-06\n",
            "Epoch 1, Loss: 7.817931873432826e-06\n",
            "Epoch 1, Loss: 9.941103598976042e-06\n",
            "Epoch 1, Loss: 7.678604561078828e-06\n",
            "Epoch 1, Loss: 7.88600209489232e-06\n",
            "Epoch 1, Loss: 9.70363453234313e-06\n",
            "Epoch 1, Loss: 6.7996224970556796e-06\n",
            "Epoch 1, Loss: 9.024808605317958e-06\n",
            "Epoch 1, Loss: 7.816291144990828e-06\n",
            "Epoch 1, Loss: 8.685645298101008e-06\n",
            "Epoch 1, Loss: 9.56114126893226e-06\n",
            "Epoch 1, Loss: 7.046499831631081e-06\n",
            "Epoch 1, Loss: 1.177343619929161e-05\n",
            "Epoch 1, Loss: 8.907113624445628e-06\n",
            "Epoch 1, Loss: 9.974832209991291e-06\n",
            "Epoch 1, Loss: 8.877200343704317e-06\n",
            "Epoch 1, Loss: 9.663651326263789e-06\n",
            "Epoch 1, Loss: 8.536008863302413e-06\n",
            "Epoch 1, Loss: 8.482106750307139e-06\n",
            "Epoch 1, Loss: 8.687710760568734e-06\n",
            "Epoch 1, Loss: 1.2156202501500957e-05\n",
            "Epoch 1, Loss: 7.787192771502305e-06\n",
            "Epoch 1, Loss: 9.067217433766928e-06\n",
            "Epoch 1, Loss: 9.156695341516752e-06\n",
            "Epoch 1, Loss: 8.721290214452893e-06\n",
            "Epoch 1, Loss: 9.628213774703909e-06\n",
            "Epoch 1, Loss: 9.062392564374022e-06\n",
            "Epoch 1, Loss: 6.630940333707258e-06\n",
            "Epoch 1, Loss: 7.679335794819053e-06\n",
            "Epoch 1, Loss: 7.233583346533123e-06\n",
            "Epoch 1, Loss: 7.759696927678306e-06\n",
            "Epoch 1, Loss: 8.623967005405575e-06\n",
            "Epoch 1, Loss: 8.21593221189687e-06\n",
            "Epoch 1, Loss: 8.500724106852431e-06\n",
            "Epoch 1, Loss: 1.0411134098831099e-05\n",
            "Epoch 1, Loss: 7.689416634093504e-06\n",
            "Epoch 1, Loss: 8.237133442889899e-06\n",
            "Epoch 1, Loss: 8.543614057998639e-06\n",
            "Epoch 1, Loss: 9.22288563742768e-06\n",
            "Epoch 1, Loss: 8.926996997615788e-06\n",
            "Epoch 1, Loss: 9.973153282771818e-06\n",
            "Epoch 1, Loss: 9.274918738810811e-06\n",
            "Epoch 1, Loss: 1.0343711437599268e-05\n",
            "Epoch 1, Loss: 7.647035090485588e-06\n",
            "Epoch 1, Loss: 7.941291187307797e-06\n",
            "Epoch 1, Loss: 8.626348062534817e-06\n",
            "Epoch 1, Loss: 8.182747478713281e-06\n",
            "Epoch 1, Loss: 8.165090548573062e-06\n",
            "Epoch 1, Loss: 9.994057108997367e-06\n",
            "Epoch 1, Loss: 1.0171346730203368e-05\n",
            "Epoch 1, Loss: 8.199452167900745e-06\n",
            "Epoch 1, Loss: 9.605828381609172e-06\n",
            "Epoch 1, Loss: 7.16985277904314e-06\n",
            "Epoch 1, Loss: 1.0384785127826035e-05\n",
            "Epoch 1, Loss: 1.0262951036565937e-05\n",
            "Epoch 1, Loss: 7.037648629193427e-06\n",
            "Epoch 1, Loss: 1.0851371371245477e-05\n",
            "Epoch 1, Loss: 7.097236448316835e-06\n",
            "Epoch 1, Loss: 7.67866185924504e-06\n",
            "Epoch 1, Loss: 8.281596819870174e-06\n",
            "Epoch 1, Loss: 9.039084034156986e-06\n",
            "Epoch 1, Loss: 8.363356755580753e-06\n",
            "Epoch 1, Loss: 9.310107998317108e-06\n",
            "Epoch 1, Loss: 1.0090073374158237e-05\n",
            "Epoch 1, Loss: 7.895093403931241e-06\n",
            "Epoch 1, Loss: 7.051562079141149e-06\n",
            "Epoch 1, Loss: 1.2470874025893863e-05\n",
            "Epoch 1, Loss: 8.019175766094122e-06\n",
            "Epoch 1, Loss: 8.192494533432182e-06\n",
            "Epoch 1, Loss: 8.44634178065462e-06\n",
            "Epoch 1, Loss: 9.948009392246604e-06\n",
            "Epoch 1, Loss: 6.953163847356336e-06\n",
            "Epoch 1, Loss: 7.674540029256605e-06\n",
            "Epoch 1, Loss: 1.1581355465750676e-05\n",
            "Epoch 1, Loss: 9.646509170124773e-06\n",
            "Epoch 1, Loss: 7.952922715048771e-06\n",
            "Epoch 1, Loss: 9.42288988881046e-06\n",
            "Epoch 1, Loss: 7.417920642183162e-06\n",
            "Epoch 1, Loss: 9.958824193745386e-06\n",
            "Epoch 1, Loss: 8.314939805131871e-06\n",
            "Epoch 1, Loss: 8.092983080132399e-06\n",
            "Epoch 1, Loss: 7.200777417892823e-06\n",
            "Epoch 1, Loss: 7.4754161687451415e-06\n",
            "Epoch 1, Loss: 8.45608337840531e-06\n",
            "Epoch 1, Loss: 7.984259354998358e-06\n",
            "Epoch 1, Loss: 1.0742556696641259e-05\n",
            "Epoch 1, Loss: 1.0454858056618832e-05\n",
            "Epoch 1, Loss: 9.784720532479696e-06\n",
            "Epoch 1, Loss: 9.829439477471169e-06\n",
            "Epoch 1, Loss: 9.196559403790161e-06\n",
            "Epoch 1, Loss: 7.965953955135774e-06\n",
            "Epoch 1, Loss: 7.387213372567203e-06\n",
            "Epoch 1, Loss: 6.612121069338173e-06\n",
            "Epoch 1, Loss: 6.66633741275291e-06\n",
            "Epoch 1, Loss: 7.90642934589414e-06\n",
            "Epoch 1, Loss: 8.170227374648675e-06\n",
            "Epoch 1, Loss: 8.399211765208747e-06\n",
            "Epoch 1, Loss: 8.564179552195128e-06\n",
            "Epoch 1, Loss: 1.030165276461048e-05\n",
            "Epoch 1, Loss: 7.018616543064127e-06\n",
            "Epoch 1, Loss: 1.0315264262317214e-05\n",
            "Epoch 1, Loss: 7.557233857369283e-06\n",
            "Epoch 1, Loss: 6.953241154405987e-06\n",
            "Epoch 1, Loss: 8.511720807291567e-06\n",
            "Epoch 1, Loss: 8.27446456241887e-06\n",
            "Epoch 1, Loss: 7.4065605986106675e-06\n",
            "Epoch 1, Loss: 8.21774847281631e-06\n",
            "Epoch 1, Loss: 6.317498900898499e-06\n",
            "Epoch 1, Loss: 7.5199554885330144e-06\n",
            "Epoch 1, Loss: 8.1845528256963e-06\n",
            "Epoch 1, Loss: 9.197953659167979e-06\n",
            "Epoch 1, Loss: 7.766600901959464e-06\n",
            "Epoch 1, Loss: 1.1501027984195389e-05\n",
            "Epoch 1, Loss: 8.490565051033627e-06\n",
            "Epoch 1, Loss: 1.3325940926733892e-05\n",
            "Epoch 1, Loss: 8.829005309962668e-06\n",
            "Epoch 1, Loss: 9.015841897053178e-06\n",
            "Epoch 1, Loss: 7.83466748544015e-06\n",
            "Epoch 1, Loss: 7.210778676380869e-06\n",
            "Epoch 1, Loss: 7.353158707701368e-06\n",
            "Epoch 1, Loss: 7.85074462328339e-06\n",
            "Epoch 1, Loss: 8.611053090135101e-06\n",
            "Epoch 1, Loss: 8.438721124548465e-06\n",
            "Epoch 1, Loss: 8.142191290971823e-06\n",
            "Epoch 1, Loss: 7.516061486967374e-06\n",
            "Epoch 1, Loss: 7.67906203691382e-06\n",
            "Epoch 1, Loss: 1.0262843716191128e-05\n",
            "Epoch 1, Loss: 8.372393494937569e-06\n",
            "Epoch 1, Loss: 1.1148646080982871e-05\n",
            "Epoch 1, Loss: 7.6763335528085e-06\n",
            "Epoch 1, Loss: 8.329781849170104e-06\n",
            "Epoch 1, Loss: 1.1964244549744762e-05\n",
            "Epoch 1, Loss: 7.158417247410398e-06\n",
            "Epoch 1, Loss: 1.046384477376705e-05\n",
            "Epoch 1, Loss: 8.546361641492695e-06\n",
            "Epoch 1, Loss: 7.560371159343049e-06\n",
            "Epoch 1, Loss: 6.310806384135503e-06\n",
            "Epoch 1, Loss: 8.02611521066865e-06\n",
            "Epoch 1, Loss: 9.502683496975806e-06\n",
            "Epoch 1, Loss: 8.182719284377526e-06\n",
            "Epoch 1, Loss: 8.736524250707589e-06\n",
            "Epoch 1, Loss: 7.789684786985163e-06\n",
            "Epoch 1, Loss: 1.1349428859830368e-05\n",
            "Epoch 1, Loss: 9.58877080847742e-06\n",
            "Epoch 1, Loss: 8.29970849736128e-06\n",
            "Epoch 1, Loss: 6.5889712459465954e-06\n",
            "Epoch 1, Loss: 7.80186655902071e-06\n",
            "Epoch 1, Loss: 1.1071341759816278e-05\n",
            "Epoch 1, Loss: 7.770515367155895e-06\n",
            "Epoch 1, Loss: 7.547053428424988e-06\n",
            "Epoch 1, Loss: 6.97786117598298e-06\n",
            "Epoch 1, Loss: 6.980633315833984e-06\n",
            "Epoch 1, Loss: 7.510320756409783e-06\n",
            "Epoch 1, Loss: 7.687380275456235e-06\n",
            "Epoch 1, Loss: 8.931761840358377e-06\n",
            "Epoch 1, Loss: 1.4659414773632307e-05\n",
            "Epoch 1, Loss: 7.482178261852823e-06\n",
            "Epoch 1, Loss: 7.491166797990445e-06\n",
            "Epoch 1, Loss: 9.01117437024368e-06\n",
            "Epoch 1, Loss: 7.438196917064488e-06\n",
            "Epoch 1, Loss: 8.19601245893864e-06\n",
            "Epoch 1, Loss: 6.533662599395029e-06\n",
            "Epoch 1, Loss: 7.792819815222174e-06\n",
            "Epoch 1, Loss: 6.871963705634698e-06\n",
            "Epoch 1, Loss: 7.956144145282451e-06\n",
            "Epoch 1, Loss: 9.179864719044417e-06\n",
            "Epoch 1, Loss: 8.701073966221884e-06\n",
            "Epoch 1, Loss: 7.450339580827858e-06\n",
            "Epoch 1, Loss: 8.686820365255699e-06\n",
            "Epoch 1, Loss: 8.169108696165495e-06\n",
            "Epoch 1, Loss: 7.824762178643141e-06\n",
            "Epoch 1, Loss: 9.116314686252736e-06\n",
            "Epoch 1, Loss: 6.08242680755211e-06\n",
            "Epoch 1, Loss: 6.964565272937762e-06\n",
            "Epoch 1, Loss: 6.890240911161527e-06\n",
            "Epoch 1, Loss: 9.681846677267458e-06\n",
            "Epoch 1, Loss: 9.264900654670782e-06\n",
            "Epoch 1, Loss: 6.7890368882217444e-06\n",
            "Epoch 1, Loss: 7.446186373272212e-06\n",
            "Epoch 1, Loss: 1.5335028365370817e-05\n",
            "Epoch 1, Loss: 9.43971645028796e-06\n",
            "Epoch 1, Loss: 7.121808266674634e-06\n",
            "Epoch 1, Loss: 9.500611668045167e-06\n",
            "Epoch 1, Loss: 7.2596817517478485e-06\n",
            "Epoch 1, Loss: 1.0717814802774228e-05\n",
            "Epoch 1, Loss: 8.334301128343213e-06\n",
            "Epoch 1, Loss: 7.40752102501574e-06\n",
            "Epoch 1, Loss: 6.809412298025563e-06\n",
            "Epoch 1, Loss: 9.170230441668537e-06\n",
            "Epoch 1, Loss: 7.415941581712104e-06\n",
            "Epoch 1, Loss: 9.02514329936821e-06\n",
            "Epoch 1, Loss: 8.79827348398976e-06\n",
            "Epoch 1, Loss: 7.968769750732463e-06\n",
            "Epoch 1, Loss: 7.057240054564318e-06\n",
            "Epoch 1, Loss: 8.741937563172542e-06\n",
            "Epoch 1, Loss: 1.1528760296641849e-05\n",
            "Epoch 1, Loss: 6.554089395649498e-06\n",
            "Epoch 1, Loss: 7.662579264433589e-06\n",
            "Epoch 1, Loss: 1.0671280506358016e-05\n",
            "Epoch 1, Loss: 7.72365638113115e-06\n",
            "Epoch 1, Loss: 8.752394933253527e-06\n",
            "Epoch 1, Loss: 8.201423952414189e-06\n",
            "Epoch 1, Loss: 9.340656106360257e-06\n",
            "Epoch 1, Loss: 8.821931260172278e-06\n",
            "Epoch 1, Loss: 6.301866505964426e-06\n",
            "Epoch 1, Loss: 8.713113857083954e-06\n",
            "Epoch 1, Loss: 9.265061635232996e-06\n",
            "Epoch 1, Loss: 7.193781129899435e-06\n",
            "Epoch 1, Loss: 9.342056728200987e-06\n",
            "Epoch 1, Loss: 8.758366675465368e-06\n",
            "Epoch 1, Loss: 7.654371074750088e-06\n",
            "Epoch 1, Loss: 6.8505059971357696e-06\n",
            "Epoch 1, Loss: 8.539329428458586e-06\n",
            "Epoch 1, Loss: 7.920945790829137e-06\n",
            "Epoch 1, Loss: 9.554729331284761e-06\n",
            "Epoch 1, Loss: 6.920836312929168e-06\n",
            "Epoch 1, Loss: 9.150048754236195e-06\n",
            "Epoch 1, Loss: 6.731052053510211e-06\n",
            "Epoch 1, Loss: 9.699596375867259e-06\n",
            "Epoch 1, Loss: 7.86549844633555e-06\n",
            "Epoch 1, Loss: 1.0574180123512633e-05\n",
            "Epoch 1, Loss: 6.742262939951615e-06\n",
            "Epoch 1, Loss: 7.377473139058566e-06\n",
            "Epoch 1, Loss: 8.91579929884756e-06\n",
            "Epoch 1, Loss: 8.450136192550417e-06\n",
            "Epoch 1, Loss: 7.483256467821775e-06\n",
            "Epoch 1, Loss: 9.958457667380571e-06\n",
            "Epoch 1, Loss: 8.173044989234768e-06\n",
            "Epoch 1, Loss: 1.073121984518366e-05\n",
            "Epoch 1, Loss: 6.5879053181561176e-06\n",
            "Epoch 1, Loss: 9.244286047760397e-06\n",
            "Epoch 1, Loss: 7.065913450787775e-06\n",
            "Epoch 1, Loss: 8.013505066628568e-06\n",
            "Epoch 1, Loss: 7.124669537006412e-06\n",
            "Epoch 1, Loss: 1.593227352714166e-05\n",
            "Epoch 1, Loss: 9.510768904874567e-06\n",
            "Epoch 1, Loss: 6.93222045811126e-06\n",
            "Epoch 1, Loss: 6.733288955729222e-06\n",
            "Epoch 1, Loss: 7.80711525294464e-06\n",
            "Epoch 1, Loss: 7.896454917499796e-06\n",
            "Epoch 1, Loss: 6.202604254212929e-06\n",
            "Epoch 1, Loss: 5.835783667862415e-06\n",
            "Epoch 1, Loss: 7.504786481149495e-06\n",
            "Epoch 1, Loss: 9.399475857208017e-06\n",
            "Epoch 1, Loss: 9.751765901455656e-06\n",
            "Epoch 1, Loss: 6.68208622300881e-06\n",
            "Epoch 1, Loss: 7.4004688030981924e-06\n",
            "Epoch 1, Loss: 7.577304586448008e-06\n",
            "Epoch 1, Loss: 7.1668782766209915e-06\n",
            "Epoch 1, Loss: 6.70427834847942e-06\n",
            "Epoch 1, Loss: 9.903600584948435e-06\n",
            "Epoch 1, Loss: 8.888076081348117e-06\n",
            "Epoch 1, Loss: 6.353120625135489e-06\n",
            "Epoch 1, Loss: 7.320360964513384e-06\n",
            "Epoch 1, Loss: 7.37925529392669e-06\n",
            "Epoch 1, Loss: 7.190522865130333e-06\n",
            "Epoch 1, Loss: 8.093798896879889e-06\n",
            "Epoch 1, Loss: 8.277223059849348e-06\n",
            "Epoch 1, Loss: 6.6867210080090445e-06\n",
            "Epoch 1, Loss: 7.137273769330932e-06\n",
            "Epoch 1, Loss: 8.576802429161035e-06\n",
            "Epoch 1, Loss: 7.127786830096738e-06\n",
            "Epoch 1, Loss: 9.513265467830934e-06\n",
            "Epoch 1, Loss: 6.889201358717401e-06\n",
            "Epoch 1, Loss: 7.094707143551204e-06\n",
            "Epoch 1, Loss: 1.0767836101877037e-05\n",
            "Epoch 1, Loss: 6.904553629283328e-06\n",
            "Epoch 1, Loss: 7.849484973121434e-06\n",
            "Epoch 1, Loss: 8.709917892701924e-06\n",
            "Epoch 1, Loss: 8.982760846265592e-06\n",
            "Epoch 1, Loss: 9.933913133863825e-06\n",
            "Epoch 1, Loss: 7.882911631895695e-06\n",
            "Epoch 1, Loss: 1.12157595140161e-05\n",
            "Epoch 1, Loss: 6.660674898739671e-06\n",
            "Epoch 1, Loss: 6.680822934868047e-06\n",
            "Epoch 1, Loss: 9.100960596697405e-06\n",
            "Epoch 1, Loss: 9.311648682341911e-06\n",
            "Epoch 1, Loss: 6.4502346504013985e-06\n",
            "Epoch 1, Loss: 7.993692634045146e-06\n",
            "Epoch 1, Loss: 8.61928583617555e-06\n",
            "Epoch 1, Loss: 6.673089956166223e-06\n",
            "Epoch 1, Loss: 1.0875793122977484e-05\n",
            "Epoch 1, Loss: 8.881476787792053e-06\n",
            "Epoch 1, Loss: 9.026616680785082e-06\n",
            "Epoch 1, Loss: 7.462988833140116e-06\n",
            "Epoch 1, Loss: 6.6195234467159025e-06\n",
            "Epoch 1, Loss: 7.73509600549005e-06\n",
            "Epoch 1, Loss: 6.667777597613167e-06\n",
            "Epoch 1, Loss: 8.421475286013447e-06\n",
            "Epoch 1, Loss: 1.020396848616656e-05\n",
            "Epoch 1, Loss: 7.024992100923555e-06\n",
            "Epoch 1, Loss: 6.226163350220304e-06\n",
            "Epoch 1, Loss: 1.0478142939973623e-05\n",
            "Epoch 1, Loss: 7.530176389991539e-06\n",
            "Epoch 1, Loss: 8.008392796909902e-06\n",
            "Epoch 1, Loss: 6.363085503835464e-06\n",
            "Epoch 1, Loss: 9.02245028555626e-06\n",
            "Epoch 1, Loss: 6.7229566411697306e-06\n",
            "Epoch 1, Loss: 6.440443485189462e-06\n",
            "Epoch 1, Loss: 7.408115834550699e-06\n",
            "Epoch 1, Loss: 6.6738880377670284e-06\n",
            "Epoch 1, Loss: 8.569281817472074e-06\n",
            "Epoch 1, Loss: 7.197862487373641e-06\n",
            "Epoch 1, Loss: 7.77957211539615e-06\n",
            "Epoch 1, Loss: 9.144687282969244e-06\n",
            "Epoch 1, Loss: 9.028579370351508e-06\n",
            "Epoch 1, Loss: 9.116751243709587e-06\n",
            "Epoch 1, Loss: 7.056224603729788e-06\n",
            "Epoch 1, Loss: 6.693342129437951e-06\n",
            "Epoch 1, Loss: 8.322401299665216e-06\n",
            "Epoch 1, Loss: 6.862989721412305e-06\n",
            "Epoch 1, Loss: 7.445815299433889e-06\n",
            "Epoch 1, Loss: 8.398691534239333e-06\n",
            "Epoch 1, Loss: 8.051692020671908e-06\n",
            "Epoch 1, Loss: 8.540451744920574e-06\n",
            "Epoch 1, Loss: 6.578690317837754e-06\n",
            "Epoch 1, Loss: 6.907775969011709e-06\n",
            "Epoch 1, Loss: 8.232867912738584e-06\n",
            "Epoch 1, Loss: 7.873959475546144e-06\n",
            "Epoch 1, Loss: 8.542707291780971e-06\n",
            "Epoch 1, Loss: 7.34219202058739e-06\n",
            "Epoch 1, Loss: 6.7005148594034836e-06\n",
            "Epoch 1, Loss: 8.033450285438448e-06\n",
            "Epoch 1, Loss: 7.327606454055058e-06\n",
            "Epoch 1, Loss: 7.766071576043032e-06\n",
            "Epoch 1, Loss: 8.528716534783598e-06\n",
            "Epoch 1, Loss: 7.739114153082483e-06\n",
            "Epoch 1, Loss: 1.0274286069034133e-05\n",
            "Epoch 1, Loss: 1.0722617844294291e-05\n",
            "Epoch 1, Loss: 6.778317583666649e-06\n",
            "Epoch 1, Loss: 7.26663847672171e-06\n",
            "Epoch 1, Loss: 8.261114999186248e-06\n",
            "Epoch 1, Loss: 7.393532996502472e-06\n",
            "Epoch 1, Loss: 9.369115105073433e-06\n",
            "Epoch 1, Loss: 8.129271918733139e-06\n",
            "Epoch 1, Loss: 7.238774742290843e-06\n",
            "Epoch 1, Loss: 8.402781531913206e-06\n",
            "Epoch 1, Loss: 7.044314770610072e-06\n",
            "Epoch 1, Loss: 6.529254733322887e-06\n",
            "Epoch 1, Loss: 7.428263415931724e-06\n",
            "Epoch 1, Loss: 8.012283615244087e-06\n",
            "Epoch 1, Loss: 8.970450835477095e-06\n",
            "Epoch 1, Loss: 7.0830869844940025e-06\n",
            "Epoch 1, Loss: 6.8955823735450394e-06\n",
            "Epoch 1, Loss: 7.3086785050691105e-06\n",
            "Epoch 1, Loss: 6.5733529481804e-06\n",
            "Epoch 1, Loss: 7.959630238474347e-06\n",
            "Epoch 1, Loss: 6.349154773488408e-06\n",
            "Epoch 1, Loss: 8.07041760708671e-06\n",
            "Epoch 1, Loss: 7.624435511388583e-06\n",
            "Epoch 1, Loss: 8.212960892706178e-06\n",
            "Epoch 1, Loss: 6.537735316669568e-06\n",
            "Epoch 1, Loss: 8.00121961219702e-06\n",
            "Epoch 1, Loss: 1.0403443411632907e-05\n",
            "Epoch 1, Loss: 7.8145840234356e-06\n",
            "Epoch 1, Loss: 8.229062586906366e-06\n",
            "Epoch 1, Loss: 1.1242376785958186e-05\n",
            "Epoch 1, Loss: 8.419420737482142e-06\n",
            "Epoch 1, Loss: 7.1906342782313e-06\n",
            "Epoch 1, Loss: 7.419706435030093e-06\n",
            "Epoch 1, Loss: 6.776895133953076e-06\n",
            "Epoch 1, Loss: 8.35741502669407e-06\n",
            "Epoch 1, Loss: 7.793168151692953e-06\n",
            "Epoch 1, Loss: 7.71416580391815e-06\n",
            "Epoch 1, Loss: 6.353111530188471e-06\n",
            "Epoch 1, Loss: 9.28870213101618e-06\n",
            "Epoch 1, Loss: 9.096044777834322e-06\n",
            "Epoch 1, Loss: 8.637629434815608e-06\n",
            "Epoch 1, Loss: 7.884767001087312e-06\n",
            "Epoch 1, Loss: 6.268679499044083e-06\n",
            "Epoch 1, Loss: 8.540546332369559e-06\n",
            "Epoch 1, Loss: 8.617482308181934e-06\n",
            "Epoch 1, Loss: 6.365680746966973e-06\n",
            "Epoch 1, Loss: 6.665710316156037e-06\n",
            "Epoch 1, Loss: 7.658470167370979e-06\n",
            "Epoch 1, Loss: 6.630144525843207e-06\n",
            "Epoch 1, Loss: 1.0378726074122824e-05\n",
            "Epoch 1, Loss: 6.5160779740836006e-06\n",
            "Epoch 1, Loss: 8.690886716067325e-06\n",
            "Epoch 1, Loss: 6.6468878685554955e-06\n",
            "Epoch 1, Loss: 9.455779945710674e-06\n",
            "Epoch 1, Loss: 9.956792382581625e-06\n",
            "Epoch 1, Loss: 8.044179594435263e-06\n",
            "Epoch 1, Loss: 9.109939128393307e-06\n",
            "Epoch 1, Loss: 7.076268502714811e-06\n",
            "Epoch 1, Loss: 8.71215797815239e-06\n",
            "Epoch 1, Loss: 8.69294581207214e-06\n",
            "Epoch 1, Loss: 8.001385140232742e-06\n",
            "Epoch 1, Loss: 7.72816019889433e-06\n",
            "Epoch 1, Loss: 7.27074757378432e-06\n",
            "Epoch 1, Loss: 7.01705357641913e-06\n",
            "Epoch 1, Loss: 7.479952273570234e-06\n",
            "Epoch 1, Loss: 6.760433279850986e-06\n",
            "Epoch 1, Loss: 6.927289177838247e-06\n",
            "Epoch 1, Loss: 7.841386832296848e-06\n",
            "Epoch 1, Loss: 8.670139322930481e-06\n",
            "Epoch 1, Loss: 8.527769750799052e-06\n",
            "Epoch 1, Loss: 7.660756637051236e-06\n",
            "Epoch 1, Loss: 6.882331035740208e-06\n",
            "Epoch 1, Loss: 6.793205557187321e-06\n",
            "Epoch 1, Loss: 6.570332971023163e-06\n",
            "Epoch 1, Loss: 5.964930096524768e-06\n",
            "Epoch 1, Loss: 1.0274644409946632e-05\n",
            "Epoch 1, Loss: 8.496061127516441e-06\n",
            "Epoch 1, Loss: 7.586212632304523e-06\n",
            "Epoch 1, Loss: 7.344071491388604e-06\n",
            "Epoch 1, Loss: 7.395430657197721e-06\n",
            "Epoch 1, Loss: 8.959155820775777e-06\n",
            "Epoch 1, Loss: 7.114627351256786e-06\n",
            "Epoch 1, Loss: 9.705675438453909e-06\n",
            "Epoch 1, Loss: 6.95621793056489e-06\n",
            "Epoch 1, Loss: 6.8914564508304466e-06\n",
            "Epoch 1, Loss: 8.265629730885848e-06\n",
            "Epoch 1, Loss: 8.756494025874417e-06\n",
            "Epoch 1, Loss: 1.330897521256702e-05\n",
            "Epoch 1, Loss: 7.0427095124614425e-06\n",
            "Epoch 1, Loss: 9.276423952542245e-06\n",
            "Epoch 1, Loss: 7.479830856027547e-06\n",
            "Epoch 1, Loss: 8.254118256445508e-06\n",
            "Epoch 1, Loss: 7.65336699259933e-06\n",
            "Epoch 1, Loss: 5.787353074993007e-06\n",
            "Epoch 1, Loss: 8.405357220908627e-06\n",
            "Epoch 1, Loss: 7.532446943514515e-06\n",
            "Epoch 1, Loss: 7.548764187959023e-06\n",
            "Epoch 1, Loss: 7.535526037827367e-06\n",
            "Epoch 1, Loss: 7.097386969689978e-06\n",
            "Epoch 1, Loss: 8.04079172667116e-06\n",
            "Epoch 1, Loss: 9.429982128494885e-06\n",
            "Epoch 1, Loss: 9.74147224042099e-06\n",
            "Epoch 1, Loss: 1.0368517905590124e-05\n",
            "Epoch 1, Loss: 6.666459285042947e-06\n",
            "Epoch 1, Loss: 8.417009667027742e-06\n",
            "Epoch 1, Loss: 8.78103674040176e-06\n",
            "Epoch 1, Loss: 7.233201358758379e-06\n",
            "Epoch 1, Loss: 7.680677299504168e-06\n",
            "Epoch 1, Loss: 7.156746505643241e-06\n",
            "Epoch 1, Loss: 5.37446430826094e-06\n",
            "Epoch 1, Loss: 8.149027053150348e-06\n",
            "Epoch 1, Loss: 8.019563210837077e-06\n",
            "Epoch 1, Loss: 7.4403337748663034e-06\n",
            "Epoch 1, Loss: 9.6083049356821e-06\n",
            "Epoch 1, Loss: 7.632248525624163e-06\n",
            "Epoch 1, Loss: 8.086078196356539e-06\n",
            "Epoch 1, Loss: 6.818476776970783e-06\n",
            "Epoch 1, Loss: 6.779897375963628e-06\n",
            "Epoch 1, Loss: 7.717928383499384e-06\n",
            "Epoch 1, Loss: 6.659097380179446e-06\n",
            "Epoch 1, Loss: 1.0095753168570809e-05\n",
            "Epoch 1, Loss: 9.003516424854752e-06\n",
            "Epoch 1, Loss: 7.288867436727742e-06\n",
            "Epoch 1, Loss: 7.526301942561986e-06\n",
            "Epoch 1, Loss: 7.534099040640285e-06\n",
            "Epoch 1, Loss: 6.713574748573592e-06\n",
            "Epoch 1, Loss: 7.007060048636049e-06\n",
            "Epoch 1, Loss: 1.0185653081862256e-05\n",
            "Epoch 1, Loss: 8.07152537163347e-06\n",
            "Epoch 1, Loss: 8.103898835543077e-06\n",
            "Epoch 1, Loss: 7.304311566258548e-06\n",
            "Epoch 1, Loss: 8.28456541057676e-06\n",
            "Epoch 1, Loss: 7.66070206736913e-06\n",
            "Epoch 1, Loss: 7.546457709395327e-06\n",
            "Epoch 1, Loss: 8.553026418667287e-06\n",
            "Epoch 1, Loss: 6.664028205705108e-06\n",
            "Epoch 1, Loss: 6.801287781854626e-06\n",
            "Epoch 1, Loss: 7.101018582034158e-06\n",
            "Epoch 1, Loss: 7.231948075059336e-06\n",
            "Epoch 1, Loss: 7.615349204570521e-06\n",
            "Epoch 1, Loss: 7.963411917444319e-06\n",
            "Epoch 1, Loss: 5.844687620992772e-06\n",
            "Epoch 1, Loss: 8.454680937575176e-06\n",
            "Epoch 1, Loss: 7.2387779255222995e-06\n",
            "Epoch 1, Loss: 1.2273303582333028e-05\n",
            "Epoch 1, Loss: 5.786811925645452e-06\n",
            "Epoch 1, Loss: 5.52509345652652e-06\n",
            "Epoch 1, Loss: 6.427056632674066e-06\n",
            "Epoch 1, Loss: 5.6898288676165976e-06\n",
            "Epoch 1, Loss: 6.942245363461552e-06\n",
            "Epoch 1, Loss: 6.81468418406439e-06\n",
            "Epoch 1, Loss: 8.35200808069203e-06\n",
            "Epoch 1, Loss: 6.8489644036162645e-06\n",
            "Epoch 1, Loss: 7.244366315717343e-06\n",
            "Epoch 1, Loss: 8.435339623247273e-06\n",
            "Epoch 1, Loss: 6.2422786868410185e-06\n",
            "Epoch 1, Loss: 7.301572622964159e-06\n",
            "Epoch 1, Loss: 6.4196419771178626e-06\n",
            "Epoch 1, Loss: 6.174346253828844e-06\n",
            "Epoch 1, Loss: 9.686405064712744e-06\n",
            "Epoch 1, Loss: 6.493679393315688e-06\n",
            "Epoch 1, Loss: 6.946470421098638e-06\n",
            "Epoch 1, Loss: 8.563812116335612e-06\n",
            "Epoch 1, Loss: 7.776050551910885e-06\n",
            "Epoch 1, Loss: 7.601649940625066e-06\n",
            "Epoch 1, Loss: 6.01243937126128e-06\n",
            "Epoch 1, Loss: 9.091930223803502e-06\n",
            "Epoch 1, Loss: 6.513927019113908e-06\n",
            "Epoch 1, Loss: 8.522179086867254e-06\n",
            "Epoch 1, Loss: 6.689142537652515e-06\n",
            "Epoch 1, Loss: 9.71305234997999e-06\n",
            "Epoch 1, Loss: 7.824583008186892e-06\n",
            "Epoch 1, Loss: 8.909702955861576e-06\n",
            "Epoch 1, Loss: 7.212671789602609e-06\n",
            "Epoch 1, Loss: 6.274613951973151e-06\n",
            "Epoch 1, Loss: 6.936273621249711e-06\n",
            "Epoch 1, Loss: 6.410701189452084e-06\n",
            "Epoch 1, Loss: 6.526909601234365e-06\n",
            "Epoch 1, Loss: 8.65999663801631e-06\n",
            "Epoch 1, Loss: 9.561042134009767e-06\n",
            "Epoch 1, Loss: 7.96254607848823e-06\n",
            "Epoch 1, Loss: 7.165182069002185e-06\n",
            "Epoch 1, Loss: 7.648095561307855e-06\n",
            "Epoch 1, Loss: 6.970069534872891e-06\n",
            "Epoch 1, Loss: 6.221970579645131e-06\n",
            "Epoch 1, Loss: 5.8274358707421925e-06\n",
            "Epoch 1, Loss: 6.6001375671476126e-06\n",
            "Epoch 1, Loss: 6.897304956510197e-06\n",
            "Epoch 1, Loss: 8.117495781334583e-06\n",
            "Epoch 1, Loss: 8.579874702263623e-06\n",
            "Epoch 1, Loss: 7.217953680083156e-06\n",
            "Epoch 1, Loss: 5.834038347529713e-06\n",
            "Epoch 1, Loss: 7.269917659868952e-06\n",
            "Epoch 1, Loss: 8.282065209641587e-06\n",
            "Epoch 1, Loss: 7.383408046734985e-06\n",
            "Epoch 1, Loss: 8.09943230706267e-06\n",
            "Epoch 1, Loss: 8.144716957758646e-06\n",
            "Epoch 1, Loss: 7.280524641828379e-06\n",
            "Epoch 1, Loss: 8.535566848877352e-06\n",
            "Epoch 1, Loss: 6.977606517466484e-06\n",
            "Epoch 1, Loss: 6.295572802628158e-06\n",
            "Epoch 1, Loss: 9.779559150047135e-06\n",
            "Epoch 1, Loss: 6.560602287208894e-06\n",
            "Epoch 1, Loss: 7.067517344694352e-06\n",
            "Epoch 1, Loss: 7.530711172876181e-06\n",
            "Epoch 1, Loss: 6.81390429235762e-06\n",
            "Epoch 1, Loss: 6.7243945522932336e-06\n",
            "Epoch 1, Loss: 6.932053111086134e-06\n",
            "Epoch 1, Loss: 5.983353730698582e-06\n",
            "Epoch 1, Loss: 7.939514944155235e-06\n",
            "Epoch 1, Loss: 7.53348604121129e-06\n",
            "Epoch 1, Loss: 6.374536951625487e-06\n",
            "Epoch 1, Loss: 8.04214141680859e-06\n",
            "Epoch 1, Loss: 7.871385605540127e-06\n",
            "Epoch 1, Loss: 7.414301308017457e-06\n",
            "Epoch 1, Loss: 6.634310011577327e-06\n",
            "Epoch 1, Loss: 6.680791102553485e-06\n",
            "Epoch 1, Loss: 6.6387287915858906e-06\n",
            "Epoch 1, Loss: 5.939762559137307e-06\n",
            "Epoch 1, Loss: 6.306236628006445e-06\n",
            "Epoch 1, Loss: 8.265532414952759e-06\n",
            "Epoch 1, Loss: 7.1088334152591415e-06\n",
            "Epoch 1, Loss: 8.997814802569337e-06\n",
            "Epoch 1, Loss: 7.847003871574998e-06\n",
            "Epoch 1, Loss: 8.361136679013725e-06\n",
            "Epoch 1, Loss: 6.877432497276459e-06\n",
            "Epoch 1, Loss: 6.772755568817956e-06\n",
            "Epoch 1, Loss: 6.642117114097346e-06\n",
            "Epoch 1, Loss: 6.557339020218933e-06\n",
            "Epoch 1, Loss: 7.951733095978852e-06\n",
            "Epoch 1, Loss: 8.477519259031396e-06\n",
            "Epoch 1, Loss: 7.255539003381273e-06\n",
            "Epoch 1, Loss: 5.758889983553672e-06\n",
            "Epoch 1, Loss: 7.573954462714028e-06\n",
            "Epoch 1, Loss: 5.7363990890735295e-06\n",
            "Epoch 1, Loss: 8.335331585840322e-06\n",
            "Epoch 1, Loss: 7.821889994374942e-06\n",
            "Epoch 1, Loss: 8.045148206292652e-06\n",
            "Epoch 1, Loss: 6.3036363826540764e-06\n",
            "Epoch 1, Loss: 8.848383004078642e-06\n",
            "Epoch 1, Loss: 9.8935279311263e-06\n",
            "Epoch 1, Loss: 1.4801277757214848e-05\n",
            "Epoch 1, Loss: 5.780023457191419e-06\n",
            "Epoch 1, Loss: 8.02910108177457e-06\n",
            "Epoch 1, Loss: 8.832106686895713e-06\n",
            "Epoch 1, Loss: 7.615733011334669e-06\n",
            "Epoch 1, Loss: 7.82575716584688e-06\n",
            "Epoch 1, Loss: 6.080450475565158e-06\n",
            "Epoch 1, Loss: 9.440476787858643e-06\n",
            "Epoch 1, Loss: 6.754049536539242e-06\n",
            "Epoch 1, Loss: 8.266249096777756e-06\n",
            "Epoch 1, Loss: 7.0357405093091074e-06\n",
            "Epoch 1, Loss: 9.83635527518345e-06\n",
            "Epoch 1, Loss: 7.548245775979012e-06\n",
            "Epoch 1, Loss: 7.5837997428607196e-06\n",
            "Epoch 1, Loss: 1.1924346836167388e-05\n",
            "Epoch 1, Loss: 6.988435416133143e-06\n",
            "Epoch 1, Loss: 7.767675015202258e-06\n",
            "Epoch 1, Loss: 7.93492108641658e-06\n",
            "Epoch 1, Loss: 7.07584740666789e-06\n",
            "Epoch 1, Loss: 7.783938599459361e-06\n",
            "Epoch 1, Loss: 6.421479156415444e-06\n",
            "Epoch 1, Loss: 6.859171207906911e-06\n",
            "Epoch 1, Loss: 7.645080586371478e-06\n",
            "Epoch 1, Loss: 6.684490472252946e-06\n",
            "Epoch 1, Loss: 5.696568223356735e-06\n",
            "Epoch 1, Loss: 5.928964583290508e-06\n",
            "Epoch 1, Loss: 7.84853909863159e-06\n",
            "Epoch 1, Loss: 7.68329482525587e-06\n",
            "Epoch 1, Loss: 7.978747817105614e-06\n",
            "Epoch 1, Loss: 7.700245987507515e-06\n",
            "Epoch 1, Loss: 5.214659722696524e-06\n",
            "Epoch 1, Loss: 7.163382633734727e-06\n",
            "Epoch 1, Loss: 7.461771929229144e-06\n",
            "Epoch 1, Loss: 7.130561243684497e-06\n",
            "Epoch 1, Loss: 6.603649580938509e-06\n",
            "Epoch 1, Loss: 6.536197815876221e-06\n",
            "Epoch 1, Loss: 8.330650416610297e-06\n",
            "Epoch 1, Loss: 6.381585990311578e-06\n",
            "Epoch 1, Loss: 6.8137096604914404e-06\n",
            "Epoch 1, Loss: 7.919194104033522e-06\n",
            "Epoch 1, Loss: 6.927744379936485e-06\n",
            "Epoch 1, Loss: 7.186425591498846e-06\n",
            "Epoch 1, Loss: 1.1631357665464748e-05\n",
            "Epoch 1, Loss: 7.357213689829223e-06\n",
            "Epoch 1, Loss: 7.163964255596511e-06\n",
            "Epoch 1, Loss: 1.251530284207547e-05\n",
            "Epoch 1, Loss: 7.240523245855002e-06\n",
            "Epoch 1, Loss: 6.8909521360183135e-06\n",
            "Epoch 1, Loss: 6.571553512912942e-06\n",
            "Epoch 1, Loss: 7.2280236054211855e-06\n",
            "Epoch 1, Loss: 7.4094086812692694e-06\n",
            "Epoch 1, Loss: 6.27708050160436e-06\n",
            "Epoch 1, Loss: 7.095632554410258e-06\n",
            "Epoch 1, Loss: 6.334952558972873e-06\n",
            "Epoch 1, Loss: 6.491154181276215e-06\n",
            "Epoch 1, Loss: 7.3580122261773795e-06\n",
            "Epoch 1, Loss: 6.029127234796761e-06\n",
            "Epoch 1, Loss: 6.245700205909088e-06\n",
            "Epoch 1, Loss: 7.082873253239086e-06\n",
            "Epoch 1, Loss: 7.793198165018111e-06\n",
            "Epoch 1, Loss: 7.065990757837426e-06\n",
            "Epoch 1, Loss: 6.011137429595692e-06\n",
            "Epoch 1, Loss: 6.4606524574628565e-06\n",
            "Epoch 1, Loss: 5.969222456769785e-06\n",
            "Epoch 1, Loss: 7.183793968579266e-06\n",
            "Epoch 1, Loss: 6.238109563128091e-06\n",
            "Epoch 1, Loss: 6.4642572397133335e-06\n",
            "Epoch 1, Loss: 8.431839887634851e-06\n",
            "Epoch 1, Loss: 8.326695024152286e-06\n",
            "Epoch 1, Loss: 8.66885602590628e-06\n",
            "Epoch 1, Loss: 1.0501678843866102e-05\n",
            "Epoch 1, Loss: 8.043947673286311e-06\n",
            "Epoch 1, Loss: 1.2445414540707134e-05\n",
            "Epoch 1, Loss: 7.826261935406365e-06\n",
            "Epoch 1, Loss: 5.943495125393383e-06\n",
            "Epoch 1, Loss: 6.163228135847021e-06\n",
            "Epoch 1, Loss: 7.169931905082194e-06\n",
            "Epoch 1, Loss: 8.997111763164867e-06\n",
            "Epoch 1, Loss: 6.39647896605311e-06\n",
            "Epoch 1, Loss: 7.618231393280439e-06\n",
            "Epoch 1, Loss: 6.725193543388741e-06\n",
            "Epoch 1, Loss: 5.769772542407736e-06\n",
            "Epoch 1, Loss: 6.712092726957053e-06\n",
            "Epoch 1, Loss: 9.818747457757127e-06\n",
            "Epoch 1, Loss: 8.523430551576894e-06\n",
            "Epoch 1, Loss: 9.089402738027275e-06\n",
            "Epoch 1, Loss: 6.1172927416919265e-06\n",
            "Epoch 1, Loss: 7.821143299224786e-06\n",
            "Epoch 1, Loss: 7.3425835580565035e-06\n",
            "Epoch 1, Loss: 7.2289126364921685e-06\n",
            "Epoch 1, Loss: 8.260978574980982e-06\n",
            "Epoch 1, Loss: 7.261016889970051e-06\n",
            "Epoch 1, Loss: 7.013192316662753e-06\n",
            "Epoch 1, Loss: 7.269659818120999e-06\n",
            "Epoch 1, Loss: 8.697882549313363e-06\n",
            "Epoch 1, Loss: 6.984290848777164e-06\n",
            "Epoch 1, Loss: 7.76471097196918e-06\n",
            "Epoch 1, Loss: 5.989248620608123e-06\n",
            "Epoch 1, Loss: 7.712408660154324e-06\n",
            "Epoch 1, Loss: 5.926317498960998e-06\n",
            "Epoch 1, Loss: 6.469547770393547e-06\n",
            "Epoch 1, Loss: 6.390981070580892e-06\n",
            "Epoch 1, Loss: 5.925850018684287e-06\n",
            "Epoch 1, Loss: 6.246614702831721e-06\n",
            "Epoch 1, Loss: 6.769567789888242e-06\n",
            "Epoch 1, Loss: 8.210021405830048e-06\n",
            "Epoch 1, Loss: 6.902167569933226e-06\n",
            "Epoch 1, Loss: 7.2245547926286235e-06\n",
            "Epoch 1, Loss: 6.47092429062468e-06\n",
            "Epoch 1, Loss: 6.0313027461234014e-06\n",
            "Epoch 1, Loss: 7.084478966135066e-06\n",
            "Epoch 1, Loss: 6.769116225768812e-06\n",
            "Epoch 1, Loss: 7.800713319738861e-06\n",
            "Epoch 1, Loss: 6.252707407838898e-06\n",
            "Epoch 1, Loss: 6.977059001656016e-06\n",
            "Epoch 1, Loss: 6.9262187025742605e-06\n",
            "Epoch 1, Loss: 6.349338036670815e-06\n",
            "Epoch 1, Loss: 7.343700872297632e-06\n",
            "Epoch 1, Loss: 5.836633590661222e-06\n",
            "Epoch 1, Loss: 7.4631475399655756e-06\n",
            "Epoch 1, Loss: 7.446982635883614e-06\n",
            "Epoch 1, Loss: 7.587555501231691e-06\n",
            "Epoch 1, Loss: 6.100108748796629e-06\n",
            "Epoch 1, Loss: 6.154809852887411e-06\n",
            "Epoch 1, Loss: 6.9007178353786e-06\n",
            "Epoch 1, Loss: 6.289259545155801e-06\n",
            "Epoch 1, Loss: 7.478649422409944e-06\n",
            "Epoch 1, Loss: 8.064828762144316e-06\n",
            "Epoch 1, Loss: 7.341639957303414e-06\n",
            "Epoch 1, Loss: 5.176380000193603e-06\n",
            "Epoch 1, Loss: 6.931888947292464e-06\n",
            "Epoch 1, Loss: 7.787253707647324e-06\n",
            "Epoch 1, Loss: 7.858880053390749e-06\n",
            "Epoch 1, Loss: 7.081162948452402e-06\n",
            "Epoch 1, Loss: 6.5041463130910415e-06\n",
            "Epoch 1, Loss: 6.146102350612637e-06\n",
            "Epoch 1, Loss: 6.473488610936329e-06\n",
            "Epoch 1, Loss: 7.484713023586664e-06\n",
            "Epoch 1, Loss: 7.654641194676515e-06\n",
            "Epoch 1, Loss: 7.712848855589982e-06\n",
            "Epoch 1, Loss: 9.816430065257009e-06\n",
            "Epoch 1, Loss: 7.100529273884604e-06\n",
            "Epoch 1, Loss: 7.517056019423762e-06\n",
            "Epoch 1, Loss: 6.69011478748871e-06\n",
            "Epoch 1, Loss: 8.368203452846501e-06\n",
            "Epoch 1, Loss: 5.971718564978801e-06\n",
            "Epoch 1, Loss: 6.199763447511941e-06\n",
            "Epoch 1, Loss: 6.891604243719485e-06\n",
            "Epoch 1, Loss: 5.243588020675816e-06\n",
            "Epoch 1, Loss: 5.2153513934172224e-06\n",
            "Epoch 1, Loss: 7.693082807236351e-06\n",
            "Epoch 1, Loss: 6.821217084507225e-06\n",
            "Epoch 1, Loss: 6.830659458501032e-06\n",
            "Epoch 1, Loss: 7.100652965164045e-06\n",
            "Epoch 1, Loss: 7.712248589086812e-06\n",
            "Epoch 1, Loss: 6.214776931301458e-06\n",
            "Epoch 1, Loss: 5.865023467777064e-06\n",
            "Epoch 1, Loss: 7.1869167186378036e-06\n",
            "Epoch 1, Loss: 5.031221462559188e-06\n",
            "Epoch 1, Loss: 7.4495374065008946e-06\n",
            "Epoch 1, Loss: 9.828710972215049e-06\n",
            "Epoch 1, Loss: 6.279037734202575e-06\n",
            "Epoch 1, Loss: 6.869289791211486e-06\n",
            "Epoch 1, Loss: 6.2045128288445994e-06\n",
            "Epoch 1, Loss: 7.6260080277279485e-06\n",
            "Epoch 1, Loss: 7.636762347829062e-06\n",
            "Epoch 1, Loss: 7.178836767707253e-06\n",
            "Epoch 1, Loss: 9.793059689400252e-06\n",
            "Epoch 1, Loss: 8.167179657903034e-06\n",
            "Epoch 1, Loss: 8.361891559616197e-06\n",
            "Epoch 1, Loss: 6.864333499834174e-06\n",
            "Epoch 1, Loss: 6.355918230838142e-06\n",
            "Epoch 1, Loss: 7.050703516142676e-06\n",
            "Epoch 1, Loss: 7.97882785263937e-06\n",
            "Epoch 1, Loss: 5.371712177293375e-06\n",
            "Epoch 1, Loss: 7.243864274641965e-06\n",
            "Epoch 1, Loss: 6.68121947455802e-06\n",
            "Epoch 1, Loss: 6.8108656705589965e-06\n",
            "Epoch 1, Loss: 5.174874331714818e-06\n",
            "Epoch 1, Loss: 5.718510692531709e-06\n",
            "Epoch 1, Loss: 7.821272447472438e-06\n",
            "Epoch 1, Loss: 6.181493517942727e-06\n",
            "Epoch 1, Loss: 6.850384124845732e-06\n",
            "Epoch 1, Loss: 7.365051715169102e-06\n",
            "Epoch 1, Loss: 7.54499751565163e-06\n",
            "Epoch 1, Loss: 5.6457065511494875e-06\n",
            "Epoch 1, Loss: 6.30398199064075e-06\n",
            "Epoch 1, Loss: 6.232008217921248e-06\n",
            "Epoch 1, Loss: 6.62281536278897e-06\n",
            "Epoch 1, Loss: 6.223717718967237e-06\n",
            "Epoch 1, Loss: 7.356127753155306e-06\n",
            "Epoch 1, Loss: 6.8360150180524215e-06\n",
            "Epoch 1, Loss: 6.951562681933865e-06\n",
            "Epoch 1, Loss: 7.5333969107305165e-06\n",
            "Epoch 1, Loss: 6.254686013562605e-06\n",
            "Epoch 1, Loss: 6.859200766484719e-06\n",
            "Epoch 1, Loss: 6.45650925434893e-06\n",
            "Epoch 1, Loss: 5.305797003529733e-06\n",
            "Epoch 1, Loss: 8.140063982864376e-06\n",
            "Epoch 1, Loss: 6.35233118373435e-06\n",
            "Epoch 1, Loss: 6.844559720775578e-06\n",
            "Epoch 1, Loss: 7.863443897804245e-06\n",
            "Epoch 1, Loss: 7.5628640843206085e-06\n",
            "Epoch 1, Loss: 6.257589120650664e-06\n",
            "Epoch 1, Loss: 6.511173978651641e-06\n",
            "Epoch 1, Loss: 6.100379778217757e-06\n",
            "Epoch 1, Loss: 7.283006652869517e-06\n",
            "Epoch 1, Loss: 5.949070782662602e-06\n",
            "Epoch 1, Loss: 6.249701073102187e-06\n",
            "Epoch 1, Loss: 5.580903689406114e-06\n",
            "Epoch 1, Loss: 8.18989246909041e-06\n",
            "Epoch 1, Loss: 5.645737928716699e-06\n",
            "Epoch 1, Loss: 6.505030341941165e-06\n",
            "Epoch 1, Loss: 8.45308204588946e-06\n",
            "Epoch 1, Loss: 6.935277269803919e-06\n",
            "Epoch 1, Loss: 6.053720881027402e-06\n",
            "Epoch 1, Loss: 5.8080381677427795e-06\n",
            "Epoch 1, Loss: 7.3135652201017365e-06\n",
            "Epoch 1, Loss: 5.76798947804491e-06\n",
            "Epoch 1, Loss: 6.662269242951879e-06\n",
            "Epoch 1, Loss: 6.3545676312060095e-06\n",
            "Epoch 1, Loss: 6.503008080471773e-06\n",
            "Epoch 1, Loss: 7.942961929074954e-06\n",
            "Epoch 1, Loss: 8.774492926022504e-06\n",
            "Epoch 1, Loss: 6.202084932738217e-06\n",
            "Epoch 1, Loss: 6.731369921908481e-06\n",
            "Epoch 1, Loss: 5.997610514896223e-06\n",
            "Epoch 1, Loss: 7.135820396797499e-06\n",
            "Epoch 1, Loss: 5.272446287563071e-06\n",
            "Epoch 1, Loss: 5.247254193818662e-06\n",
            "Epoch 1, Loss: 6.359729013638571e-06\n",
            "Epoch 1, Loss: 6.798538834118517e-06\n",
            "Epoch 1, Loss: 6.246846169233322e-06\n",
            "Epoch 1, Loss: 6.80431139699067e-06\n",
            "Epoch 1, Loss: 7.359443316090619e-06\n",
            "Epoch 1, Loss: 6.8069684857618995e-06\n",
            "Epoch 1, Loss: 6.747209681634558e-06\n",
            "Epoch 1, Loss: 7.269482011906803e-06\n",
            "Epoch 1, Loss: 5.606129434454488e-06\n",
            "Epoch 1, Loss: 7.391617600660538e-06\n",
            "Epoch 1, Loss: 8.64171943248948e-06\n",
            "Epoch 1, Loss: 8.357274055015296e-06\n",
            "Epoch 1, Loss: 6.888983079988975e-06\n",
            "Epoch 1, Loss: 7.604855454701465e-06\n",
            "Epoch 1, Loss: 1.2964833331352565e-05\n",
            "Epoch 1, Loss: 7.153281785576837e-06\n",
            "Epoch 1, Loss: 6.827695415267954e-06\n",
            "Epoch 1, Loss: 5.566873369389214e-06\n",
            "Epoch 1, Loss: 5.826435881317593e-06\n",
            "Epoch 1, Loss: 6.559082521562232e-06\n",
            "Epoch 1, Loss: 8.276594599010423e-06\n",
            "Epoch 1, Loss: 5.275830517348368e-06\n",
            "Epoch 1, Loss: 6.718616987200221e-06\n",
            "Epoch 1, Loss: 6.355357527354499e-06\n",
            "Epoch 1, Loss: 6.466414106398588e-06\n",
            "Epoch 1, Loss: 8.55096550367307e-06\n",
            "Epoch 1, Loss: 5.419495664682472e-06\n",
            "Epoch 1, Loss: 8.893968697520904e-06\n",
            "Epoch 1, Loss: 9.531519935990218e-06\n",
            "Epoch 1, Loss: 6.660896815446904e-06\n",
            "Epoch 1, Loss: 7.588918379042298e-06\n",
            "Epoch 1, Loss: 7.246941095218062e-06\n",
            "Epoch 1, Loss: 6.575110091944225e-06\n",
            "Epoch 1, Loss: 6.913187007739907e-06\n",
            "Epoch 1, Loss: 7.4695681178127415e-06\n",
            "Epoch 1, Loss: 5.943471023783786e-06\n",
            "Epoch 1, Loss: 8.124861778924242e-06\n",
            "Epoch 1, Loss: 6.111617494752863e-06\n",
            "Epoch 1, Loss: 6.385218057403108e-06\n",
            "Epoch 1, Loss: 6.69105338602094e-06\n",
            "Epoch 1, Loss: 6.271140591707081e-06\n",
            "Epoch 1, Loss: 6.495628440461587e-06\n",
            "Epoch 1, Loss: 4.5570709517051e-06\n",
            "Reached Stop Point!!\n",
            "Converged after 1 epochs.\n",
            "Training completed. Final loss: 4.5570709517051e-06\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#----// Training Loop //---------------------------\n",
        "\n",
        "optimizer = torch.optim.Adam(nn_model.parameters(), lr=0.00001)  # Using Adam optimizer with lower learning rate\n",
        "\n",
        "num_epochs = 1000  # Set a maximum number of epochs\n",
        "best_loss = float('inf')\n",
        "patience = 100  # Number of epochs to wait for improvement before early stopping\n",
        "no_improve = 0\n",
        "epoch = 0\n",
        "\n",
        "#for epoch in range(num_epochs):\n",
        "while True:\n",
        "    nn_model.train()  # Set the model to training mode\n",
        "    optimizer.zero_grad()\n",
        "    loss, _ = nn_model.forward(Y_train, Labels_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    # Early stopping check\n",
        "    if loss.item() < best_loss:\n",
        "        best_loss = loss.item()\n",
        "        no_improve = 0\n",
        "    else:\n",
        "        no_improve += 1\n",
        "\n",
        "    if no_improve >= patience:\n",
        "        print(f\"Early stopping triggered. No improvement for {patience} epochs.\")\n",
        "        break\n",
        "    \"\"\"\n",
        "\n",
        "    if loss.item() < 5e-6:\n",
        "        print(\"Reached Stop Point!!\")\n",
        "        print(f\"Converged after {epoch+1} epochs.\")\n",
        "        break\n",
        "\n",
        "print(f\"Training completed. Final loss: {loss.item()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qjvkO5Q46ud"
      },
      "outputs": [],
      "source": [
        "\n",
        "#-------------------------------\n",
        "\"\"\"\n",
        "    Plot a single IR spectrum.\n",
        "\n",
        "    Parameters:\n",
        "    - X: array-like\n",
        "        The wavenumbers (x-axis values)\n",
        "    - Y: array-like\n",
        "        The absorbance or transmittance values (y-axis values)\n",
        "    - title: str, default='IR Spectrum'\n",
        "        Title of the plot\n",
        "    - xlabel: str, default='Wavenumber (cm)'\n",
        "        Label for the x-axis\n",
        "    - ylabel: str, default='Absorbance'\n",
        "        Label for the y-axis\n",
        "    - filename: str, default='ir_spectrum.png'\n",
        "        Filename to save the plot\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "def plot_ir(X, Y, title='IR Spectrum', xlabel='Wavenumber (cm)', ylabel='Absorbance', filename='ir_spectrum.png'):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(X, Y)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"IR spectrum plot saved as '{filename}'\")\n",
        "\n",
        "# Example usage:\n",
        "plot_ir(processed_X_values, processed_Y_values[2])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhreq77KgwC8",
        "outputId": "17029dfb-a7d8-47a8-8e5d-73fee9f4957b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices Predicted: [0, 7, 13, 23]\n",
            "Actual Indices: [13, 23]\n",
            "----------------------\n",
            "Indices Predicted: [10, 23]\n",
            "Actual Indices: [0]\n",
            "----------------------\n",
            "Indices Predicted: []\n",
            "Actual Indices: [1, 15, 23]\n",
            "----------------------\n",
            "Indices Predicted: [8, 23]\n",
            "Actual Indices: [7, 8, 23]\n",
            "----------------------\n",
            "Indices Predicted: [23]\n",
            "Actual Indices: [7, 16, 23]\n",
            "----------------------\n",
            "Indices Predicted: [6, 23]\n",
            "Actual Indices: [1, 6, 23]\n",
            "----------------------\n",
            "Indices Predicted: [6, 7, 8, 22, 23]\n",
            "Actual Indices: [6, 7, 13, 23]\n",
            "----------------------\n",
            "Indices Predicted: [23]\n",
            "Actual Indices: [0]\n",
            "----------------------\n",
            "Indices Predicted: [0, 7, 23]\n",
            "Actual Indices: [5, 6, 23]\n",
            "----------------------\n"
          ]
        }
      ],
      "source": [
        "i = 7\n",
        "for i in range(0, 9):\n",
        "  with torch.no_grad():\n",
        "      def get_indices_above_threshold(vector, threshold):\n",
        "          return [i for i, value in enumerate(vector) if value > threshold]\n",
        "\n",
        "      # Use __call__ method for inference\n",
        "      model_output = nn_model(Y_test[i])\n",
        "      threshold = 0.6 # Adjust this threshold as needed\n",
        "      indices_above_threshold = get_indices_above_threshold(model_output, threshold)\n",
        "      correct = get_indices_above_threshold(Labels_test[i], threshold)\n",
        "\n",
        "      print(\"Indices Predicted:\", indices_above_threshold)\n",
        "      print(\"Actual Indices:\", correct)\n",
        "      #print(model_output)\n",
        "      print(\"----------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 10\n",
        "with torch.no_grad():\n",
        "  def get_indices_above_threshold(vector, threshold):\n",
        "      return [i for i, value in enumerate(vector) if value > threshold]\n",
        "\n",
        "  # Example usage:\n",
        "  model_output = nn_model(Y_train[i])\n",
        "  threshold = 0.9960 # Adjust this threshold as needed\n",
        "  indices_above_threshold = get_indices_above_threshold(model_output, threshold)\n",
        "  correct = get_indices_above_threshold(Labels_train[i], threshold)\n",
        "\n",
        "  print(\"Indices Predicted:\", indices_above_threshold)\n",
        "  print(\"Actual Indices:\", correct)\n",
        "  #print(model_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6TeNJZdn3_G",
        "outputId": "09b9a9d5-1bd8-437d-dc93-7029b75c871f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices Predicted: [23]\n",
            "Actual Indices: [23]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-F5808fhg-cA",
        "outputId": "3f3df469-8c01-4704-f81f-18f2a66c88ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4898(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.4783(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4583(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4681(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5238(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4400 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4783(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.4000 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4444(total performance!)\n",
            "Precision: 0.4737(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4091(total performance!)\n",
            "Precision: 0.4737(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4091(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3600 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4186(total performance!)\n",
            "Precision: 0.4706(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3810(total performance!)\n",
            "Precision: 0.4706(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3810(total performance!)\n",
            "Precision: 0.4706(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3810(total performance!)\n",
            "Precision: 0.4706(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3810(total performance!)\n",
            "Precision: 0.4706(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3810(total performance!)\n",
            "Precision: 0.4706(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3810(total performance!)\n",
            "Precision: 0.4706(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3810(total performance!)\n",
            "Precision: 0.4706(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3810(total performance!)\n",
            "Precision: 0.4706(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3810(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3902(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3902(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3902(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3902(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3902(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3902(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3902(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3902(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3902(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3902(total performance!)\n",
            "Precision: 0.5333(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4000(total performance!)\n",
            "Precision: 0.5333(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4000(total performance!)\n",
            "Precision: 0.5333(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4000(total performance!)\n",
            "Precision: 0.5333(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4000(total performance!)\n",
            "Precision: 0.5333(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4000(total performance!)\n",
            "Precision: 0.5333(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4000(total performance!)\n",
            "Precision: 0.5333(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4000(total performance!)\n",
            "Precision: 0.5333(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4000(total performance!)\n",
            "Precision: 0.5333(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4000(total performance!)\n",
            "Precision: 0.5333(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4000(total performance!)\n",
            "Precision: 0.5333(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4000(total performance!)\n",
            "Precision: 0.5333(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4000(total performance!)\n",
            "Precision: 0.5333(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4000(total performance!)\n",
            "Precision: 0.5333(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.3200 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.4000(total performance!)\n",
            "Precision: 0.5000(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.2800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3590(total performance!)\n",
            "Precision: 0.5833(Positive guesses/inverse Proportional to false positive rate)\n",
            "Recall: 0.2800 (Negative Guesses/Inverse Proportional to false negative rate.)\n",
            "F1 Score: 0.3784(total performance!)\n",
            "Maximum F1 Score: 0.4898 at Threshold: 0.4000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "tresh = np.arange(0.4, 0.999, 0.001)\n",
        "pre = []\n",
        "rec = []\n",
        "f1s = []\n",
        "\n",
        "\n",
        "for treshi in tresh:\n",
        "  def evaluate_model_accuracy(model, X_values, y_true, threshold=treshi):\n",
        "      model.eval()\n",
        "      total_correct = 0\n",
        "      total_predicted = 0\n",
        "      total_actual = 0\n",
        "\n",
        "      with torch.no_grad():\n",
        "          for i in range(len(X_values)):\n",
        "              model_output = model(X_values[i].unsqueeze(0)).squeeze()\n",
        "              predicted_indices = set(get_indices_above_threshold(model_output, threshold))\n",
        "              actual_indices = set(get_indices_above_threshold(y_true[i], threshold))\n",
        "\n",
        "              correct = predicted_indices.intersection(actual_indices)\n",
        "              total_correct += len(correct)\n",
        "              total_predicted += len(predicted_indices)\n",
        "              total_actual += len(actual_indices)\n",
        "\n",
        "      precision = total_correct / total_predicted if total_predicted > 0 else 0\n",
        "      recall = total_correct / total_actual if total_actual > 0 else 0\n",
        "      f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "      print(f\"Precision: {precision:.4f}(Positive guesses/inverse Proportional to false positive rate)\")\n",
        "      print(f\"Recall: {recall:.4f} (Negative Guesses/Inverse Proportional to false negative rate.)\")\n",
        "      print(f\"F1 Score: {f1_score:.4f}(total performance!)\")\n",
        "\n",
        "      return precision, recall, f1_score\n",
        "\n",
        "  # Usage\n",
        "  precision, recall, f1_score = evaluate_model_accuracy(nn_model, Y_test, Labels_test)\n",
        "  pre.append(precision)\n",
        "  rec.append(recall)\n",
        "  f1s.append(f1_score)\n",
        "\n",
        "#plt.plot(tresh, pre, label='Precision')\n",
        "#plt.plot(tresh, rec, label='Recall')\n",
        "plt.plot(tresh, f1s, label='F1 Score')\n",
        "\n",
        "max_f1 = max(f1s)\n",
        "max_index = f1s.index(max_f1)\n",
        "print(f\"Maximum F1 Score: {max_f1:.4f} at Threshold: {tresh[max_index]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfLictSkHlk3"
      },
      "outputs": [],
      "source": [
        "# Export the model for future training\n",
        "torch.save({\n",
        "    'model_state_dict': nn_model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': loss.item()\n",
        "}, 'ir_model_checkpoint_(4L)_(L2)_v1.pth')\n",
        "\n",
        "print(\"Model saved successfully for future training.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEUq1u5ASg5X"
      },
      "outputs": [],
      "source": [
        "# Assuming you have defined your model architecture (nn_model) beforehand\n",
        "\n",
        "# Load the checkpoint\n",
        "checkpoint = torch.load('ir_model_checkpoint_(4L)_(L2)_v1.pth')\n",
        "\n",
        "# Load the model state dictionary\n",
        "nn_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# If you want to continue training, you can also load the optimizer state\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "# Set the model to evaluation mode if you're using it for inference\n",
        "#nn_model.eval()\n",
        "\n",
        "print(\"Model loaded successfully.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}